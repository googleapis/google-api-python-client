<html><body>
<style>

body, h1, h2, h3, div, span, p, pre, a {
  margin: 0;
  padding: 0;
  border: 0;
  font-weight: inherit;
  font-style: inherit;
  font-size: 100%;
  font-family: inherit;
  vertical-align: baseline;
}

body {
  font-size: 13px;
  padding: 1em;
}

h1 {
  font-size: 26px;
  margin-bottom: 1em;
}

h2 {
  font-size: 24px;
  margin-bottom: 1em;
}

h3 {
  font-size: 20px;
  margin-bottom: 1em;
  margin-top: 1em;
}

pre, code {
  line-height: 1.5;
  font-family: Monaco, 'DejaVu Sans Mono', 'Bitstream Vera Sans Mono', 'Lucida Console', monospace;
}

pre {
  margin-top: 0.5em;
}

h1, h2, h3, p {
  font-family: Arial, sans serif;
}

h1, h2, h3 {
  border-bottom: solid #CCC 1px;
}

.toc_element {
  margin-top: 0.5em;
}

.firstline {
  margin-left: 2 em;
}

.method  {
  margin-top: 1em;
  border: solid 1px #CCC;
  padding: 1em;
  background: #EEE;
}

.details {
  font-weight: bold;
  font-size: 14px;
}

</style>

<h1><a href="aiplatform_v1beta1.html">Vertex AI API</a> . <a href="aiplatform_v1beta1.projects.html">projects</a> . <a href="aiplatform_v1beta1.projects.locations.html">locations</a></h1>
<h2>Instance Methods</h2>
<p class="toc_element">
  <code><a href="aiplatform_v1beta1.projects.locations.agents.html">agents()</a></code>
</p>
<p class="firstline">Returns the agents Resource.</p>

<p class="toc_element">
  <code><a href="aiplatform_v1beta1.projects.locations.apps.html">apps()</a></code>
</p>
<p class="firstline">Returns the apps Resource.</p>

<p class="toc_element">
  <code><a href="aiplatform_v1beta1.projects.locations.batchPredictionJobs.html">batchPredictionJobs()</a></code>
</p>
<p class="firstline">Returns the batchPredictionJobs Resource.</p>

<p class="toc_element">
  <code><a href="aiplatform_v1beta1.projects.locations.cachedContents.html">cachedContents()</a></code>
</p>
<p class="firstline">Returns the cachedContents Resource.</p>

<p class="toc_element">
  <code><a href="aiplatform_v1beta1.projects.locations.customJobs.html">customJobs()</a></code>
</p>
<p class="firstline">Returns the customJobs Resource.</p>

<p class="toc_element">
  <code><a href="aiplatform_v1beta1.projects.locations.dataLabelingJobs.html">dataLabelingJobs()</a></code>
</p>
<p class="firstline">Returns the dataLabelingJobs Resource.</p>

<p class="toc_element">
  <code><a href="aiplatform_v1beta1.projects.locations.datasets.html">datasets()</a></code>
</p>
<p class="firstline">Returns the datasets Resource.</p>

<p class="toc_element">
  <code><a href="aiplatform_v1beta1.projects.locations.deploymentResourcePools.html">deploymentResourcePools()</a></code>
</p>
<p class="firstline">Returns the deploymentResourcePools Resource.</p>

<p class="toc_element">
  <code><a href="aiplatform_v1beta1.projects.locations.edgeDevices.html">edgeDevices()</a></code>
</p>
<p class="firstline">Returns the edgeDevices Resource.</p>

<p class="toc_element">
  <code><a href="aiplatform_v1beta1.projects.locations.endpoints.html">endpoints()</a></code>
</p>
<p class="firstline">Returns the endpoints Resource.</p>

<p class="toc_element">
  <code><a href="aiplatform_v1beta1.projects.locations.evaluationTasks.html">evaluationTasks()</a></code>
</p>
<p class="firstline">Returns the evaluationTasks Resource.</p>

<p class="toc_element">
  <code><a href="aiplatform_v1beta1.projects.locations.exampleStores.html">exampleStores()</a></code>
</p>
<p class="firstline">Returns the exampleStores Resource.</p>

<p class="toc_element">
  <code><a href="aiplatform_v1beta1.projects.locations.extensionControllers.html">extensionControllers()</a></code>
</p>
<p class="firstline">Returns the extensionControllers Resource.</p>

<p class="toc_element">
  <code><a href="aiplatform_v1beta1.projects.locations.extensions.html">extensions()</a></code>
</p>
<p class="firstline">Returns the extensions Resource.</p>

<p class="toc_element">
  <code><a href="aiplatform_v1beta1.projects.locations.featureGroups.html">featureGroups()</a></code>
</p>
<p class="firstline">Returns the featureGroups Resource.</p>

<p class="toc_element">
  <code><a href="aiplatform_v1beta1.projects.locations.featureOnlineStores.html">featureOnlineStores()</a></code>
</p>
<p class="firstline">Returns the featureOnlineStores Resource.</p>

<p class="toc_element">
  <code><a href="aiplatform_v1beta1.projects.locations.featurestores.html">featurestores()</a></code>
</p>
<p class="firstline">Returns the featurestores Resource.</p>

<p class="toc_element">
  <code><a href="aiplatform_v1beta1.projects.locations.hyperparameterTuningJobs.html">hyperparameterTuningJobs()</a></code>
</p>
<p class="firstline">Returns the hyperparameterTuningJobs Resource.</p>

<p class="toc_element">
  <code><a href="aiplatform_v1beta1.projects.locations.indexEndpoints.html">indexEndpoints()</a></code>
</p>
<p class="firstline">Returns the indexEndpoints Resource.</p>

<p class="toc_element">
  <code><a href="aiplatform_v1beta1.projects.locations.indexes.html">indexes()</a></code>
</p>
<p class="firstline">Returns the indexes Resource.</p>

<p class="toc_element">
  <code><a href="aiplatform_v1beta1.projects.locations.metadataStores.html">metadataStores()</a></code>
</p>
<p class="firstline">Returns the metadataStores Resource.</p>

<p class="toc_element">
  <code><a href="aiplatform_v1beta1.projects.locations.migratableResources.html">migratableResources()</a></code>
</p>
<p class="firstline">Returns the migratableResources Resource.</p>

<p class="toc_element">
  <code><a href="aiplatform_v1beta1.projects.locations.modelDeploymentMonitoringJobs.html">modelDeploymentMonitoringJobs()</a></code>
</p>
<p class="firstline">Returns the modelDeploymentMonitoringJobs Resource.</p>

<p class="toc_element">
  <code><a href="aiplatform_v1beta1.projects.locations.modelMonitors.html">modelMonitors()</a></code>
</p>
<p class="firstline">Returns the modelMonitors Resource.</p>

<p class="toc_element">
  <code><a href="aiplatform_v1beta1.projects.locations.models.html">models()</a></code>
</p>
<p class="firstline">Returns the models Resource.</p>

<p class="toc_element">
  <code><a href="aiplatform_v1beta1.projects.locations.nasJobs.html">nasJobs()</a></code>
</p>
<p class="firstline">Returns the nasJobs Resource.</p>

<p class="toc_element">
  <code><a href="aiplatform_v1beta1.projects.locations.notebookExecutionJobs.html">notebookExecutionJobs()</a></code>
</p>
<p class="firstline">Returns the notebookExecutionJobs Resource.</p>

<p class="toc_element">
  <code><a href="aiplatform_v1beta1.projects.locations.notebookRuntimeTemplates.html">notebookRuntimeTemplates()</a></code>
</p>
<p class="firstline">Returns the notebookRuntimeTemplates Resource.</p>

<p class="toc_element">
  <code><a href="aiplatform_v1beta1.projects.locations.notebookRuntimes.html">notebookRuntimes()</a></code>
</p>
<p class="firstline">Returns the notebookRuntimes Resource.</p>

<p class="toc_element">
  <code><a href="aiplatform_v1beta1.projects.locations.operations.html">operations()</a></code>
</p>
<p class="firstline">Returns the operations Resource.</p>

<p class="toc_element">
  <code><a href="aiplatform_v1beta1.projects.locations.persistentResources.html">persistentResources()</a></code>
</p>
<p class="firstline">Returns the persistentResources Resource.</p>

<p class="toc_element">
  <code><a href="aiplatform_v1beta1.projects.locations.pipelineJobs.html">pipelineJobs()</a></code>
</p>
<p class="firstline">Returns the pipelineJobs Resource.</p>

<p class="toc_element">
  <code><a href="aiplatform_v1beta1.projects.locations.publishers.html">publishers()</a></code>
</p>
<p class="firstline">Returns the publishers Resource.</p>

<p class="toc_element">
  <code><a href="aiplatform_v1beta1.projects.locations.ragCorpora.html">ragCorpora()</a></code>
</p>
<p class="firstline">Returns the ragCorpora Resource.</p>

<p class="toc_element">
  <code><a href="aiplatform_v1beta1.projects.locations.reasoningEngines.html">reasoningEngines()</a></code>
</p>
<p class="firstline">Returns the reasoningEngines Resource.</p>

<p class="toc_element">
  <code><a href="aiplatform_v1beta1.projects.locations.schedules.html">schedules()</a></code>
</p>
<p class="firstline">Returns the schedules Resource.</p>

<p class="toc_element">
  <code><a href="aiplatform_v1beta1.projects.locations.solvers.html">solvers()</a></code>
</p>
<p class="firstline">Returns the solvers Resource.</p>

<p class="toc_element">
  <code><a href="aiplatform_v1beta1.projects.locations.specialistPools.html">specialistPools()</a></code>
</p>
<p class="firstline">Returns the specialistPools Resource.</p>

<p class="toc_element">
  <code><a href="aiplatform_v1beta1.projects.locations.studies.html">studies()</a></code>
</p>
<p class="firstline">Returns the studies Resource.</p>

<p class="toc_element">
  <code><a href="aiplatform_v1beta1.projects.locations.tensorboards.html">tensorboards()</a></code>
</p>
<p class="firstline">Returns the tensorboards Resource.</p>

<p class="toc_element">
  <code><a href="aiplatform_v1beta1.projects.locations.trainingPipelines.html">trainingPipelines()</a></code>
</p>
<p class="firstline">Returns the trainingPipelines Resource.</p>

<p class="toc_element">
  <code><a href="aiplatform_v1beta1.projects.locations.tuningJobs.html">tuningJobs()</a></code>
</p>
<p class="firstline">Returns the tuningJobs Resource.</p>

<p class="toc_element">
  <code><a href="#augmentPrompt">augmentPrompt(parent, body=None, x__xgafv=None)</a></code></p>
<p class="firstline">Given an input prompt, it returns augmented prompt from vertex rag store to guide LLM towards generating grounded responses.</p>
<p class="toc_element">
  <code><a href="#close">close()</a></code></p>
<p class="firstline">Close httplib2 connections.</p>
<p class="toc_element">
  <code><a href="#corroborateContent">corroborateContent(parent, body=None, x__xgafv=None)</a></code></p>
<p class="firstline">Given an input text, it returns a score that evaluates the factuality of the text. It also extracts and returns claims from the text and provides supporting facts.</p>
<p class="toc_element">
  <code><a href="#deploy">deploy(destination, body=None, x__xgafv=None)</a></code></p>
<p class="firstline">Deploys a model to a new endpoint.</p>
<p class="toc_element">
  <code><a href="#deployPublisherModel">deployPublisherModel(destination, body=None, x__xgafv=None)</a></code></p>
<p class="firstline">Deploys publisher models.</p>
<p class="toc_element">
  <code><a href="#evaluateDataset">evaluateDataset(location, body=None, x__xgafv=None)</a></code></p>
<p class="firstline">Evaluates a dataset based on a set of given metrics.</p>
<p class="toc_element">
  <code><a href="#evaluateInstances">evaluateInstances(location, body=None, x__xgafv=None)</a></code></p>
<p class="firstline">Evaluates instances based on a given metric.</p>
<p class="toc_element">
  <code><a href="#get">get(name, x__xgafv=None)</a></code></p>
<p class="firstline">Gets information about a location.</p>
<p class="toc_element">
  <code><a href="#list">list(name, filter=None, pageSize=None, pageToken=None, x__xgafv=None)</a></code></p>
<p class="firstline">Lists information about the supported locations for this service.</p>
<p class="toc_element">
  <code><a href="#list_next">list_next()</a></code></p>
<p class="firstline">Retrieves the next page of results.</p>
<p class="toc_element">
  <code><a href="#retrieveContexts">retrieveContexts(parent, body=None, x__xgafv=None)</a></code></p>
<p class="firstline">Retrieves relevant contexts for a query.</p>
<h3>Method Details</h3>
<div class="method">
    <code class="details" id="augmentPrompt">augmentPrompt(parent, body=None, x__xgafv=None)</code>
  <pre>Given an input prompt, it returns augmented prompt from vertex rag store to guide LLM towards generating grounded responses.

Args:
  parent: string, Required. The resource name of the Location from which to augment prompt. The users must have permission to make a call in the project. Format: `projects/{project}/locations/{location}`. (required)
  body: object, The request body.
    The object takes the form of:

{ # Request message for AugmentPrompt.
  &quot;contents&quot;: [ # Optional. Input content to augment, only text format is supported for now.
    { # The base structured datatype containing multi-part content of a message. A `Content` includes a `role` field designating the producer of the `Content` and a `parts` field containing multi-part data that contains the content of the message turn.
      &quot;parts&quot;: [ # Required. Ordered `Parts` that constitute a single message. Parts may have different IANA MIME types.
        { # A datatype containing media that is part of a multi-part `Content` message. A `Part` consists of data which has an associated datatype. A `Part` can only contain one of the accepted types in `Part.data`. A `Part` must have a fixed IANA MIME type identifying the type and subtype of the media if `inline_data` or `file_data` field is filled with raw bytes.
          &quot;codeExecutionResult&quot;: { # Result of executing the [ExecutableCode]. Always follows a `part` containing the [ExecutableCode]. # Optional. Result of executing the [ExecutableCode].
            &quot;outcome&quot;: &quot;A String&quot;, # Required. Outcome of the code execution.
            &quot;output&quot;: &quot;A String&quot;, # Optional. Contains stdout when code execution is successful, stderr or other description otherwise.
          },
          &quot;executableCode&quot;: { # Code generated by the model that is meant to be executed, and the result returned to the model. Generated when using the [FunctionDeclaration] tool and [FunctionCallingConfig] mode is set to [Mode.CODE]. # Optional. Code generated by the model that is meant to be executed.
            &quot;code&quot;: &quot;A String&quot;, # Required. The code to be executed.
            &quot;language&quot;: &quot;A String&quot;, # Required. Programming language of the `code`.
          },
          &quot;fileData&quot;: { # URI based data. # Optional. URI based data.
            &quot;displayName&quot;: &quot;A String&quot;, # Optional. Display name of the file data. Used to provide a label or filename to distinguish file datas. This field is only returned in PromptMessage for prompt management. It is not currently used in the Gemini GenerateContent calls.
            &quot;fileUri&quot;: &quot;A String&quot;, # Required. URI.
            &quot;mimeType&quot;: &quot;A String&quot;, # Required. The IANA standard MIME type of the source data.
          },
          &quot;functionCall&quot;: { # A predicted [FunctionCall] returned from the model that contains a string representing the [FunctionDeclaration.name] and a structured JSON object containing the parameters and their values. # Optional. A predicted [FunctionCall] returned from the model that contains a string representing the [FunctionDeclaration.name] with the parameters and their values.
            &quot;args&quot;: { # Optional. Required. The function parameters and values in JSON object format. See [FunctionDeclaration.parameters] for parameter details.
              &quot;a_key&quot;: &quot;&quot;, # Properties of the object.
            },
            &quot;name&quot;: &quot;A String&quot;, # Required. The name of the function to call. Matches [FunctionDeclaration.name].
          },
          &quot;functionResponse&quot;: { # The result output from a [FunctionCall] that contains a string representing the [FunctionDeclaration.name] and a structured JSON object containing any output from the function is used as context to the model. This should contain the result of a [FunctionCall] made based on model prediction. # Optional. The result output of a [FunctionCall] that contains a string representing the [FunctionDeclaration.name] and a structured JSON object containing any output from the function call. It is used as context to the model.
            &quot;name&quot;: &quot;A String&quot;, # Required. The name of the function to call. Matches [FunctionDeclaration.name] and [FunctionCall.name].
            &quot;response&quot;: { # Required. The function response in JSON object format. Use &quot;output&quot; key to specify function output and &quot;error&quot; key to specify error details (if any). If &quot;output&quot; and &quot;error&quot; keys are not specified, then whole &quot;response&quot; is treated as function output.
              &quot;a_key&quot;: &quot;&quot;, # Properties of the object.
            },
          },
          &quot;inlineData&quot;: { # Content blob. # Optional. Inlined bytes data.
            &quot;data&quot;: &quot;A String&quot;, # Required. Raw bytes.
            &quot;displayName&quot;: &quot;A String&quot;, # Optional. Display name of the blob. Used to provide a label or filename to distinguish blobs. This field is only returned in PromptMessage for prompt management. It is not currently used in the Gemini GenerateContent calls.
            &quot;mimeType&quot;: &quot;A String&quot;, # Required. The IANA standard MIME type of the source data.
          },
          &quot;text&quot;: &quot;A String&quot;, # Optional. Text part (can be code).
          &quot;thought&quot;: True or False, # Output only. Indicates if the part is thought from the model.
          &quot;videoMetadata&quot;: { # Metadata describes the input video content. # Optional. Video metadata. The metadata should only be specified while the video data is presented in inline_data or file_data.
            &quot;endOffset&quot;: &quot;A String&quot;, # Optional. The end offset of the video.
            &quot;startOffset&quot;: &quot;A String&quot;, # Optional. The start offset of the video.
          },
        },
      ],
      &quot;role&quot;: &quot;A String&quot;, # Optional. The producer of the content. Must be either &#x27;user&#x27; or &#x27;model&#x27;. Useful to set for multi-turn conversations, otherwise can be left blank or unset.
    },
  ],
  &quot;model&quot;: { # Metadata of the backend deployed model. # Optional. Metadata of the backend deployed model.
    &quot;model&quot;: &quot;A String&quot;, # Optional. The model that the user will send the augmented prompt for content generation.
    &quot;modelVersion&quot;: &quot;A String&quot;, # Optional. The model version of the backend deployed model.
  },
  &quot;vertexRagStore&quot;: { # Retrieve from Vertex RAG Store for grounding. # Optional. Retrieves contexts from the Vertex RagStore.
    &quot;ragCorpora&quot;: [ # Optional. Deprecated. Please use rag_resources instead.
      &quot;A String&quot;,
    ],
    &quot;ragResources&quot;: [ # Optional. The representation of the rag source. It can be used to specify corpus only or ragfiles. Currently only support one corpus or multiple files from one corpus. In the future we may open up multiple corpora support.
      { # The definition of the Rag resource.
        &quot;ragCorpus&quot;: &quot;A String&quot;, # Optional. RagCorpora resource name. Format: `projects/{project}/locations/{location}/ragCorpora/{rag_corpus}`
        &quot;ragFileIds&quot;: [ # Optional. rag_file_id. The files should be in the same rag_corpus set in rag_corpus field.
          &quot;A String&quot;,
        ],
      },
    ],
    &quot;ragRetrievalConfig&quot;: { # Specifies the context retrieval config. # Optional. The retrieval config for the Rag query.
      &quot;filter&quot;: { # Config for filters. # Optional. Config for filters.
        &quot;metadataFilter&quot;: &quot;A String&quot;, # Optional. String for metadata filtering.
        &quot;vectorDistanceThreshold&quot;: 3.14, # Optional. Only returns contexts with vector distance smaller than the threshold.
        &quot;vectorSimilarityThreshold&quot;: 3.14, # Optional. Only returns contexts with vector similarity larger than the threshold.
      },
      &quot;hybridSearch&quot;: { # Config for Hybrid Search. # Optional. Config for Hybrid Search.
        &quot;alpha&quot;: 3.14, # Optional. Alpha value controls the weight between dense and sparse vector search results. The range is [0, 1], while 0 means sparse vector search only and 1 means dense vector search only. The default value is 0.5 which balances sparse and dense vector search equally.
      },
      &quot;ranking&quot;: { # Config for ranking and reranking. # Optional. Config for ranking and reranking.
        &quot;llmRanker&quot;: { # Config for LlmRanker. # Optional. Config for LlmRanker.
          &quot;modelName&quot;: &quot;A String&quot;, # Optional. The model name used for ranking. Format: `gemini-1.5-pro`
        },
        &quot;rankService&quot;: { # Config for Rank Service. # Optional. Config for Rank Service.
          &quot;modelName&quot;: &quot;A String&quot;, # Optional. The model name of the rank service. Format: `semantic-ranker-512@latest`
        },
      },
      &quot;topK&quot;: 42, # Optional. The number of contexts to retrieve.
    },
    &quot;similarityTopK&quot;: 42, # Optional. Number of top k results to return from the selected corpora.
    &quot;vectorDistanceThreshold&quot;: 3.14, # Optional. Only return results with vector distance smaller than the threshold.
  },
}

  x__xgafv: string, V1 error format.
    Allowed values
      1 - v1 error format
      2 - v2 error format

Returns:
  An object of the form:

    { # Response message for AugmentPrompt.
  &quot;augmentedPrompt&quot;: [ # Augmented prompt, only text format is supported for now.
    { # The base structured datatype containing multi-part content of a message. A `Content` includes a `role` field designating the producer of the `Content` and a `parts` field containing multi-part data that contains the content of the message turn.
      &quot;parts&quot;: [ # Required. Ordered `Parts` that constitute a single message. Parts may have different IANA MIME types.
        { # A datatype containing media that is part of a multi-part `Content` message. A `Part` consists of data which has an associated datatype. A `Part` can only contain one of the accepted types in `Part.data`. A `Part` must have a fixed IANA MIME type identifying the type and subtype of the media if `inline_data` or `file_data` field is filled with raw bytes.
          &quot;codeExecutionResult&quot;: { # Result of executing the [ExecutableCode]. Always follows a `part` containing the [ExecutableCode]. # Optional. Result of executing the [ExecutableCode].
            &quot;outcome&quot;: &quot;A String&quot;, # Required. Outcome of the code execution.
            &quot;output&quot;: &quot;A String&quot;, # Optional. Contains stdout when code execution is successful, stderr or other description otherwise.
          },
          &quot;executableCode&quot;: { # Code generated by the model that is meant to be executed, and the result returned to the model. Generated when using the [FunctionDeclaration] tool and [FunctionCallingConfig] mode is set to [Mode.CODE]. # Optional. Code generated by the model that is meant to be executed.
            &quot;code&quot;: &quot;A String&quot;, # Required. The code to be executed.
            &quot;language&quot;: &quot;A String&quot;, # Required. Programming language of the `code`.
          },
          &quot;fileData&quot;: { # URI based data. # Optional. URI based data.
            &quot;displayName&quot;: &quot;A String&quot;, # Optional. Display name of the file data. Used to provide a label or filename to distinguish file datas. This field is only returned in PromptMessage for prompt management. It is not currently used in the Gemini GenerateContent calls.
            &quot;fileUri&quot;: &quot;A String&quot;, # Required. URI.
            &quot;mimeType&quot;: &quot;A String&quot;, # Required. The IANA standard MIME type of the source data.
          },
          &quot;functionCall&quot;: { # A predicted [FunctionCall] returned from the model that contains a string representing the [FunctionDeclaration.name] and a structured JSON object containing the parameters and their values. # Optional. A predicted [FunctionCall] returned from the model that contains a string representing the [FunctionDeclaration.name] with the parameters and their values.
            &quot;args&quot;: { # Optional. Required. The function parameters and values in JSON object format. See [FunctionDeclaration.parameters] for parameter details.
              &quot;a_key&quot;: &quot;&quot;, # Properties of the object.
            },
            &quot;name&quot;: &quot;A String&quot;, # Required. The name of the function to call. Matches [FunctionDeclaration.name].
          },
          &quot;functionResponse&quot;: { # The result output from a [FunctionCall] that contains a string representing the [FunctionDeclaration.name] and a structured JSON object containing any output from the function is used as context to the model. This should contain the result of a [FunctionCall] made based on model prediction. # Optional. The result output of a [FunctionCall] that contains a string representing the [FunctionDeclaration.name] and a structured JSON object containing any output from the function call. It is used as context to the model.
            &quot;name&quot;: &quot;A String&quot;, # Required. The name of the function to call. Matches [FunctionDeclaration.name] and [FunctionCall.name].
            &quot;response&quot;: { # Required. The function response in JSON object format. Use &quot;output&quot; key to specify function output and &quot;error&quot; key to specify error details (if any). If &quot;output&quot; and &quot;error&quot; keys are not specified, then whole &quot;response&quot; is treated as function output.
              &quot;a_key&quot;: &quot;&quot;, # Properties of the object.
            },
          },
          &quot;inlineData&quot;: { # Content blob. # Optional. Inlined bytes data.
            &quot;data&quot;: &quot;A String&quot;, # Required. Raw bytes.
            &quot;displayName&quot;: &quot;A String&quot;, # Optional. Display name of the blob. Used to provide a label or filename to distinguish blobs. This field is only returned in PromptMessage for prompt management. It is not currently used in the Gemini GenerateContent calls.
            &quot;mimeType&quot;: &quot;A String&quot;, # Required. The IANA standard MIME type of the source data.
          },
          &quot;text&quot;: &quot;A String&quot;, # Optional. Text part (can be code).
          &quot;thought&quot;: True or False, # Output only. Indicates if the part is thought from the model.
          &quot;videoMetadata&quot;: { # Metadata describes the input video content. # Optional. Video metadata. The metadata should only be specified while the video data is presented in inline_data or file_data.
            &quot;endOffset&quot;: &quot;A String&quot;, # Optional. The end offset of the video.
            &quot;startOffset&quot;: &quot;A String&quot;, # Optional. The start offset of the video.
          },
        },
      ],
      &quot;role&quot;: &quot;A String&quot;, # Optional. The producer of the content. Must be either &#x27;user&#x27; or &#x27;model&#x27;. Useful to set for multi-turn conversations, otherwise can be left blank or unset.
    },
  ],
  &quot;facts&quot;: [ # Retrieved facts from RAG data sources.
    { # The fact used in grounding.
      &quot;query&quot;: &quot;A String&quot;, # Query that is used to retrieve this fact.
      &quot;score&quot;: 3.14, # If present, according to the underlying Vector DB and the selected metric type, the score can be either the distance or the similarity between the query and the fact and its range depends on the metric type. For example, if the metric type is COSINE_DISTANCE, it represents the distance between the query and the fact. The larger the distance, the less relevant the fact is to the query. The range is [0, 2], while 0 means the most relevant and 2 means the least relevant.
      &quot;summary&quot;: &quot;A String&quot;, # If present, the summary/snippet of the fact.
      &quot;title&quot;: &quot;A String&quot;, # If present, it refers to the title of this fact.
      &quot;uri&quot;: &quot;A String&quot;, # If present, this uri links to the source of the fact.
      &quot;vectorDistance&quot;: 3.14, # If present, the distance between the query vector and this fact vector.
    },
  ],
}</pre>
</div>

<div class="method">
    <code class="details" id="close">close()</code>
  <pre>Close httplib2 connections.</pre>
</div>

<div class="method">
    <code class="details" id="corroborateContent">corroborateContent(parent, body=None, x__xgafv=None)</code>
  <pre>Given an input text, it returns a score that evaluates the factuality of the text. It also extracts and returns claims from the text and provides supporting facts.

Args:
  parent: string, Required. The resource name of the Location from which to corroborate text. The users must have permission to make a call in the project. Format: `projects/{project}/locations/{location}`. (required)
  body: object, The request body.
    The object takes the form of:

{ # Request message for CorroborateContent.
  &quot;content&quot;: { # The base structured datatype containing multi-part content of a message. A `Content` includes a `role` field designating the producer of the `Content` and a `parts` field containing multi-part data that contains the content of the message turn. # Optional. Input content to corroborate, only text format is supported for now.
    &quot;parts&quot;: [ # Required. Ordered `Parts` that constitute a single message. Parts may have different IANA MIME types.
      { # A datatype containing media that is part of a multi-part `Content` message. A `Part` consists of data which has an associated datatype. A `Part` can only contain one of the accepted types in `Part.data`. A `Part` must have a fixed IANA MIME type identifying the type and subtype of the media if `inline_data` or `file_data` field is filled with raw bytes.
        &quot;codeExecutionResult&quot;: { # Result of executing the [ExecutableCode]. Always follows a `part` containing the [ExecutableCode]. # Optional. Result of executing the [ExecutableCode].
          &quot;outcome&quot;: &quot;A String&quot;, # Required. Outcome of the code execution.
          &quot;output&quot;: &quot;A String&quot;, # Optional. Contains stdout when code execution is successful, stderr or other description otherwise.
        },
        &quot;executableCode&quot;: { # Code generated by the model that is meant to be executed, and the result returned to the model. Generated when using the [FunctionDeclaration] tool and [FunctionCallingConfig] mode is set to [Mode.CODE]. # Optional. Code generated by the model that is meant to be executed.
          &quot;code&quot;: &quot;A String&quot;, # Required. The code to be executed.
          &quot;language&quot;: &quot;A String&quot;, # Required. Programming language of the `code`.
        },
        &quot;fileData&quot;: { # URI based data. # Optional. URI based data.
          &quot;displayName&quot;: &quot;A String&quot;, # Optional. Display name of the file data. Used to provide a label or filename to distinguish file datas. This field is only returned in PromptMessage for prompt management. It is not currently used in the Gemini GenerateContent calls.
          &quot;fileUri&quot;: &quot;A String&quot;, # Required. URI.
          &quot;mimeType&quot;: &quot;A String&quot;, # Required. The IANA standard MIME type of the source data.
        },
        &quot;functionCall&quot;: { # A predicted [FunctionCall] returned from the model that contains a string representing the [FunctionDeclaration.name] and a structured JSON object containing the parameters and their values. # Optional. A predicted [FunctionCall] returned from the model that contains a string representing the [FunctionDeclaration.name] with the parameters and their values.
          &quot;args&quot;: { # Optional. Required. The function parameters and values in JSON object format. See [FunctionDeclaration.parameters] for parameter details.
            &quot;a_key&quot;: &quot;&quot;, # Properties of the object.
          },
          &quot;name&quot;: &quot;A String&quot;, # Required. The name of the function to call. Matches [FunctionDeclaration.name].
        },
        &quot;functionResponse&quot;: { # The result output from a [FunctionCall] that contains a string representing the [FunctionDeclaration.name] and a structured JSON object containing any output from the function is used as context to the model. This should contain the result of a [FunctionCall] made based on model prediction. # Optional. The result output of a [FunctionCall] that contains a string representing the [FunctionDeclaration.name] and a structured JSON object containing any output from the function call. It is used as context to the model.
          &quot;name&quot;: &quot;A String&quot;, # Required. The name of the function to call. Matches [FunctionDeclaration.name] and [FunctionCall.name].
          &quot;response&quot;: { # Required. The function response in JSON object format. Use &quot;output&quot; key to specify function output and &quot;error&quot; key to specify error details (if any). If &quot;output&quot; and &quot;error&quot; keys are not specified, then whole &quot;response&quot; is treated as function output.
            &quot;a_key&quot;: &quot;&quot;, # Properties of the object.
          },
        },
        &quot;inlineData&quot;: { # Content blob. # Optional. Inlined bytes data.
          &quot;data&quot;: &quot;A String&quot;, # Required. Raw bytes.
          &quot;displayName&quot;: &quot;A String&quot;, # Optional. Display name of the blob. Used to provide a label or filename to distinguish blobs. This field is only returned in PromptMessage for prompt management. It is not currently used in the Gemini GenerateContent calls.
          &quot;mimeType&quot;: &quot;A String&quot;, # Required. The IANA standard MIME type of the source data.
        },
        &quot;text&quot;: &quot;A String&quot;, # Optional. Text part (can be code).
        &quot;thought&quot;: True or False, # Output only. Indicates if the part is thought from the model.
        &quot;videoMetadata&quot;: { # Metadata describes the input video content. # Optional. Video metadata. The metadata should only be specified while the video data is presented in inline_data or file_data.
          &quot;endOffset&quot;: &quot;A String&quot;, # Optional. The end offset of the video.
          &quot;startOffset&quot;: &quot;A String&quot;, # Optional. The start offset of the video.
        },
      },
    ],
    &quot;role&quot;: &quot;A String&quot;, # Optional. The producer of the content. Must be either &#x27;user&#x27; or &#x27;model&#x27;. Useful to set for multi-turn conversations, otherwise can be left blank or unset.
  },
  &quot;facts&quot;: [ # Optional. Facts used to generate the text can also be used to corroborate the text.
    { # The fact used in grounding.
      &quot;query&quot;: &quot;A String&quot;, # Query that is used to retrieve this fact.
      &quot;score&quot;: 3.14, # If present, according to the underlying Vector DB and the selected metric type, the score can be either the distance or the similarity between the query and the fact and its range depends on the metric type. For example, if the metric type is COSINE_DISTANCE, it represents the distance between the query and the fact. The larger the distance, the less relevant the fact is to the query. The range is [0, 2], while 0 means the most relevant and 2 means the least relevant.
      &quot;summary&quot;: &quot;A String&quot;, # If present, the summary/snippet of the fact.
      &quot;title&quot;: &quot;A String&quot;, # If present, it refers to the title of this fact.
      &quot;uri&quot;: &quot;A String&quot;, # If present, this uri links to the source of the fact.
      &quot;vectorDistance&quot;: 3.14, # If present, the distance between the query vector and this fact vector.
    },
  ],
  &quot;parameters&quot;: { # Parameters that can be overrided per request. # Optional. Parameters that can be set to override default settings per request.
    &quot;citationThreshold&quot;: 3.14, # Optional. Only return claims with citation score larger than the threshold.
  },
}

  x__xgafv: string, V1 error format.
    Allowed values
      1 - v1 error format
      2 - v2 error format

Returns:
  An object of the form:

    { # Response message for CorroborateContent.
  &quot;claims&quot;: [ # Claims that are extracted from the input content and facts that support the claims.
    { # Claim that is extracted from the input text and facts that support it.
      &quot;endIndex&quot;: 42, # Index in the input text where the claim ends (exclusive).
      &quot;factIndexes&quot;: [ # Indexes of the facts supporting this claim.
        42,
      ],
      &quot;score&quot;: 3.14, # Confidence score of this corroboration.
      &quot;startIndex&quot;: 42, # Index in the input text where the claim starts (inclusive).
    },
  ],
  &quot;corroborationScore&quot;: 3.14, # Confidence score of corroborating content. Value is [0,1] with 1 is the most confidence.
}</pre>
</div>

<div class="method">
    <code class="details" id="deploy">deploy(destination, body=None, x__xgafv=None)</code>
  <pre>Deploys a model to a new endpoint.

Args:
  destination: string, Required. The resource name of the Location to deploy the model in. Format: `projects/{project}/locations/{location}` (required)
  body: object, The request body.
    The object takes the form of:

{ # Request message for ModelGardenService.Deploy.
  &quot;deployConfig&quot;: { # The deploy config to use for the deployment. # Optional. The deploy config to use for the deployment. If not specified, the default deploy config will be used.
    &quot;dedicatedResources&quot;: { # A description of resources that are dedicated to a DeployedModel or DeployedIndex, and that need a higher degree of manual configuration. # Optional. The dedicated resources to use for the endpoint. If not set, the default resources will be used.
      &quot;autoscalingMetricSpecs&quot;: [ # Immutable. The metric specifications that overrides a resource utilization metric (CPU utilization, accelerator&#x27;s duty cycle, and so on) target value (default to 60 if not set). At most one entry is allowed per metric. If machine_spec.accelerator_count is above 0, the autoscaling will be based on both CPU utilization and accelerator&#x27;s duty cycle metrics and scale up when either metrics exceeds its target value while scale down if both metrics are under their target value. The default target value is 60 for both metrics. If machine_spec.accelerator_count is 0, the autoscaling will be based on CPU utilization metric only with default target value 60 if not explicitly set. For example, in the case of Online Prediction, if you want to override target CPU utilization to 80, you should set autoscaling_metric_specs.metric_name to `aiplatform.googleapis.com/prediction/online/cpu/utilization` and autoscaling_metric_specs.target to `80`.
        { # The metric specification that defines the target resource utilization (CPU utilization, accelerator&#x27;s duty cycle, and so on) for calculating the desired replica count.
          &quot;metricName&quot;: &quot;A String&quot;, # Required. The resource metric name. Supported metrics: * For Online Prediction: * `aiplatform.googleapis.com/prediction/online/accelerator/duty_cycle` * `aiplatform.googleapis.com/prediction/online/cpu/utilization`
          &quot;target&quot;: 42, # The target resource utilization in percentage (1% - 100%) for the given metric; once the real usage deviates from the target by a certain percentage, the machine replicas change. The default value is 60 (representing 60%) if not provided.
        },
      ],
      &quot;machineSpec&quot;: { # Specification of a single machine. # Required. Immutable. The specification of a single machine being used.
        &quot;acceleratorCount&quot;: 42, # The number of accelerators to attach to the machine.
        &quot;acceleratorType&quot;: &quot;A String&quot;, # Immutable. The type of accelerator(s) that may be attached to the machine as per accelerator_count.
        &quot;machineType&quot;: &quot;A String&quot;, # Immutable. The type of the machine. See the [list of machine types supported for prediction](https://cloud.google.com/vertex-ai/docs/predictions/configure-compute#machine-types) See the [list of machine types supported for custom training](https://cloud.google.com/vertex-ai/docs/training/configure-compute#machine-types). For DeployedModel this field is optional, and the default value is `n1-standard-2`. For BatchPredictionJob or as part of WorkerPoolSpec this field is required.
        &quot;multihostGpuNodeCount&quot;: 42, # Optional. Immutable. The number of nodes per replica for multihost GPU deployments.
        &quot;reservationAffinity&quot;: { # A ReservationAffinity can be used to configure a Vertex AI resource (e.g., a DeployedModel) to draw its Compute Engine resources from a Shared Reservation, or exclusively from on-demand capacity. # Optional. Immutable. Configuration controlling how this resource pool consumes reservation.
          &quot;key&quot;: &quot;A String&quot;, # Optional. Corresponds to the label key of a reservation resource. To target a SPECIFIC_RESERVATION by name, use `compute.googleapis.com/reservation-name` as the key and specify the name of your reservation as its value.
          &quot;reservationAffinityType&quot;: &quot;A String&quot;, # Required. Specifies the reservation affinity type.
          &quot;values&quot;: [ # Optional. Corresponds to the label values of a reservation resource. This must be the full resource name of the reservation or reservation block.
            &quot;A String&quot;,
          ],
        },
        &quot;tpuTopology&quot;: &quot;A String&quot;, # Immutable. The topology of the TPUs. Corresponds to the TPU topologies available from GKE. (Example: tpu_topology: &quot;2x2x1&quot;).
      },
      &quot;maxReplicaCount&quot;: 42, # Immutable. The maximum number of replicas that may be deployed on when the traffic against it increases. If the requested value is too large, the deployment will error, but if deployment succeeds then the ability to scale to that many replicas is guaranteed (barring service outages). If traffic increases beyond what its replicas at maximum may handle, a portion of the traffic will be dropped. If this value is not provided, will use min_replica_count as the default value. The value of this field impacts the charge against Vertex CPU and GPU quotas. Specifically, you will be charged for (max_replica_count * number of cores in the selected machine type) and (max_replica_count * number of GPUs per replica in the selected machine type).
      &quot;minReplicaCount&quot;: 42, # Required. Immutable. The minimum number of machine replicas that will be always deployed on. This value must be greater than or equal to 1. If traffic increases, it may dynamically be deployed onto more replicas, and as traffic decreases, some of these extra replicas may be freed.
      &quot;requiredReplicaCount&quot;: 42, # Optional. Number of required available replicas for the deployment to succeed. This field is only needed when partial deployment/mutation is desired. If set, the deploy/mutate operation will succeed once available_replica_count reaches required_replica_count, and the rest of the replicas will be retried. If not set, the default required_replica_count will be min_replica_count.
      &quot;spot&quot;: True or False, # Optional. If true, schedule the deployment workload on [spot VMs](https://cloud.google.com/kubernetes-engine/docs/concepts/spot-vms).
    },
    &quot;fastTryoutEnabled&quot;: True or False, # Optional. If true, enable the QMT fast tryout feature for this model if possible.
  },
  &quot;endpointConfig&quot;: { # The endpoint config to use for the deployment. # Optional. The endpoint config to use for the deployment. If not specified, the default endpoint config will be used.
    &quot;dedicatedEndpointEnabled&quot;: True or False, # Optional. If true, the endpoint will be exposed through a dedicated DNS [Endpoint.dedicated_endpoint_dns]. Your request to the dedicated DNS will be isolated from other users&#x27; traffic and will have better performance and reliability. Note: Once you enabled dedicated endpoint, you won&#x27;t be able to send request to the shared DNS {region}-aiplatform.googleapis.com. The limitations will be removed soon.
    &quot;endpointDisplayName&quot;: &quot;A String&quot;, # Optional. The user-specified display name of the endpoint. If not set, a default name will be used.
  },
  &quot;huggingFaceModelId&quot;: &quot;A String&quot;, # The Hugging Face model to deploy. Format: Hugging Face model ID like `google/gemma-2-2b-it`.
  &quot;modelConfig&quot;: { # The model config to use for the deployment. # Optional. The model config to use for the deployment. If not specified, the default model config will be used.
    &quot;acceptEula&quot;: True or False, # Optional. Whether the user accepts the End User License Agreement (EULA) for the model.
    &quot;containerSpec&quot;: { # Specification of a container for serving predictions. Some fields in this message correspond to fields in the [Kubernetes Container v1 core specification](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core). # Optional. The specification of the container that is to be used when deploying. If not set, the default container spec will be used.
      &quot;args&quot;: [ # Immutable. Specifies arguments for the command that runs when the container starts. This overrides the container&#x27;s [`CMD`](https://docs.docker.com/engine/reference/builder/#cmd). Specify this field as an array of executable and arguments, similar to a Docker `CMD`&#x27;s &quot;default parameters&quot; form. If you don&#x27;t specify this field but do specify the command field, then the command from the `command` field runs without any additional arguments. See the [Kubernetes documentation about how the `command` and `args` fields interact with a container&#x27;s `ENTRYPOINT` and `CMD`](https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#notes). If you don&#x27;t specify this field and don&#x27;t specify the `command` field, then the container&#x27;s [`ENTRYPOINT`](https://docs.docker.com/engine/reference/builder/#cmd) and `CMD` determine what runs based on their default behavior. See the Docker documentation about [how `CMD` and `ENTRYPOINT` interact](https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact). In this field, you can reference [environment variables set by Vertex AI](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables) and environment variables set in the env field. You cannot reference environment variables set in the Docker image. In order for environment variables to be expanded, reference them by using the following syntax: $( VARIABLE_NAME) Note that this differs from Bash variable expansion, which does not use parentheses. If a variable cannot be resolved, the reference in the input string is used unchanged. To avoid variable expansion, you can escape this syntax with `$$`; for example: $$(VARIABLE_NAME) This field corresponds to the `args` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
        &quot;A String&quot;,
      ],
      &quot;command&quot;: [ # Immutable. Specifies the command that runs when the container starts. This overrides the container&#x27;s [ENTRYPOINT](https://docs.docker.com/engine/reference/builder/#entrypoint). Specify this field as an array of executable and arguments, similar to a Docker `ENTRYPOINT`&#x27;s &quot;exec&quot; form, not its &quot;shell&quot; form. If you do not specify this field, then the container&#x27;s `ENTRYPOINT` runs, in conjunction with the args field or the container&#x27;s [`CMD`](https://docs.docker.com/engine/reference/builder/#cmd), if either exists. If this field is not specified and the container does not have an `ENTRYPOINT`, then refer to the Docker documentation about [how `CMD` and `ENTRYPOINT` interact](https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact). If you specify this field, then you can also specify the `args` field to provide additional arguments for this command. However, if you specify this field, then the container&#x27;s `CMD` is ignored. See the [Kubernetes documentation about how the `command` and `args` fields interact with a container&#x27;s `ENTRYPOINT` and `CMD`](https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#notes). In this field, you can reference [environment variables set by Vertex AI](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables) and environment variables set in the env field. You cannot reference environment variables set in the Docker image. In order for environment variables to be expanded, reference them by using the following syntax: $( VARIABLE_NAME) Note that this differs from Bash variable expansion, which does not use parentheses. If a variable cannot be resolved, the reference in the input string is used unchanged. To avoid variable expansion, you can escape this syntax with `$$`; for example: $$(VARIABLE_NAME) This field corresponds to the `command` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
        &quot;A String&quot;,
      ],
      &quot;deploymentTimeout&quot;: &quot;A String&quot;, # Immutable. Deployment timeout. Limit for deployment timeout is 2 hours.
      &quot;env&quot;: [ # Immutable. List of environment variables to set in the container. After the container starts running, code running in the container can read these environment variables. Additionally, the command and args fields can reference these variables. Later entries in this list can also reference earlier entries. For example, the following example sets the variable `VAR_2` to have the value `foo bar`: ```json [ { &quot;name&quot;: &quot;VAR_1&quot;, &quot;value&quot;: &quot;foo&quot; }, { &quot;name&quot;: &quot;VAR_2&quot;, &quot;value&quot;: &quot;$(VAR_1) bar&quot; } ] ``` If you switch the order of the variables in the example, then the expansion does not occur. This field corresponds to the `env` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
        { # Represents an environment variable present in a Container or Python Module.
          &quot;name&quot;: &quot;A String&quot;, # Required. Name of the environment variable. Must be a valid C identifier.
          &quot;value&quot;: &quot;A String&quot;, # Required. Variables that reference a $(VAR_NAME) are expanded using the previous defined environment variables in the container and any service environment variables. If a variable cannot be resolved, the reference in the input string will be unchanged. The $(VAR_NAME) syntax can be escaped with a double $$, ie: $$(VAR_NAME). Escaped references will never be expanded, regardless of whether the variable exists or not.
        },
      ],
      &quot;grpcPorts&quot;: [ # Immutable. List of ports to expose from the container. Vertex AI sends gRPC prediction requests that it receives to the first port on this list. Vertex AI also sends liveness and health checks to this port. If you do not specify this field, gRPC requests to the container will be disabled. Vertex AI does not use ports other than the first one listed. This field corresponds to the `ports` field of the Kubernetes Containers v1 core API.
        { # Represents a network port in a container.
          &quot;containerPort&quot;: 42, # The number of the port to expose on the pod&#x27;s IP address. Must be a valid port number, between 1 and 65535 inclusive.
        },
      ],
      &quot;healthProbe&quot;: { # Probe describes a health check to be performed against a container to determine whether it is alive or ready to receive traffic. # Immutable. Specification for Kubernetes readiness probe.
        &quot;exec&quot;: { # ExecAction specifies a command to execute. # ExecAction probes the health of a container by executing a command.
          &quot;command&quot;: [ # Command is the command line to execute inside the container, the working directory for the command is root (&#x27;/&#x27;) in the container&#x27;s filesystem. The command is simply exec&#x27;d, it is not run inside a shell, so traditional shell instructions (&#x27;|&#x27;, etc) won&#x27;t work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
            &quot;A String&quot;,
          ],
        },
        &quot;failureThreshold&quot;: 42, # Number of consecutive failures before the probe is considered failed. Defaults to 3. Minimum value is 1. Maps to Kubernetes probe argument &#x27;failureThreshold&#x27;.
        &quot;grpc&quot;: { # GrpcAction checks the health of a container using a gRPC service. # GrpcAction probes the health of a container by sending a gRPC request.
          &quot;port&quot;: 42, # Port number of the gRPC service. Number must be in the range 1 to 65535.
          &quot;service&quot;: &quot;A String&quot;, # Service is the name of the service to place in the gRPC HealthCheckRequest (see https://github.com/grpc/grpc/blob/master/doc/health-checking.md). If this is not specified, the default behavior is defined by gRPC.
        },
        &quot;httpGet&quot;: { # HttpGetAction describes an action based on HTTP Get requests. # HttpGetAction probes the health of a container by sending an HTTP GET request.
          &quot;host&quot;: &quot;A String&quot;, # Host name to connect to, defaults to the model serving container&#x27;s IP. You probably want to set &quot;Host&quot; in httpHeaders instead.
          &quot;httpHeaders&quot;: [ # Custom headers to set in the request. HTTP allows repeated headers.
            { # HttpHeader describes a custom header to be used in HTTP probes
              &quot;name&quot;: &quot;A String&quot;, # The header field name. This will be canonicalized upon output, so case-variant names will be understood as the same header.
              &quot;value&quot;: &quot;A String&quot;, # The header field value
            },
          ],
          &quot;path&quot;: &quot;A String&quot;, # Path to access on the HTTP server.
          &quot;port&quot;: 42, # Number of the port to access on the container. Number must be in the range 1 to 65535.
          &quot;scheme&quot;: &quot;A String&quot;, # Scheme to use for connecting to the host. Defaults to HTTP. Acceptable values are &quot;HTTP&quot; or &quot;HTTPS&quot;.
        },
        &quot;initialDelaySeconds&quot;: 42, # Number of seconds to wait before starting the probe. Defaults to 0. Minimum value is 0. Maps to Kubernetes probe argument &#x27;initialDelaySeconds&#x27;.
        &quot;periodSeconds&quot;: 42, # How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1. Must be less than timeout_seconds. Maps to Kubernetes probe argument &#x27;periodSeconds&#x27;.
        &quot;successThreshold&quot;: 42, # Number of consecutive successes before the probe is considered successful. Defaults to 1. Minimum value is 1. Maps to Kubernetes probe argument &#x27;successThreshold&#x27;.
        &quot;tcpSocket&quot;: { # TcpSocketAction probes the health of a container by opening a TCP socket connection. # TcpSocketAction probes the health of a container by opening a TCP socket connection.
          &quot;host&quot;: &quot;A String&quot;, # Optional: Host name to connect to, defaults to the model serving container&#x27;s IP.
          &quot;port&quot;: 42, # Number of the port to access on the container. Number must be in the range 1 to 65535.
        },
        &quot;timeoutSeconds&quot;: 42, # Number of seconds after which the probe times out. Defaults to 1 second. Minimum value is 1. Must be greater or equal to period_seconds. Maps to Kubernetes probe argument &#x27;timeoutSeconds&#x27;.
      },
      &quot;healthRoute&quot;: &quot;A String&quot;, # Immutable. HTTP path on the container to send health checks to. Vertex AI intermittently sends GET requests to this path on the container&#x27;s IP address and port to check that the container is healthy. Read more about [health checks](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#health). For example, if you set this field to `/bar`, then Vertex AI intermittently sends a GET request to the `/bar` path on the port of your container specified by the first value of this `ModelContainerSpec`&#x27;s ports field. If you don&#x27;t specify this field, it defaults to the following value when you deploy this Model to an Endpoint: /v1/endpoints/ENDPOINT/deployedModels/ DEPLOYED_MODEL:predict The placeholders in this value are replaced as follows: * ENDPOINT: The last segment (following `endpoints/`)of the Endpoint.name][] field of the Endpoint where this Model has been deployed. (Vertex AI makes this value available to your container code as the [`AIP_ENDPOINT_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).) * DEPLOYED_MODEL: DeployedModel.id of the `DeployedModel`. (Vertex AI makes this value available to your container code as the [`AIP_DEPLOYED_MODEL_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
      &quot;imageUri&quot;: &quot;A String&quot;, # Required. Immutable. URI of the Docker image to be used as the custom container for serving predictions. This URI must identify an image in Artifact Registry or Container Registry. Learn more about the [container publishing requirements](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#publishing), including permissions requirements for the Vertex AI Service Agent. The container image is ingested upon ModelService.UploadModel, stored internally, and this original path is afterwards not used. To learn about the requirements for the Docker image itself, see [Custom container requirements](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#). You can use the URI to one of Vertex AI&#x27;s [pre-built container images for prediction](https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers) in this field.
      &quot;livenessProbe&quot;: { # Probe describes a health check to be performed against a container to determine whether it is alive or ready to receive traffic. # Immutable. Specification for Kubernetes liveness probe.
        &quot;exec&quot;: { # ExecAction specifies a command to execute. # ExecAction probes the health of a container by executing a command.
          &quot;command&quot;: [ # Command is the command line to execute inside the container, the working directory for the command is root (&#x27;/&#x27;) in the container&#x27;s filesystem. The command is simply exec&#x27;d, it is not run inside a shell, so traditional shell instructions (&#x27;|&#x27;, etc) won&#x27;t work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
            &quot;A String&quot;,
          ],
        },
        &quot;failureThreshold&quot;: 42, # Number of consecutive failures before the probe is considered failed. Defaults to 3. Minimum value is 1. Maps to Kubernetes probe argument &#x27;failureThreshold&#x27;.
        &quot;grpc&quot;: { # GrpcAction checks the health of a container using a gRPC service. # GrpcAction probes the health of a container by sending a gRPC request.
          &quot;port&quot;: 42, # Port number of the gRPC service. Number must be in the range 1 to 65535.
          &quot;service&quot;: &quot;A String&quot;, # Service is the name of the service to place in the gRPC HealthCheckRequest (see https://github.com/grpc/grpc/blob/master/doc/health-checking.md). If this is not specified, the default behavior is defined by gRPC.
        },
        &quot;httpGet&quot;: { # HttpGetAction describes an action based on HTTP Get requests. # HttpGetAction probes the health of a container by sending an HTTP GET request.
          &quot;host&quot;: &quot;A String&quot;, # Host name to connect to, defaults to the model serving container&#x27;s IP. You probably want to set &quot;Host&quot; in httpHeaders instead.
          &quot;httpHeaders&quot;: [ # Custom headers to set in the request. HTTP allows repeated headers.
            { # HttpHeader describes a custom header to be used in HTTP probes
              &quot;name&quot;: &quot;A String&quot;, # The header field name. This will be canonicalized upon output, so case-variant names will be understood as the same header.
              &quot;value&quot;: &quot;A String&quot;, # The header field value
            },
          ],
          &quot;path&quot;: &quot;A String&quot;, # Path to access on the HTTP server.
          &quot;port&quot;: 42, # Number of the port to access on the container. Number must be in the range 1 to 65535.
          &quot;scheme&quot;: &quot;A String&quot;, # Scheme to use for connecting to the host. Defaults to HTTP. Acceptable values are &quot;HTTP&quot; or &quot;HTTPS&quot;.
        },
        &quot;initialDelaySeconds&quot;: 42, # Number of seconds to wait before starting the probe. Defaults to 0. Minimum value is 0. Maps to Kubernetes probe argument &#x27;initialDelaySeconds&#x27;.
        &quot;periodSeconds&quot;: 42, # How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1. Must be less than timeout_seconds. Maps to Kubernetes probe argument &#x27;periodSeconds&#x27;.
        &quot;successThreshold&quot;: 42, # Number of consecutive successes before the probe is considered successful. Defaults to 1. Minimum value is 1. Maps to Kubernetes probe argument &#x27;successThreshold&#x27;.
        &quot;tcpSocket&quot;: { # TcpSocketAction probes the health of a container by opening a TCP socket connection. # TcpSocketAction probes the health of a container by opening a TCP socket connection.
          &quot;host&quot;: &quot;A String&quot;, # Optional: Host name to connect to, defaults to the model serving container&#x27;s IP.
          &quot;port&quot;: 42, # Number of the port to access on the container. Number must be in the range 1 to 65535.
        },
        &quot;timeoutSeconds&quot;: 42, # Number of seconds after which the probe times out. Defaults to 1 second. Minimum value is 1. Must be greater or equal to period_seconds. Maps to Kubernetes probe argument &#x27;timeoutSeconds&#x27;.
      },
      &quot;ports&quot;: [ # Immutable. List of ports to expose from the container. Vertex AI sends any prediction requests that it receives to the first port on this list. Vertex AI also sends [liveness and health checks](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#liveness) to this port. If you do not specify this field, it defaults to following value: ```json [ { &quot;containerPort&quot;: 8080 } ] ``` Vertex AI does not use ports other than the first one listed. This field corresponds to the `ports` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
        { # Represents a network port in a container.
          &quot;containerPort&quot;: 42, # The number of the port to expose on the pod&#x27;s IP address. Must be a valid port number, between 1 and 65535 inclusive.
        },
      ],
      &quot;predictRoute&quot;: &quot;A String&quot;, # Immutable. HTTP path on the container to send prediction requests to. Vertex AI forwards requests sent using projects.locations.endpoints.predict to this path on the container&#x27;s IP address and port. Vertex AI then returns the container&#x27;s response in the API response. For example, if you set this field to `/foo`, then when Vertex AI receives a prediction request, it forwards the request body in a POST request to the `/foo` path on the port of your container specified by the first value of this `ModelContainerSpec`&#x27;s ports field. If you don&#x27;t specify this field, it defaults to the following value when you deploy this Model to an Endpoint: /v1/endpoints/ENDPOINT/deployedModels/DEPLOYED_MODEL:predict The placeholders in this value are replaced as follows: * ENDPOINT: The last segment (following `endpoints/`)of the Endpoint.name][] field of the Endpoint where this Model has been deployed. (Vertex AI makes this value available to your container code as the [`AIP_ENDPOINT_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).) * DEPLOYED_MODEL: DeployedModel.id of the `DeployedModel`. (Vertex AI makes this value available to your container code as the [`AIP_DEPLOYED_MODEL_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
      &quot;sharedMemorySizeMb&quot;: &quot;A String&quot;, # Immutable. The amount of the VM memory to reserve as the shared memory for the model in megabytes.
      &quot;startupProbe&quot;: { # Probe describes a health check to be performed against a container to determine whether it is alive or ready to receive traffic. # Immutable. Specification for Kubernetes startup probe.
        &quot;exec&quot;: { # ExecAction specifies a command to execute. # ExecAction probes the health of a container by executing a command.
          &quot;command&quot;: [ # Command is the command line to execute inside the container, the working directory for the command is root (&#x27;/&#x27;) in the container&#x27;s filesystem. The command is simply exec&#x27;d, it is not run inside a shell, so traditional shell instructions (&#x27;|&#x27;, etc) won&#x27;t work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
            &quot;A String&quot;,
          ],
        },
        &quot;failureThreshold&quot;: 42, # Number of consecutive failures before the probe is considered failed. Defaults to 3. Minimum value is 1. Maps to Kubernetes probe argument &#x27;failureThreshold&#x27;.
        &quot;grpc&quot;: { # GrpcAction checks the health of a container using a gRPC service. # GrpcAction probes the health of a container by sending a gRPC request.
          &quot;port&quot;: 42, # Port number of the gRPC service. Number must be in the range 1 to 65535.
          &quot;service&quot;: &quot;A String&quot;, # Service is the name of the service to place in the gRPC HealthCheckRequest (see https://github.com/grpc/grpc/blob/master/doc/health-checking.md). If this is not specified, the default behavior is defined by gRPC.
        },
        &quot;httpGet&quot;: { # HttpGetAction describes an action based on HTTP Get requests. # HttpGetAction probes the health of a container by sending an HTTP GET request.
          &quot;host&quot;: &quot;A String&quot;, # Host name to connect to, defaults to the model serving container&#x27;s IP. You probably want to set &quot;Host&quot; in httpHeaders instead.
          &quot;httpHeaders&quot;: [ # Custom headers to set in the request. HTTP allows repeated headers.
            { # HttpHeader describes a custom header to be used in HTTP probes
              &quot;name&quot;: &quot;A String&quot;, # The header field name. This will be canonicalized upon output, so case-variant names will be understood as the same header.
              &quot;value&quot;: &quot;A String&quot;, # The header field value
            },
          ],
          &quot;path&quot;: &quot;A String&quot;, # Path to access on the HTTP server.
          &quot;port&quot;: 42, # Number of the port to access on the container. Number must be in the range 1 to 65535.
          &quot;scheme&quot;: &quot;A String&quot;, # Scheme to use for connecting to the host. Defaults to HTTP. Acceptable values are &quot;HTTP&quot; or &quot;HTTPS&quot;.
        },
        &quot;initialDelaySeconds&quot;: 42, # Number of seconds to wait before starting the probe. Defaults to 0. Minimum value is 0. Maps to Kubernetes probe argument &#x27;initialDelaySeconds&#x27;.
        &quot;periodSeconds&quot;: 42, # How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1. Must be less than timeout_seconds. Maps to Kubernetes probe argument &#x27;periodSeconds&#x27;.
        &quot;successThreshold&quot;: 42, # Number of consecutive successes before the probe is considered successful. Defaults to 1. Minimum value is 1. Maps to Kubernetes probe argument &#x27;successThreshold&#x27;.
        &quot;tcpSocket&quot;: { # TcpSocketAction probes the health of a container by opening a TCP socket connection. # TcpSocketAction probes the health of a container by opening a TCP socket connection.
          &quot;host&quot;: &quot;A String&quot;, # Optional: Host name to connect to, defaults to the model serving container&#x27;s IP.
          &quot;port&quot;: 42, # Number of the port to access on the container. Number must be in the range 1 to 65535.
        },
        &quot;timeoutSeconds&quot;: 42, # Number of seconds after which the probe times out. Defaults to 1 second. Minimum value is 1. Must be greater or equal to period_seconds. Maps to Kubernetes probe argument &#x27;timeoutSeconds&#x27;.
      },
    },
    &quot;huggingFaceAccessToken&quot;: &quot;A String&quot;, # Optional. The Hugging Face read access token used to access the model artifacts of gated models.
    &quot;huggingFaceCacheEnabled&quot;: True or False, # Optional. If true, the model will deploy with a cached version instead of directly downloading the model artifacts from Hugging Face. This is suitable for VPC-SC users with limited internet access.
    &quot;modelDisplayName&quot;: &quot;A String&quot;, # Optional. The user-specified display name of the uploaded model. If not set, a default name will be used.
  },
  &quot;publisherModelName&quot;: &quot;A String&quot;, # The Model Garden model to deploy. Format: `publishers/{publisher}/models/{publisher_model}@{version_id}`, or `publishers/hf-{hugging-face-author}/models/{hugging-face-model-name}@001`.
}

  x__xgafv: string, V1 error format.
    Allowed values
      1 - v1 error format
      2 - v2 error format

Returns:
  An object of the form:

    { # This resource represents a long-running operation that is the result of a network API call.
  &quot;done&quot;: True or False, # If the value is `false`, it means the operation is still in progress. If `true`, the operation is completed, and either `error` or `response` is available.
  &quot;error&quot;: { # The `Status` type defines a logical error model that is suitable for different programming environments, including REST APIs and RPC APIs. It is used by [gRPC](https://github.com/grpc). Each `Status` message contains three pieces of data: error code, error message, and error details. You can find out more about this error model and how to work with it in the [API Design Guide](https://cloud.google.com/apis/design/errors). # The error result of the operation in case of failure or cancellation.
    &quot;code&quot;: 42, # The status code, which should be an enum value of google.rpc.Code.
    &quot;details&quot;: [ # A list of messages that carry the error details. There is a common set of message types for APIs to use.
      {
        &quot;a_key&quot;: &quot;&quot;, # Properties of the object. Contains field @type with type URL.
      },
    ],
    &quot;message&quot;: &quot;A String&quot;, # A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client.
  },
  &quot;metadata&quot;: { # Service-specific metadata associated with the operation. It typically contains progress information and common metadata such as create time. Some services might not provide such metadata. Any method that returns a long-running operation should document the metadata type, if any.
    &quot;a_key&quot;: &quot;&quot;, # Properties of the object. Contains field @type with type URL.
  },
  &quot;name&quot;: &quot;A String&quot;, # The server-assigned name, which is only unique within the same service that originally returns it. If you use the default HTTP mapping, the `name` should be a resource name ending with `operations/{unique_id}`.
  &quot;response&quot;: { # The normal, successful response of the operation. If the original method returns no data on success, such as `Delete`, the response is `google.protobuf.Empty`. If the original method is standard `Get`/`Create`/`Update`, the response should be the resource. For other methods, the response should have the type `XxxResponse`, where `Xxx` is the original method name. For example, if the original method name is `TakeSnapshot()`, the inferred response type is `TakeSnapshotResponse`.
    &quot;a_key&quot;: &quot;&quot;, # Properties of the object. Contains field @type with type URL.
  },
}</pre>
</div>

<div class="method">
    <code class="details" id="deployPublisherModel">deployPublisherModel(destination, body=None, x__xgafv=None)</code>
  <pre>Deploys publisher models.

Args:
  destination: string, Required. The resource name of the Location to deploy the model in. Format: `projects/{project}/locations/{location}` (required)
  body: object, The request body.
    The object takes the form of:

{ # Request message for ModelGardenService.DeployPublisherModel.
  &quot;acceptEula&quot;: True or False, # Optional. Whether the user accepts the End User License Agreement (EULA) for the model.
  &quot;dedicatedResources&quot;: { # A description of resources that are dedicated to a DeployedModel or DeployedIndex, and that need a higher degree of manual configuration. # Optional. The dedicated resources to use for the endpoint. If not set, the default resources will be used.
    &quot;autoscalingMetricSpecs&quot;: [ # Immutable. The metric specifications that overrides a resource utilization metric (CPU utilization, accelerator&#x27;s duty cycle, and so on) target value (default to 60 if not set). At most one entry is allowed per metric. If machine_spec.accelerator_count is above 0, the autoscaling will be based on both CPU utilization and accelerator&#x27;s duty cycle metrics and scale up when either metrics exceeds its target value while scale down if both metrics are under their target value. The default target value is 60 for both metrics. If machine_spec.accelerator_count is 0, the autoscaling will be based on CPU utilization metric only with default target value 60 if not explicitly set. For example, in the case of Online Prediction, if you want to override target CPU utilization to 80, you should set autoscaling_metric_specs.metric_name to `aiplatform.googleapis.com/prediction/online/cpu/utilization` and autoscaling_metric_specs.target to `80`.
      { # The metric specification that defines the target resource utilization (CPU utilization, accelerator&#x27;s duty cycle, and so on) for calculating the desired replica count.
        &quot;metricName&quot;: &quot;A String&quot;, # Required. The resource metric name. Supported metrics: * For Online Prediction: * `aiplatform.googleapis.com/prediction/online/accelerator/duty_cycle` * `aiplatform.googleapis.com/prediction/online/cpu/utilization`
        &quot;target&quot;: 42, # The target resource utilization in percentage (1% - 100%) for the given metric; once the real usage deviates from the target by a certain percentage, the machine replicas change. The default value is 60 (representing 60%) if not provided.
      },
    ],
    &quot;machineSpec&quot;: { # Specification of a single machine. # Required. Immutable. The specification of a single machine being used.
      &quot;acceleratorCount&quot;: 42, # The number of accelerators to attach to the machine.
      &quot;acceleratorType&quot;: &quot;A String&quot;, # Immutable. The type of accelerator(s) that may be attached to the machine as per accelerator_count.
      &quot;machineType&quot;: &quot;A String&quot;, # Immutable. The type of the machine. See the [list of machine types supported for prediction](https://cloud.google.com/vertex-ai/docs/predictions/configure-compute#machine-types) See the [list of machine types supported for custom training](https://cloud.google.com/vertex-ai/docs/training/configure-compute#machine-types). For DeployedModel this field is optional, and the default value is `n1-standard-2`. For BatchPredictionJob or as part of WorkerPoolSpec this field is required.
      &quot;multihostGpuNodeCount&quot;: 42, # Optional. Immutable. The number of nodes per replica for multihost GPU deployments.
      &quot;reservationAffinity&quot;: { # A ReservationAffinity can be used to configure a Vertex AI resource (e.g., a DeployedModel) to draw its Compute Engine resources from a Shared Reservation, or exclusively from on-demand capacity. # Optional. Immutable. Configuration controlling how this resource pool consumes reservation.
        &quot;key&quot;: &quot;A String&quot;, # Optional. Corresponds to the label key of a reservation resource. To target a SPECIFIC_RESERVATION by name, use `compute.googleapis.com/reservation-name` as the key and specify the name of your reservation as its value.
        &quot;reservationAffinityType&quot;: &quot;A String&quot;, # Required. Specifies the reservation affinity type.
        &quot;values&quot;: [ # Optional. Corresponds to the label values of a reservation resource. This must be the full resource name of the reservation or reservation block.
          &quot;A String&quot;,
        ],
      },
      &quot;tpuTopology&quot;: &quot;A String&quot;, # Immutable. The topology of the TPUs. Corresponds to the TPU topologies available from GKE. (Example: tpu_topology: &quot;2x2x1&quot;).
    },
    &quot;maxReplicaCount&quot;: 42, # Immutable. The maximum number of replicas that may be deployed on when the traffic against it increases. If the requested value is too large, the deployment will error, but if deployment succeeds then the ability to scale to that many replicas is guaranteed (barring service outages). If traffic increases beyond what its replicas at maximum may handle, a portion of the traffic will be dropped. If this value is not provided, will use min_replica_count as the default value. The value of this field impacts the charge against Vertex CPU and GPU quotas. Specifically, you will be charged for (max_replica_count * number of cores in the selected machine type) and (max_replica_count * number of GPUs per replica in the selected machine type).
    &quot;minReplicaCount&quot;: 42, # Required. Immutable. The minimum number of machine replicas that will be always deployed on. This value must be greater than or equal to 1. If traffic increases, it may dynamically be deployed onto more replicas, and as traffic decreases, some of these extra replicas may be freed.
    &quot;requiredReplicaCount&quot;: 42, # Optional. Number of required available replicas for the deployment to succeed. This field is only needed when partial deployment/mutation is desired. If set, the deploy/mutate operation will succeed once available_replica_count reaches required_replica_count, and the rest of the replicas will be retried. If not set, the default required_replica_count will be min_replica_count.
    &quot;spot&quot;: True or False, # Optional. If true, schedule the deployment workload on [spot VMs](https://cloud.google.com/kubernetes-engine/docs/concepts/spot-vms).
  },
  &quot;endpointDisplayName&quot;: &quot;A String&quot;, # Optional. The user-specified display name of the endpoint. If not set, a default name will be used.
  &quot;huggingFaceAccessToken&quot;: &quot;A String&quot;, # Optional. The Hugging Face read access token used to access the model artifacts of gated models.
  &quot;model&quot;: &quot;A String&quot;, # Required. The model to deploy. Format: 1. `publishers/{publisher}/models/{publisher_model}@{version_id}`, or `publishers/hf-{hugging-face-author}/models/{hugging-face-model-name}@001`. 2. Hugging Face model ID like `google/gemma-2-2b-it`. 3. Custom model Google Cloud Storage URI like `gs://bucket`. 4. Custom model zip file like `https://example.com/a.zip`.
  &quot;modelDisplayName&quot;: &quot;A String&quot;, # Optional. The user-specified display name of the uploaded model. If not set, a default name will be used.
}

  x__xgafv: string, V1 error format.
    Allowed values
      1 - v1 error format
      2 - v2 error format

Returns:
  An object of the form:

    { # This resource represents a long-running operation that is the result of a network API call.
  &quot;done&quot;: True or False, # If the value is `false`, it means the operation is still in progress. If `true`, the operation is completed, and either `error` or `response` is available.
  &quot;error&quot;: { # The `Status` type defines a logical error model that is suitable for different programming environments, including REST APIs and RPC APIs. It is used by [gRPC](https://github.com/grpc). Each `Status` message contains three pieces of data: error code, error message, and error details. You can find out more about this error model and how to work with it in the [API Design Guide](https://cloud.google.com/apis/design/errors). # The error result of the operation in case of failure or cancellation.
    &quot;code&quot;: 42, # The status code, which should be an enum value of google.rpc.Code.
    &quot;details&quot;: [ # A list of messages that carry the error details. There is a common set of message types for APIs to use.
      {
        &quot;a_key&quot;: &quot;&quot;, # Properties of the object. Contains field @type with type URL.
      },
    ],
    &quot;message&quot;: &quot;A String&quot;, # A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client.
  },
  &quot;metadata&quot;: { # Service-specific metadata associated with the operation. It typically contains progress information and common metadata such as create time. Some services might not provide such metadata. Any method that returns a long-running operation should document the metadata type, if any.
    &quot;a_key&quot;: &quot;&quot;, # Properties of the object. Contains field @type with type URL.
  },
  &quot;name&quot;: &quot;A String&quot;, # The server-assigned name, which is only unique within the same service that originally returns it. If you use the default HTTP mapping, the `name` should be a resource name ending with `operations/{unique_id}`.
  &quot;response&quot;: { # The normal, successful response of the operation. If the original method returns no data on success, such as `Delete`, the response is `google.protobuf.Empty`. If the original method is standard `Get`/`Create`/`Update`, the response should be the resource. For other methods, the response should have the type `XxxResponse`, where `Xxx` is the original method name. For example, if the original method name is `TakeSnapshot()`, the inferred response type is `TakeSnapshotResponse`.
    &quot;a_key&quot;: &quot;&quot;, # Properties of the object. Contains field @type with type URL.
  },
}</pre>
</div>

<div class="method">
    <code class="details" id="evaluateDataset">evaluateDataset(location, body=None, x__xgafv=None)</code>
  <pre>Evaluates a dataset based on a set of given metrics.

Args:
  location: string, Required. The resource name of the Location to evaluate the dataset. Format: `projects/{project}/locations/{location}` (required)
  body: object, The request body.
    The object takes the form of:

{ # Request message for EvaluationService.EvaluateDataset.
  &quot;autoraterConfig&quot;: { # The configs for autorater. This is applicable to both EvaluateInstances and EvaluateDataset. # Optional. Autorater config used for evaluation.
    &quot;autoraterModel&quot;: &quot;A String&quot;, # Optional. The fully qualified name of the publisher model or tuned autorater endpoint to use. Publisher model format: `projects/{project}/locations/{location}/publishers/*/models/*` Tuned model endpoint format: `projects/{project}/locations/{location}/endpoints/{endpoint}`
    &quot;flipEnabled&quot;: True or False, # Optional. Whether to flip the candidate and baseline responses. This is only applicable to the pairwise metric. If enabled, also provide PairwiseMetricSpec.candidate_response_field_name and PairwiseMetricSpec.baseline_response_field_name. When rendering PairwiseMetricSpec.metric_prompt_template, the candidate and baseline fields will be flipped for half of the samples to reduce bias.
    &quot;samplingCount&quot;: 42, # Optional. Number of samples for each instance in the dataset. If not specified, the default is 4. Minimum value is 1, maximum value is 32.
  },
  &quot;dataset&quot;: { # The dataset used for evaluation. # Required. The dataset used for evaluation.
    &quot;bigquerySource&quot;: { # The BigQuery location for the input content. # BigQuery source holds the dataset.
      &quot;inputUri&quot;: &quot;A String&quot;, # Required. BigQuery URI to a table, up to 2000 characters long. Accepted forms: * BigQuery path. For example: `bq://projectId.bqDatasetId.bqTableId`.
    },
    &quot;gcsSource&quot;: { # The Google Cloud Storage location for the input content. # Cloud storage source holds the dataset.
      &quot;uris&quot;: [ # Required. Google Cloud Storage URI(-s) to the input file(s). May contain wildcards. For more information on wildcards, see https://cloud.google.com/storage/docs/gsutil/addlhelp/WildcardNames.
        &quot;A String&quot;,
      ],
    },
  },
  &quot;metrics&quot;: [ # Required. The metrics used for evaluation.
    { # The metric used for dataset level evaluation.
      &quot;aggregationMetrics&quot;: [ # Optional. The aggregation metrics to use.
        &quot;A String&quot;,
      ],
      &quot;bleuSpec&quot;: { # Spec for bleu score metric - calculates the precision of n-grams in the prediction as compared to reference - returns a score ranging between 0 to 1. # Spec for bleu metric.
        &quot;useEffectiveOrder&quot;: True or False, # Optional. Whether to use_effective_order to compute bleu score.
      },
      &quot;exactMatchSpec&quot;: { # Spec for exact match metric - returns 1 if prediction and reference exactly matches, otherwise 0. # Spec for exact match metric.
      },
      &quot;pairwiseMetricSpec&quot;: { # Spec for pairwise metric. # Spec for pairwise metric.
        &quot;baselineResponseFieldName&quot;: &quot;A String&quot;, # Optional. The field name of the baseline response.
        &quot;candidateResponseFieldName&quot;: &quot;A String&quot;, # Optional. The field name of the candidate response.
        &quot;metricPromptTemplate&quot;: &quot;A String&quot;, # Required. Metric prompt template for pairwise metric.
        &quot;systemInstruction&quot;: &quot;A String&quot;, # Optional. System instructions for pairwise metric.
      },
      &quot;pointwiseMetricSpec&quot;: { # Spec for pointwise metric. # Spec for pointwise metric.
        &quot;metricPromptTemplate&quot;: &quot;A String&quot;, # Required. Metric prompt template for pointwise metric.
        &quot;systemInstruction&quot;: &quot;A String&quot;, # Optional. System instructions for pointwise metric.
      },
      &quot;rougeSpec&quot;: { # Spec for rouge score metric - calculates the recall of n-grams in prediction as compared to reference - returns a score ranging between 0 and 1. # Spec for rouge metric.
        &quot;rougeType&quot;: &quot;A String&quot;, # Optional. Supported rouge types are rougen[1-9], rougeL, and rougeLsum.
        &quot;splitSummaries&quot;: True or False, # Optional. Whether to split summaries while using rougeLsum.
        &quot;useStemmer&quot;: True or False, # Optional. Whether to use stemmer to compute rouge score.
      },
    },
  ],
  &quot;outputConfig&quot;: { # Config for evaluation output. # Required. Config for evaluation output.
    &quot;gcsDestination&quot;: { # The Google Cloud Storage location where the output is to be written to. # Cloud storage destination for evaluation output.
      &quot;outputUriPrefix&quot;: &quot;A String&quot;, # Required. Google Cloud Storage URI to output directory. If the uri doesn&#x27;t end with &#x27;/&#x27;, a &#x27;/&#x27; will be automatically appended. The directory is created if it doesn&#x27;t exist.
    },
  },
}

  x__xgafv: string, V1 error format.
    Allowed values
      1 - v1 error format
      2 - v2 error format

Returns:
  An object of the form:

    { # This resource represents a long-running operation that is the result of a network API call.
  &quot;done&quot;: True or False, # If the value is `false`, it means the operation is still in progress. If `true`, the operation is completed, and either `error` or `response` is available.
  &quot;error&quot;: { # The `Status` type defines a logical error model that is suitable for different programming environments, including REST APIs and RPC APIs. It is used by [gRPC](https://github.com/grpc). Each `Status` message contains three pieces of data: error code, error message, and error details. You can find out more about this error model and how to work with it in the [API Design Guide](https://cloud.google.com/apis/design/errors). # The error result of the operation in case of failure or cancellation.
    &quot;code&quot;: 42, # The status code, which should be an enum value of google.rpc.Code.
    &quot;details&quot;: [ # A list of messages that carry the error details. There is a common set of message types for APIs to use.
      {
        &quot;a_key&quot;: &quot;&quot;, # Properties of the object. Contains field @type with type URL.
      },
    ],
    &quot;message&quot;: &quot;A String&quot;, # A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client.
  },
  &quot;metadata&quot;: { # Service-specific metadata associated with the operation. It typically contains progress information and common metadata such as create time. Some services might not provide such metadata. Any method that returns a long-running operation should document the metadata type, if any.
    &quot;a_key&quot;: &quot;&quot;, # Properties of the object. Contains field @type with type URL.
  },
  &quot;name&quot;: &quot;A String&quot;, # The server-assigned name, which is only unique within the same service that originally returns it. If you use the default HTTP mapping, the `name` should be a resource name ending with `operations/{unique_id}`.
  &quot;response&quot;: { # The normal, successful response of the operation. If the original method returns no data on success, such as `Delete`, the response is `google.protobuf.Empty`. If the original method is standard `Get`/`Create`/`Update`, the response should be the resource. For other methods, the response should have the type `XxxResponse`, where `Xxx` is the original method name. For example, if the original method name is `TakeSnapshot()`, the inferred response type is `TakeSnapshotResponse`.
    &quot;a_key&quot;: &quot;&quot;, # Properties of the object. Contains field @type with type URL.
  },
}</pre>
</div>

<div class="method">
    <code class="details" id="evaluateInstances">evaluateInstances(location, body=None, x__xgafv=None)</code>
  <pre>Evaluates instances based on a given metric.

Args:
  location: string, Required. The resource name of the Location to evaluate the instances. Format: `projects/{project}/locations/{location}` (required)
  body: object, The request body.
    The object takes the form of:

{ # Request message for EvaluationService.EvaluateInstances.
  &quot;autoraterConfig&quot;: { # The configs for autorater. This is applicable to both EvaluateInstances and EvaluateDataset. # Optional. Autorater config used for evaluation.
    &quot;autoraterModel&quot;: &quot;A String&quot;, # Optional. The fully qualified name of the publisher model or tuned autorater endpoint to use. Publisher model format: `projects/{project}/locations/{location}/publishers/*/models/*` Tuned model endpoint format: `projects/{project}/locations/{location}/endpoints/{endpoint}`
    &quot;flipEnabled&quot;: True or False, # Optional. Whether to flip the candidate and baseline responses. This is only applicable to the pairwise metric. If enabled, also provide PairwiseMetricSpec.candidate_response_field_name and PairwiseMetricSpec.baseline_response_field_name. When rendering PairwiseMetricSpec.metric_prompt_template, the candidate and baseline fields will be flipped for half of the samples to reduce bias.
    &quot;samplingCount&quot;: 42, # Optional. Number of samples for each instance in the dataset. If not specified, the default is 4. Minimum value is 1, maximum value is 32.
  },
  &quot;bleuInput&quot;: { # Input for bleu metric. # Instances and metric spec for bleu metric.
    &quot;instances&quot;: [ # Required. Repeated bleu instances.
      { # Spec for bleu instance.
        &quot;prediction&quot;: &quot;A String&quot;, # Required. Output of the evaluated model.
        &quot;reference&quot;: &quot;A String&quot;, # Required. Ground truth used to compare against the prediction.
      },
    ],
    &quot;metricSpec&quot;: { # Spec for bleu score metric - calculates the precision of n-grams in the prediction as compared to reference - returns a score ranging between 0 to 1. # Required. Spec for bleu score metric.
      &quot;useEffectiveOrder&quot;: True or False, # Optional. Whether to use_effective_order to compute bleu score.
    },
  },
  &quot;coherenceInput&quot;: { # Input for coherence metric. # Input for coherence metric.
    &quot;instance&quot;: { # Spec for coherence instance. # Required. Coherence instance.
      &quot;prediction&quot;: &quot;A String&quot;, # Required. Output of the evaluated model.
    },
    &quot;metricSpec&quot;: { # Spec for coherence score metric. # Required. Spec for coherence score metric.
      &quot;version&quot;: 42, # Optional. Which version to use for evaluation.
    },
  },
  &quot;cometInput&quot;: { # Input for Comet metric. # Translation metrics. Input for Comet metric.
    &quot;instance&quot;: { # Spec for Comet instance - The fields used for evaluation are dependent on the comet version. # Required. Comet instance.
      &quot;prediction&quot;: &quot;A String&quot;, # Required. Output of the evaluated model.
      &quot;reference&quot;: &quot;A String&quot;, # Optional. Ground truth used to compare against the prediction.
      &quot;source&quot;: &quot;A String&quot;, # Optional. Source text in original language.
    },
    &quot;metricSpec&quot;: { # Spec for Comet metric. # Required. Spec for comet metric.
      &quot;sourceLanguage&quot;: &quot;A String&quot;, # Optional. Source language in BCP-47 format.
      &quot;targetLanguage&quot;: &quot;A String&quot;, # Optional. Target language in BCP-47 format. Covers both prediction and reference.
      &quot;version&quot;: &quot;A String&quot;, # Required. Which version to use for evaluation.
    },
  },
  &quot;exactMatchInput&quot;: { # Input for exact match metric. # Auto metric instances. Instances and metric spec for exact match metric.
    &quot;instances&quot;: [ # Required. Repeated exact match instances.
      { # Spec for exact match instance.
        &quot;prediction&quot;: &quot;A String&quot;, # Required. Output of the evaluated model.
        &quot;reference&quot;: &quot;A String&quot;, # Required. Ground truth used to compare against the prediction.
      },
    ],
    &quot;metricSpec&quot;: { # Spec for exact match metric - returns 1 if prediction and reference exactly matches, otherwise 0. # Required. Spec for exact match metric.
    },
  },
  &quot;fluencyInput&quot;: { # Input for fluency metric. # LLM-based metric instance. General text generation metrics, applicable to other categories. Input for fluency metric.
    &quot;instance&quot;: { # Spec for fluency instance. # Required. Fluency instance.
      &quot;prediction&quot;: &quot;A String&quot;, # Required. Output of the evaluated model.
    },
    &quot;metricSpec&quot;: { # Spec for fluency score metric. # Required. Spec for fluency score metric.
      &quot;version&quot;: 42, # Optional. Which version to use for evaluation.
    },
  },
  &quot;fulfillmentInput&quot;: { # Input for fulfillment metric. # Input for fulfillment metric.
    &quot;instance&quot;: { # Spec for fulfillment instance. # Required. Fulfillment instance.
      &quot;instruction&quot;: &quot;A String&quot;, # Required. Inference instruction prompt to compare prediction with.
      &quot;prediction&quot;: &quot;A String&quot;, # Required. Output of the evaluated model.
    },
    &quot;metricSpec&quot;: { # Spec for fulfillment metric. # Required. Spec for fulfillment score metric.
      &quot;version&quot;: 42, # Optional. Which version to use for evaluation.
    },
  },
  &quot;groundednessInput&quot;: { # Input for groundedness metric. # Input for groundedness metric.
    &quot;instance&quot;: { # Spec for groundedness instance. # Required. Groundedness instance.
      &quot;context&quot;: &quot;A String&quot;, # Required. Background information provided in context used to compare against the prediction.
      &quot;prediction&quot;: &quot;A String&quot;, # Required. Output of the evaluated model.
    },
    &quot;metricSpec&quot;: { # Spec for groundedness metric. # Required. Spec for groundedness metric.
      &quot;version&quot;: 42, # Optional. Which version to use for evaluation.
    },
  },
  &quot;metricxInput&quot;: { # Input for MetricX metric. # Input for Metricx metric.
    &quot;instance&quot;: { # Spec for MetricX instance - The fields used for evaluation are dependent on the MetricX version. # Required. Metricx instance.
      &quot;prediction&quot;: &quot;A String&quot;, # Required. Output of the evaluated model.
      &quot;reference&quot;: &quot;A String&quot;, # Optional. Ground truth used to compare against the prediction.
      &quot;source&quot;: &quot;A String&quot;, # Optional. Source text in original language.
    },
    &quot;metricSpec&quot;: { # Spec for MetricX metric. # Required. Spec for Metricx metric.
      &quot;sourceLanguage&quot;: &quot;A String&quot;, # Optional. Source language in BCP-47 format.
      &quot;targetLanguage&quot;: &quot;A String&quot;, # Optional. Target language in BCP-47 format. Covers both prediction and reference.
      &quot;version&quot;: &quot;A String&quot;, # Required. Which version to use for evaluation.
    },
  },
  &quot;pairwiseMetricInput&quot;: { # Input for pairwise metric. # Input for pairwise metric.
    &quot;instance&quot;: { # Pairwise metric instance. Usually one instance corresponds to one row in an evaluation dataset. # Required. Pairwise metric instance.
      &quot;jsonInstance&quot;: &quot;A String&quot;, # Instance specified as a json string. String key-value pairs are expected in the json_instance to render PairwiseMetricSpec.instance_prompt_template.
    },
    &quot;metricSpec&quot;: { # Spec for pairwise metric. # Required. Spec for pairwise metric.
      &quot;baselineResponseFieldName&quot;: &quot;A String&quot;, # Optional. The field name of the baseline response.
      &quot;candidateResponseFieldName&quot;: &quot;A String&quot;, # Optional. The field name of the candidate response.
      &quot;metricPromptTemplate&quot;: &quot;A String&quot;, # Required. Metric prompt template for pairwise metric.
      &quot;systemInstruction&quot;: &quot;A String&quot;, # Optional. System instructions for pairwise metric.
    },
  },
  &quot;pairwiseQuestionAnsweringQualityInput&quot;: { # Input for pairwise question answering quality metric. # Input for pairwise question answering quality metric.
    &quot;instance&quot;: { # Spec for pairwise question answering quality instance. # Required. Pairwise question answering quality instance.
      &quot;baselinePrediction&quot;: &quot;A String&quot;, # Required. Output of the baseline model.
      &quot;context&quot;: &quot;A String&quot;, # Required. Text to answer the question.
      &quot;instruction&quot;: &quot;A String&quot;, # Required. Question Answering prompt for LLM.
      &quot;prediction&quot;: &quot;A String&quot;, # Required. Output of the candidate model.
      &quot;reference&quot;: &quot;A String&quot;, # Optional. Ground truth used to compare against the prediction.
    },
    &quot;metricSpec&quot;: { # Spec for pairwise question answering quality score metric. # Required. Spec for pairwise question answering quality score metric.
      &quot;useReference&quot;: True or False, # Optional. Whether to use instance.reference to compute question answering quality.
      &quot;version&quot;: 42, # Optional. Which version to use for evaluation.
    },
  },
  &quot;pairwiseSummarizationQualityInput&quot;: { # Input for pairwise summarization quality metric. # Input for pairwise summarization quality metric.
    &quot;instance&quot;: { # Spec for pairwise summarization quality instance. # Required. Pairwise summarization quality instance.
      &quot;baselinePrediction&quot;: &quot;A String&quot;, # Required. Output of the baseline model.
      &quot;context&quot;: &quot;A String&quot;, # Required. Text to be summarized.
      &quot;instruction&quot;: &quot;A String&quot;, # Required. Summarization prompt for LLM.
      &quot;prediction&quot;: &quot;A String&quot;, # Required. Output of the candidate model.
      &quot;reference&quot;: &quot;A String&quot;, # Optional. Ground truth used to compare against the prediction.
    },
    &quot;metricSpec&quot;: { # Spec for pairwise summarization quality score metric. # Required. Spec for pairwise summarization quality score metric.
      &quot;useReference&quot;: True or False, # Optional. Whether to use instance.reference to compute pairwise summarization quality.
      &quot;version&quot;: 42, # Optional. Which version to use for evaluation.
    },
  },
  &quot;pointwiseMetricInput&quot;: { # Input for pointwise metric. # Input for pointwise metric.
    &quot;instance&quot;: { # Pointwise metric instance. Usually one instance corresponds to one row in an evaluation dataset. # Required. Pointwise metric instance.
      &quot;jsonInstance&quot;: &quot;A String&quot;, # Instance specified as a json string. String key-value pairs are expected in the json_instance to render PointwiseMetricSpec.instance_prompt_template.
    },
    &quot;metricSpec&quot;: { # Spec for pointwise metric. # Required. Spec for pointwise metric.
      &quot;metricPromptTemplate&quot;: &quot;A String&quot;, # Required. Metric prompt template for pointwise metric.
      &quot;systemInstruction&quot;: &quot;A String&quot;, # Optional. System instructions for pointwise metric.
    },
  },
  &quot;questionAnsweringCorrectnessInput&quot;: { # Input for question answering correctness metric. # Input for question answering correctness metric.
    &quot;instance&quot;: { # Spec for question answering correctness instance. # Required. Question answering correctness instance.
      &quot;context&quot;: &quot;A String&quot;, # Optional. Text provided as context to answer the question.
      &quot;instruction&quot;: &quot;A String&quot;, # Required. The question asked and other instruction in the inference prompt.
      &quot;prediction&quot;: &quot;A String&quot;, # Required. Output of the evaluated model.
      &quot;reference&quot;: &quot;A String&quot;, # Optional. Ground truth used to compare against the prediction.
    },
    &quot;metricSpec&quot;: { # Spec for question answering correctness metric. # Required. Spec for question answering correctness score metric.
      &quot;useReference&quot;: True or False, # Optional. Whether to use instance.reference to compute question answering correctness.
      &quot;version&quot;: 42, # Optional. Which version to use for evaluation.
    },
  },
  &quot;questionAnsweringHelpfulnessInput&quot;: { # Input for question answering helpfulness metric. # Input for question answering helpfulness metric.
    &quot;instance&quot;: { # Spec for question answering helpfulness instance. # Required. Question answering helpfulness instance.
      &quot;context&quot;: &quot;A String&quot;, # Optional. Text provided as context to answer the question.
      &quot;instruction&quot;: &quot;A String&quot;, # Required. The question asked and other instruction in the inference prompt.
      &quot;prediction&quot;: &quot;A String&quot;, # Required. Output of the evaluated model.
      &quot;reference&quot;: &quot;A String&quot;, # Optional. Ground truth used to compare against the prediction.
    },
    &quot;metricSpec&quot;: { # Spec for question answering helpfulness metric. # Required. Spec for question answering helpfulness score metric.
      &quot;useReference&quot;: True or False, # Optional. Whether to use instance.reference to compute question answering helpfulness.
      &quot;version&quot;: 42, # Optional. Which version to use for evaluation.
    },
  },
  &quot;questionAnsweringQualityInput&quot;: { # Input for question answering quality metric. # Input for question answering quality metric.
    &quot;instance&quot;: { # Spec for question answering quality instance. # Required. Question answering quality instance.
      &quot;context&quot;: &quot;A String&quot;, # Required. Text to answer the question.
      &quot;instruction&quot;: &quot;A String&quot;, # Required. Question Answering prompt for LLM.
      &quot;prediction&quot;: &quot;A String&quot;, # Required. Output of the evaluated model.
      &quot;reference&quot;: &quot;A String&quot;, # Optional. Ground truth used to compare against the prediction.
    },
    &quot;metricSpec&quot;: { # Spec for question answering quality score metric. # Required. Spec for question answering quality score metric.
      &quot;useReference&quot;: True or False, # Optional. Whether to use instance.reference to compute question answering quality.
      &quot;version&quot;: 42, # Optional. Which version to use for evaluation.
    },
  },
  &quot;questionAnsweringRelevanceInput&quot;: { # Input for question answering relevance metric. # Input for question answering relevance metric.
    &quot;instance&quot;: { # Spec for question answering relevance instance. # Required. Question answering relevance instance.
      &quot;context&quot;: &quot;A String&quot;, # Optional. Text provided as context to answer the question.
      &quot;instruction&quot;: &quot;A String&quot;, # Required. The question asked and other instruction in the inference prompt.
      &quot;prediction&quot;: &quot;A String&quot;, # Required. Output of the evaluated model.
      &quot;reference&quot;: &quot;A String&quot;, # Optional. Ground truth used to compare against the prediction.
    },
    &quot;metricSpec&quot;: { # Spec for question answering relevance metric. # Required. Spec for question answering relevance score metric.
      &quot;useReference&quot;: True or False, # Optional. Whether to use instance.reference to compute question answering relevance.
      &quot;version&quot;: 42, # Optional. Which version to use for evaluation.
    },
  },
  &quot;rougeInput&quot;: { # Input for rouge metric. # Instances and metric spec for rouge metric.
    &quot;instances&quot;: [ # Required. Repeated rouge instances.
      { # Spec for rouge instance.
        &quot;prediction&quot;: &quot;A String&quot;, # Required. Output of the evaluated model.
        &quot;reference&quot;: &quot;A String&quot;, # Required. Ground truth used to compare against the prediction.
      },
    ],
    &quot;metricSpec&quot;: { # Spec for rouge score metric - calculates the recall of n-grams in prediction as compared to reference - returns a score ranging between 0 and 1. # Required. Spec for rouge score metric.
      &quot;rougeType&quot;: &quot;A String&quot;, # Optional. Supported rouge types are rougen[1-9], rougeL, and rougeLsum.
      &quot;splitSummaries&quot;: True or False, # Optional. Whether to split summaries while using rougeLsum.
      &quot;useStemmer&quot;: True or False, # Optional. Whether to use stemmer to compute rouge score.
    },
  },
  &quot;safetyInput&quot;: { # Input for safety metric. # Input for safety metric.
    &quot;instance&quot;: { # Spec for safety instance. # Required. Safety instance.
      &quot;prediction&quot;: &quot;A String&quot;, # Required. Output of the evaluated model.
    },
    &quot;metricSpec&quot;: { # Spec for safety metric. # Required. Spec for safety metric.
      &quot;version&quot;: 42, # Optional. Which version to use for evaluation.
    },
  },
  &quot;summarizationHelpfulnessInput&quot;: { # Input for summarization helpfulness metric. # Input for summarization helpfulness metric.
    &quot;instance&quot;: { # Spec for summarization helpfulness instance. # Required. Summarization helpfulness instance.
      &quot;context&quot;: &quot;A String&quot;, # Required. Text to be summarized.
      &quot;instruction&quot;: &quot;A String&quot;, # Optional. Summarization prompt for LLM.
      &quot;prediction&quot;: &quot;A String&quot;, # Required. Output of the evaluated model.
      &quot;reference&quot;: &quot;A String&quot;, # Optional. Ground truth used to compare against the prediction.
    },
    &quot;metricSpec&quot;: { # Spec for summarization helpfulness score metric. # Required. Spec for summarization helpfulness score metric.
      &quot;useReference&quot;: True or False, # Optional. Whether to use instance.reference to compute summarization helpfulness.
      &quot;version&quot;: 42, # Optional. Which version to use for evaluation.
    },
  },
  &quot;summarizationQualityInput&quot;: { # Input for summarization quality metric. # Input for summarization quality metric.
    &quot;instance&quot;: { # Spec for summarization quality instance. # Required. Summarization quality instance.
      &quot;context&quot;: &quot;A String&quot;, # Required. Text to be summarized.
      &quot;instruction&quot;: &quot;A String&quot;, # Required. Summarization prompt for LLM.
      &quot;prediction&quot;: &quot;A String&quot;, # Required. Output of the evaluated model.
      &quot;reference&quot;: &quot;A String&quot;, # Optional. Ground truth used to compare against the prediction.
    },
    &quot;metricSpec&quot;: { # Spec for summarization quality score metric. # Required. Spec for summarization quality score metric.
      &quot;useReference&quot;: True or False, # Optional. Whether to use instance.reference to compute summarization quality.
      &quot;version&quot;: 42, # Optional. Which version to use for evaluation.
    },
  },
  &quot;summarizationVerbosityInput&quot;: { # Input for summarization verbosity metric. # Input for summarization verbosity metric.
    &quot;instance&quot;: { # Spec for summarization verbosity instance. # Required. Summarization verbosity instance.
      &quot;context&quot;: &quot;A String&quot;, # Required. Text to be summarized.
      &quot;instruction&quot;: &quot;A String&quot;, # Optional. Summarization prompt for LLM.
      &quot;prediction&quot;: &quot;A String&quot;, # Required. Output of the evaluated model.
      &quot;reference&quot;: &quot;A String&quot;, # Optional. Ground truth used to compare against the prediction.
    },
    &quot;metricSpec&quot;: { # Spec for summarization verbosity score metric. # Required. Spec for summarization verbosity score metric.
      &quot;useReference&quot;: True or False, # Optional. Whether to use instance.reference to compute summarization verbosity.
      &quot;version&quot;: 42, # Optional. Which version to use for evaluation.
    },
  },
  &quot;toolCallValidInput&quot;: { # Input for tool call valid metric. # Tool call metric instances. Input for tool call valid metric.
    &quot;instances&quot;: [ # Required. Repeated tool call valid instances.
      { # Spec for tool call valid instance.
        &quot;prediction&quot;: &quot;A String&quot;, # Required. Output of the evaluated model.
        &quot;reference&quot;: &quot;A String&quot;, # Required. Ground truth used to compare against the prediction.
      },
    ],
    &quot;metricSpec&quot;: { # Spec for tool call valid metric. # Required. Spec for tool call valid metric.
    },
  },
  &quot;toolNameMatchInput&quot;: { # Input for tool name match metric. # Input for tool name match metric.
    &quot;instances&quot;: [ # Required. Repeated tool name match instances.
      { # Spec for tool name match instance.
        &quot;prediction&quot;: &quot;A String&quot;, # Required. Output of the evaluated model.
        &quot;reference&quot;: &quot;A String&quot;, # Required. Ground truth used to compare against the prediction.
      },
    ],
    &quot;metricSpec&quot;: { # Spec for tool name match metric. # Required. Spec for tool name match metric.
    },
  },
  &quot;toolParameterKeyMatchInput&quot;: { # Input for tool parameter key match metric. # Input for tool parameter key match metric.
    &quot;instances&quot;: [ # Required. Repeated tool parameter key match instances.
      { # Spec for tool parameter key match instance.
        &quot;prediction&quot;: &quot;A String&quot;, # Required. Output of the evaluated model.
        &quot;reference&quot;: &quot;A String&quot;, # Required. Ground truth used to compare against the prediction.
      },
    ],
    &quot;metricSpec&quot;: { # Spec for tool parameter key match metric. # Required. Spec for tool parameter key match metric.
    },
  },
  &quot;toolParameterKvMatchInput&quot;: { # Input for tool parameter key value match metric. # Input for tool parameter key value match metric.
    &quot;instances&quot;: [ # Required. Repeated tool parameter key value match instances.
      { # Spec for tool parameter key value match instance.
        &quot;prediction&quot;: &quot;A String&quot;, # Required. Output of the evaluated model.
        &quot;reference&quot;: &quot;A String&quot;, # Required. Ground truth used to compare against the prediction.
      },
    ],
    &quot;metricSpec&quot;: { # Spec for tool parameter key value match metric. # Required. Spec for tool parameter key value match metric.
      &quot;useStrictStringMatch&quot;: True or False, # Optional. Whether to use STRICT string match on parameter values.
    },
  },
  &quot;trajectoryAnyOrderMatchInput&quot;: { # Instances and metric spec for TrajectoryAnyOrderMatch metric. # Input for trajectory match any order metric.
    &quot;instances&quot;: [ # Required. Repeated TrajectoryAnyOrderMatch instance.
      { # Spec for TrajectoryAnyOrderMatch instance.
        &quot;predictedTrajectory&quot;: { # Spec for trajectory. # Required. Spec for predicted tool call trajectory.
          &quot;toolCalls&quot;: [ # Required. Tool calls in the trajectory.
            { # Spec for tool call.
              &quot;toolInput&quot;: &quot;A String&quot;, # Optional. Spec for tool input
              &quot;toolName&quot;: &quot;A String&quot;, # Required. Spec for tool name
            },
          ],
        },
        &quot;referenceTrajectory&quot;: { # Spec for trajectory. # Required. Spec for reference tool call trajectory.
          &quot;toolCalls&quot;: [ # Required. Tool calls in the trajectory.
            { # Spec for tool call.
              &quot;toolInput&quot;: &quot;A String&quot;, # Optional. Spec for tool input
              &quot;toolName&quot;: &quot;A String&quot;, # Required. Spec for tool name
            },
          ],
        },
      },
    ],
    &quot;metricSpec&quot;: { # Spec for TrajectoryAnyOrderMatch metric - returns 1 if all tool calls in the reference trajectory appear in the predicted trajectory in any order, else 0. # Required. Spec for TrajectoryAnyOrderMatch metric.
    },
  },
  &quot;trajectoryExactMatchInput&quot;: { # Instances and metric spec for TrajectoryExactMatch metric. # Input for trajectory exact match metric.
    &quot;instances&quot;: [ # Required. Repeated TrajectoryExactMatch instance.
      { # Spec for TrajectoryExactMatch instance.
        &quot;predictedTrajectory&quot;: { # Spec for trajectory. # Required. Spec for predicted tool call trajectory.
          &quot;toolCalls&quot;: [ # Required. Tool calls in the trajectory.
            { # Spec for tool call.
              &quot;toolInput&quot;: &quot;A String&quot;, # Optional. Spec for tool input
              &quot;toolName&quot;: &quot;A String&quot;, # Required. Spec for tool name
            },
          ],
        },
        &quot;referenceTrajectory&quot;: { # Spec for trajectory. # Required. Spec for reference tool call trajectory.
          &quot;toolCalls&quot;: [ # Required. Tool calls in the trajectory.
            { # Spec for tool call.
              &quot;toolInput&quot;: &quot;A String&quot;, # Optional. Spec for tool input
              &quot;toolName&quot;: &quot;A String&quot;, # Required. Spec for tool name
            },
          ],
        },
      },
    ],
    &quot;metricSpec&quot;: { # Spec for TrajectoryExactMatch metric - returns 1 if tool calls in the reference trajectory exactly match the predicted trajectory, else 0. # Required. Spec for TrajectoryExactMatch metric.
    },
  },
  &quot;trajectoryInOrderMatchInput&quot;: { # Instances and metric spec for TrajectoryInOrderMatch metric. # Input for trajectory in order match metric.
    &quot;instances&quot;: [ # Required. Repeated TrajectoryInOrderMatch instance.
      { # Spec for TrajectoryInOrderMatch instance.
        &quot;predictedTrajectory&quot;: { # Spec for trajectory. # Required. Spec for predicted tool call trajectory.
          &quot;toolCalls&quot;: [ # Required. Tool calls in the trajectory.
            { # Spec for tool call.
              &quot;toolInput&quot;: &quot;A String&quot;, # Optional. Spec for tool input
              &quot;toolName&quot;: &quot;A String&quot;, # Required. Spec for tool name
            },
          ],
        },
        &quot;referenceTrajectory&quot;: { # Spec for trajectory. # Required. Spec for reference tool call trajectory.
          &quot;toolCalls&quot;: [ # Required. Tool calls in the trajectory.
            { # Spec for tool call.
              &quot;toolInput&quot;: &quot;A String&quot;, # Optional. Spec for tool input
              &quot;toolName&quot;: &quot;A String&quot;, # Required. Spec for tool name
            },
          ],
        },
      },
    ],
    &quot;metricSpec&quot;: { # Spec for TrajectoryInOrderMatch metric - returns 1 if tool calls in the reference trajectory appear in the predicted trajectory in the same order, else 0. # Required. Spec for TrajectoryInOrderMatch metric.
    },
  },
  &quot;trajectoryPrecisionInput&quot;: { # Instances and metric spec for TrajectoryPrecision metric. # Input for trajectory precision metric.
    &quot;instances&quot;: [ # Required. Repeated TrajectoryPrecision instance.
      { # Spec for TrajectoryPrecision instance.
        &quot;predictedTrajectory&quot;: { # Spec for trajectory. # Required. Spec for predicted tool call trajectory.
          &quot;toolCalls&quot;: [ # Required. Tool calls in the trajectory.
            { # Spec for tool call.
              &quot;toolInput&quot;: &quot;A String&quot;, # Optional. Spec for tool input
              &quot;toolName&quot;: &quot;A String&quot;, # Required. Spec for tool name
            },
          ],
        },
        &quot;referenceTrajectory&quot;: { # Spec for trajectory. # Required. Spec for reference tool call trajectory.
          &quot;toolCalls&quot;: [ # Required. Tool calls in the trajectory.
            { # Spec for tool call.
              &quot;toolInput&quot;: &quot;A String&quot;, # Optional. Spec for tool input
              &quot;toolName&quot;: &quot;A String&quot;, # Required. Spec for tool name
            },
          ],
        },
      },
    ],
    &quot;metricSpec&quot;: { # Spec for TrajectoryPrecision metric - returns a float score based on average precision of individual tool calls. # Required. Spec for TrajectoryPrecision metric.
    },
  },
  &quot;trajectoryRecallInput&quot;: { # Instances and metric spec for TrajectoryRecall metric. # Input for trajectory recall metric.
    &quot;instances&quot;: [ # Required. Repeated TrajectoryRecall instance.
      { # Spec for TrajectoryRecall instance.
        &quot;predictedTrajectory&quot;: { # Spec for trajectory. # Required. Spec for predicted tool call trajectory.
          &quot;toolCalls&quot;: [ # Required. Tool calls in the trajectory.
            { # Spec for tool call.
              &quot;toolInput&quot;: &quot;A String&quot;, # Optional. Spec for tool input
              &quot;toolName&quot;: &quot;A String&quot;, # Required. Spec for tool name
            },
          ],
        },
        &quot;referenceTrajectory&quot;: { # Spec for trajectory. # Required. Spec for reference tool call trajectory.
          &quot;toolCalls&quot;: [ # Required. Tool calls in the trajectory.
            { # Spec for tool call.
              &quot;toolInput&quot;: &quot;A String&quot;, # Optional. Spec for tool input
              &quot;toolName&quot;: &quot;A String&quot;, # Required. Spec for tool name
            },
          ],
        },
      },
    ],
    &quot;metricSpec&quot;: { # Spec for TrajectoryRecall metric - returns a float score based on average recall of individual tool calls. # Required. Spec for TrajectoryRecall metric.
    },
  },
  &quot;trajectorySingleToolUseInput&quot;: { # Instances and metric spec for TrajectorySingleToolUse metric. # Input for trajectory single tool use metric.
    &quot;instances&quot;: [ # Required. Repeated TrajectorySingleToolUse instance.
      { # Spec for TrajectorySingleToolUse instance.
        &quot;predictedTrajectory&quot;: { # Spec for trajectory. # Required. Spec for predicted tool call trajectory.
          &quot;toolCalls&quot;: [ # Required. Tool calls in the trajectory.
            { # Spec for tool call.
              &quot;toolInput&quot;: &quot;A String&quot;, # Optional. Spec for tool input
              &quot;toolName&quot;: &quot;A String&quot;, # Required. Spec for tool name
            },
          ],
        },
      },
    ],
    &quot;metricSpec&quot;: { # Spec for TrajectorySingleToolUse metric - returns 1 if tool is present in the predicted trajectory, else 0. # Required. Spec for TrajectorySingleToolUse metric.
      &quot;toolName&quot;: &quot;A String&quot;, # Required. Spec for tool name to be checked for in the predicted trajectory.
    },
  },
}

  x__xgafv: string, V1 error format.
    Allowed values
      1 - v1 error format
      2 - v2 error format

Returns:
  An object of the form:

    { # Response message for EvaluationService.EvaluateInstances.
  &quot;bleuResults&quot;: { # Results for bleu metric. # Results for bleu metric.
    &quot;bleuMetricValues&quot;: [ # Output only. Bleu metric values.
      { # Bleu metric value for an instance.
        &quot;score&quot;: 3.14, # Output only. Bleu score.
      },
    ],
  },
  &quot;coherenceResult&quot;: { # Spec for coherence result. # Result for coherence metric.
    &quot;confidence&quot;: 3.14, # Output only. Confidence for coherence score.
    &quot;explanation&quot;: &quot;A String&quot;, # Output only. Explanation for coherence score.
    &quot;score&quot;: 3.14, # Output only. Coherence score.
  },
  &quot;cometResult&quot;: { # Spec for Comet result - calculates the comet score for the given instance using the version specified in the spec. # Translation metrics. Result for Comet metric.
    &quot;score&quot;: 3.14, # Output only. Comet score. Range depends on version.
  },
  &quot;exactMatchResults&quot;: { # Results for exact match metric. # Auto metric evaluation results. Results for exact match metric.
    &quot;exactMatchMetricValues&quot;: [ # Output only. Exact match metric values.
      { # Exact match metric value for an instance.
        &quot;score&quot;: 3.14, # Output only. Exact match score.
      },
    ],
  },
  &quot;fluencyResult&quot;: { # Spec for fluency result. # LLM-based metric evaluation result. General text generation metrics, applicable to other categories. Result for fluency metric.
    &quot;confidence&quot;: 3.14, # Output only. Confidence for fluency score.
    &quot;explanation&quot;: &quot;A String&quot;, # Output only. Explanation for fluency score.
    &quot;score&quot;: 3.14, # Output only. Fluency score.
  },
  &quot;fulfillmentResult&quot;: { # Spec for fulfillment result. # Result for fulfillment metric.
    &quot;confidence&quot;: 3.14, # Output only. Confidence for fulfillment score.
    &quot;explanation&quot;: &quot;A String&quot;, # Output only. Explanation for fulfillment score.
    &quot;score&quot;: 3.14, # Output only. Fulfillment score.
  },
  &quot;groundednessResult&quot;: { # Spec for groundedness result. # Result for groundedness metric.
    &quot;confidence&quot;: 3.14, # Output only. Confidence for groundedness score.
    &quot;explanation&quot;: &quot;A String&quot;, # Output only. Explanation for groundedness score.
    &quot;score&quot;: 3.14, # Output only. Groundedness score.
  },
  &quot;metricxResult&quot;: { # Spec for MetricX result - calculates the MetricX score for the given instance using the version specified in the spec. # Result for Metricx metric.
    &quot;score&quot;: 3.14, # Output only. MetricX score. Range depends on version.
  },
  &quot;pairwiseMetricResult&quot;: { # Spec for pairwise metric result. # Result for pairwise metric.
    &quot;explanation&quot;: &quot;A String&quot;, # Output only. Explanation for pairwise metric score.
    &quot;pairwiseChoice&quot;: &quot;A String&quot;, # Output only. Pairwise metric choice.
  },
  &quot;pairwiseQuestionAnsweringQualityResult&quot;: { # Spec for pairwise question answering quality result. # Result for pairwise question answering quality metric.
    &quot;confidence&quot;: 3.14, # Output only. Confidence for question answering quality score.
    &quot;explanation&quot;: &quot;A String&quot;, # Output only. Explanation for question answering quality score.
    &quot;pairwiseChoice&quot;: &quot;A String&quot;, # Output only. Pairwise question answering prediction choice.
  },
  &quot;pairwiseSummarizationQualityResult&quot;: { # Spec for pairwise summarization quality result. # Result for pairwise summarization quality metric.
    &quot;confidence&quot;: 3.14, # Output only. Confidence for summarization quality score.
    &quot;explanation&quot;: &quot;A String&quot;, # Output only. Explanation for summarization quality score.
    &quot;pairwiseChoice&quot;: &quot;A String&quot;, # Output only. Pairwise summarization prediction choice.
  },
  &quot;pointwiseMetricResult&quot;: { # Spec for pointwise metric result. # Generic metrics. Result for pointwise metric.
    &quot;explanation&quot;: &quot;A String&quot;, # Output only. Explanation for pointwise metric score.
    &quot;score&quot;: 3.14, # Output only. Pointwise metric score.
  },
  &quot;questionAnsweringCorrectnessResult&quot;: { # Spec for question answering correctness result. # Result for question answering correctness metric.
    &quot;confidence&quot;: 3.14, # Output only. Confidence for question answering correctness score.
    &quot;explanation&quot;: &quot;A String&quot;, # Output only. Explanation for question answering correctness score.
    &quot;score&quot;: 3.14, # Output only. Question Answering Correctness score.
  },
  &quot;questionAnsweringHelpfulnessResult&quot;: { # Spec for question answering helpfulness result. # Result for question answering helpfulness metric.
    &quot;confidence&quot;: 3.14, # Output only. Confidence for question answering helpfulness score.
    &quot;explanation&quot;: &quot;A String&quot;, # Output only. Explanation for question answering helpfulness score.
    &quot;score&quot;: 3.14, # Output only. Question Answering Helpfulness score.
  },
  &quot;questionAnsweringQualityResult&quot;: { # Spec for question answering quality result. # Question answering only metrics. Result for question answering quality metric.
    &quot;confidence&quot;: 3.14, # Output only. Confidence for question answering quality score.
    &quot;explanation&quot;: &quot;A String&quot;, # Output only. Explanation for question answering quality score.
    &quot;score&quot;: 3.14, # Output only. Question Answering Quality score.
  },
  &quot;questionAnsweringRelevanceResult&quot;: { # Spec for question answering relevance result. # Result for question answering relevance metric.
    &quot;confidence&quot;: 3.14, # Output only. Confidence for question answering relevance score.
    &quot;explanation&quot;: &quot;A String&quot;, # Output only. Explanation for question answering relevance score.
    &quot;score&quot;: 3.14, # Output only. Question Answering Relevance score.
  },
  &quot;rougeResults&quot;: { # Results for rouge metric. # Results for rouge metric.
    &quot;rougeMetricValues&quot;: [ # Output only. Rouge metric values.
      { # Rouge metric value for an instance.
        &quot;score&quot;: 3.14, # Output only. Rouge score.
      },
    ],
  },
  &quot;safetyResult&quot;: { # Spec for safety result. # Result for safety metric.
    &quot;confidence&quot;: 3.14, # Output only. Confidence for safety score.
    &quot;explanation&quot;: &quot;A String&quot;, # Output only. Explanation for safety score.
    &quot;score&quot;: 3.14, # Output only. Safety score.
  },
  &quot;summarizationHelpfulnessResult&quot;: { # Spec for summarization helpfulness result. # Result for summarization helpfulness metric.
    &quot;confidence&quot;: 3.14, # Output only. Confidence for summarization helpfulness score.
    &quot;explanation&quot;: &quot;A String&quot;, # Output only. Explanation for summarization helpfulness score.
    &quot;score&quot;: 3.14, # Output only. Summarization Helpfulness score.
  },
  &quot;summarizationQualityResult&quot;: { # Spec for summarization quality result. # Summarization only metrics. Result for summarization quality metric.
    &quot;confidence&quot;: 3.14, # Output only. Confidence for summarization quality score.
    &quot;explanation&quot;: &quot;A String&quot;, # Output only. Explanation for summarization quality score.
    &quot;score&quot;: 3.14, # Output only. Summarization Quality score.
  },
  &quot;summarizationVerbosityResult&quot;: { # Spec for summarization verbosity result. # Result for summarization verbosity metric.
    &quot;confidence&quot;: 3.14, # Output only. Confidence for summarization verbosity score.
    &quot;explanation&quot;: &quot;A String&quot;, # Output only. Explanation for summarization verbosity score.
    &quot;score&quot;: 3.14, # Output only. Summarization Verbosity score.
  },
  &quot;toolCallValidResults&quot;: { # Results for tool call valid metric. # Tool call metrics. Results for tool call valid metric.
    &quot;toolCallValidMetricValues&quot;: [ # Output only. Tool call valid metric values.
      { # Tool call valid metric value for an instance.
        &quot;score&quot;: 3.14, # Output only. Tool call valid score.
      },
    ],
  },
  &quot;toolNameMatchResults&quot;: { # Results for tool name match metric. # Results for tool name match metric.
    &quot;toolNameMatchMetricValues&quot;: [ # Output only. Tool name match metric values.
      { # Tool name match metric value for an instance.
        &quot;score&quot;: 3.14, # Output only. Tool name match score.
      },
    ],
  },
  &quot;toolParameterKeyMatchResults&quot;: { # Results for tool parameter key match metric. # Results for tool parameter key match metric.
    &quot;toolParameterKeyMatchMetricValues&quot;: [ # Output only. Tool parameter key match metric values.
      { # Tool parameter key match metric value for an instance.
        &quot;score&quot;: 3.14, # Output only. Tool parameter key match score.
      },
    ],
  },
  &quot;toolParameterKvMatchResults&quot;: { # Results for tool parameter key value match metric. # Results for tool parameter key value match metric.
    &quot;toolParameterKvMatchMetricValues&quot;: [ # Output only. Tool parameter key value match metric values.
      { # Tool parameter key value match metric value for an instance.
        &quot;score&quot;: 3.14, # Output only. Tool parameter key value match score.
      },
    ],
  },
  &quot;trajectoryAnyOrderMatchResults&quot;: { # Results for TrajectoryAnyOrderMatch metric. # Result for trajectory any order match metric.
    &quot;trajectoryAnyOrderMatchMetricValues&quot;: [ # Output only. TrajectoryAnyOrderMatch metric values.
      { # TrajectoryAnyOrderMatch metric value for an instance.
        &quot;score&quot;: 3.14, # Output only. TrajectoryAnyOrderMatch score.
      },
    ],
  },
  &quot;trajectoryExactMatchResults&quot;: { # Results for TrajectoryExactMatch metric. # Result for trajectory exact match metric.
    &quot;trajectoryExactMatchMetricValues&quot;: [ # Output only. TrajectoryExactMatch metric values.
      { # TrajectoryExactMatch metric value for an instance.
        &quot;score&quot;: 3.14, # Output only. TrajectoryExactMatch score.
      },
    ],
  },
  &quot;trajectoryInOrderMatchResults&quot;: { # Results for TrajectoryInOrderMatch metric. # Result for trajectory in order match metric.
    &quot;trajectoryInOrderMatchMetricValues&quot;: [ # Output only. TrajectoryInOrderMatch metric values.
      { # TrajectoryInOrderMatch metric value for an instance.
        &quot;score&quot;: 3.14, # Output only. TrajectoryInOrderMatch score.
      },
    ],
  },
  &quot;trajectoryPrecisionResults&quot;: { # Results for TrajectoryPrecision metric. # Result for trajectory precision metric.
    &quot;trajectoryPrecisionMetricValues&quot;: [ # Output only. TrajectoryPrecision metric values.
      { # TrajectoryPrecision metric value for an instance.
        &quot;score&quot;: 3.14, # Output only. TrajectoryPrecision score.
      },
    ],
  },
  &quot;trajectoryRecallResults&quot;: { # Results for TrajectoryRecall metric. # Results for trajectory recall metric.
    &quot;trajectoryRecallMetricValues&quot;: [ # Output only. TrajectoryRecall metric values.
      { # TrajectoryRecall metric value for an instance.
        &quot;score&quot;: 3.14, # Output only. TrajectoryRecall score.
      },
    ],
  },
  &quot;trajectorySingleToolUseResults&quot;: { # Results for TrajectorySingleToolUse metric. # Results for trajectory single tool use metric.
    &quot;trajectorySingleToolUseMetricValues&quot;: [ # Output only. TrajectorySingleToolUse metric values.
      { # TrajectorySingleToolUse metric value for an instance.
        &quot;score&quot;: 3.14, # Output only. TrajectorySingleToolUse score.
      },
    ],
  },
}</pre>
</div>

<div class="method">
    <code class="details" id="get">get(name, x__xgafv=None)</code>
  <pre>Gets information about a location.

Args:
  name: string, Resource name for the location. (required)
  x__xgafv: string, V1 error format.
    Allowed values
      1 - v1 error format
      2 - v2 error format

Returns:
  An object of the form:

    { # A resource that represents a Google Cloud location.
  &quot;displayName&quot;: &quot;A String&quot;, # The friendly name for this location, typically a nearby city name. For example, &quot;Tokyo&quot;.
  &quot;labels&quot;: { # Cross-service attributes for the location. For example {&quot;cloud.googleapis.com/region&quot;: &quot;us-east1&quot;}
    &quot;a_key&quot;: &quot;A String&quot;,
  },
  &quot;locationId&quot;: &quot;A String&quot;, # The canonical id for this location. For example: `&quot;us-east1&quot;`.
  &quot;metadata&quot;: { # Service-specific metadata. For example the available capacity at the given location.
    &quot;a_key&quot;: &quot;&quot;, # Properties of the object. Contains field @type with type URL.
  },
  &quot;name&quot;: &quot;A String&quot;, # Resource name for the location, which may vary between implementations. For example: `&quot;projects/example-project/locations/us-east1&quot;`
}</pre>
</div>

<div class="method">
    <code class="details" id="list">list(name, filter=None, pageSize=None, pageToken=None, x__xgafv=None)</code>
  <pre>Lists information about the supported locations for this service.

Args:
  name: string, The resource that owns the locations collection, if applicable. (required)
  filter: string, A filter to narrow down results to a preferred subset. The filtering language accepts strings like `&quot;displayName=tokyo&quot;`, and is documented in more detail in [AIP-160](https://google.aip.dev/160).
  pageSize: integer, The maximum number of results to return. If not set, the service selects a default.
  pageToken: string, A page token received from the `next_page_token` field in the response. Send that page token to receive the subsequent page.
  x__xgafv: string, V1 error format.
    Allowed values
      1 - v1 error format
      2 - v2 error format

Returns:
  An object of the form:

    { # The response message for Locations.ListLocations.
  &quot;locations&quot;: [ # A list of locations that matches the specified filter in the request.
    { # A resource that represents a Google Cloud location.
      &quot;displayName&quot;: &quot;A String&quot;, # The friendly name for this location, typically a nearby city name. For example, &quot;Tokyo&quot;.
      &quot;labels&quot;: { # Cross-service attributes for the location. For example {&quot;cloud.googleapis.com/region&quot;: &quot;us-east1&quot;}
        &quot;a_key&quot;: &quot;A String&quot;,
      },
      &quot;locationId&quot;: &quot;A String&quot;, # The canonical id for this location. For example: `&quot;us-east1&quot;`.
      &quot;metadata&quot;: { # Service-specific metadata. For example the available capacity at the given location.
        &quot;a_key&quot;: &quot;&quot;, # Properties of the object. Contains field @type with type URL.
      },
      &quot;name&quot;: &quot;A String&quot;, # Resource name for the location, which may vary between implementations. For example: `&quot;projects/example-project/locations/us-east1&quot;`
    },
  ],
  &quot;nextPageToken&quot;: &quot;A String&quot;, # The standard List next-page token.
}</pre>
</div>

<div class="method">
    <code class="details" id="list_next">list_next()</code>
  <pre>Retrieves the next page of results.

        Args:
          previous_request: The request for the previous page. (required)
          previous_response: The response from the request for the previous page. (required)

        Returns:
          A request object that you can call &#x27;execute()&#x27; on to request the next
          page. Returns None if there are no more items in the collection.
        </pre>
</div>

<div class="method">
    <code class="details" id="retrieveContexts">retrieveContexts(parent, body=None, x__xgafv=None)</code>
  <pre>Retrieves relevant contexts for a query.

Args:
  parent: string, Required. The resource name of the Location from which to retrieve RagContexts. The users must have permission to make a call in the project. Format: `projects/{project}/locations/{location}`. (required)
  body: object, The request body.
    The object takes the form of:

{ # Request message for VertexRagService.RetrieveContexts.
  &quot;query&quot;: { # A query to retrieve relevant contexts. # Required. Single RAG retrieve query.
    &quot;ragRetrievalConfig&quot;: { # Specifies the context retrieval config. # Optional. The retrieval config for the query.
      &quot;filter&quot;: { # Config for filters. # Optional. Config for filters.
        &quot;metadataFilter&quot;: &quot;A String&quot;, # Optional. String for metadata filtering.
        &quot;vectorDistanceThreshold&quot;: 3.14, # Optional. Only returns contexts with vector distance smaller than the threshold.
        &quot;vectorSimilarityThreshold&quot;: 3.14, # Optional. Only returns contexts with vector similarity larger than the threshold.
      },
      &quot;hybridSearch&quot;: { # Config for Hybrid Search. # Optional. Config for Hybrid Search.
        &quot;alpha&quot;: 3.14, # Optional. Alpha value controls the weight between dense and sparse vector search results. The range is [0, 1], while 0 means sparse vector search only and 1 means dense vector search only. The default value is 0.5 which balances sparse and dense vector search equally.
      },
      &quot;ranking&quot;: { # Config for ranking and reranking. # Optional. Config for ranking and reranking.
        &quot;llmRanker&quot;: { # Config for LlmRanker. # Optional. Config for LlmRanker.
          &quot;modelName&quot;: &quot;A String&quot;, # Optional. The model name used for ranking. Format: `gemini-1.5-pro`
        },
        &quot;rankService&quot;: { # Config for Rank Service. # Optional. Config for Rank Service.
          &quot;modelName&quot;: &quot;A String&quot;, # Optional. The model name of the rank service. Format: `semantic-ranker-512@latest`
        },
      },
      &quot;topK&quot;: 42, # Optional. The number of contexts to retrieve.
    },
    &quot;ranking&quot;: { # Configurations for hybrid search results ranking. # Optional. Configurations for hybrid search results ranking.
      &quot;alpha&quot;: 3.14, # Optional. Alpha value controls the weight between dense and sparse vector search results. The range is [0, 1], while 0 means sparse vector search only and 1 means dense vector search only. The default value is 0.5 which balances sparse and dense vector search equally.
    },
    &quot;similarityTopK&quot;: 42, # Optional. The number of contexts to retrieve.
    &quot;text&quot;: &quot;A String&quot;, # Optional. The query in text format to get relevant contexts.
  },
  &quot;vertexRagStore&quot;: { # The data source for Vertex RagStore. # The data source for Vertex RagStore.
    &quot;ragCorpora&quot;: [ # Optional. Deprecated. Please use rag_resources to specify the data source.
      &quot;A String&quot;,
    ],
    &quot;ragResources&quot;: [ # Optional. The representation of the rag source. It can be used to specify corpus only or ragfiles. Currently only support one corpus or multiple files from one corpus. In the future we may open up multiple corpora support.
      { # The definition of the Rag resource.
        &quot;ragCorpus&quot;: &quot;A String&quot;, # Optional. RagCorpora resource name. Format: `projects/{project}/locations/{location}/ragCorpora/{rag_corpus}`
        &quot;ragFileIds&quot;: [ # Optional. rag_file_id. The files should be in the same rag_corpus set in rag_corpus field.
          &quot;A String&quot;,
        ],
      },
    ],
    &quot;vectorDistanceThreshold&quot;: 3.14, # Optional. Only return contexts with vector distance smaller than the threshold.
  },
}

  x__xgafv: string, V1 error format.
    Allowed values
      1 - v1 error format
      2 - v2 error format

Returns:
  An object of the form:

    { # Response message for VertexRagService.RetrieveContexts.
  &quot;contexts&quot;: { # Relevant contexts for one query. # The contexts of the query.
    &quot;contexts&quot;: [ # All its contexts.
      { # A context of the query.
        &quot;distance&quot;: 3.14, # The distance between the query dense embedding vector and the context text vector.
        &quot;score&quot;: 3.14, # According to the underlying Vector DB and the selected metric type, the score can be either the distance or the similarity between the query and the context and its range depends on the metric type. For example, if the metric type is COSINE_DISTANCE, it represents the distance between the query and the context. The larger the distance, the less relevant the context is to the query. The range is [0, 2], while 0 means the most relevant and 2 means the least relevant.
        &quot;sourceDisplayName&quot;: &quot;A String&quot;, # The file display name.
        &quot;sourceUri&quot;: &quot;A String&quot;, # If the file is imported from Cloud Storage or Google Drive, source_uri will be original file URI in Cloud Storage or Google Drive; if file is uploaded, source_uri will be file display name.
        &quot;sparseDistance&quot;: 3.14, # The distance between the query sparse embedding vector and the context text vector.
        &quot;text&quot;: &quot;A String&quot;, # The text chunk.
      },
    ],
  },
}</pre>
</div>

</body></html>