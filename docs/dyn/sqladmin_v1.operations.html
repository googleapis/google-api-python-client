<html><body>
<style>

body, h1, h2, h3, div, span, p, pre, a {
  margin: 0;
  padding: 0;
  border: 0;
  font-weight: inherit;
  font-style: inherit;
  font-size: 100%;
  font-family: inherit;
  vertical-align: baseline;
}

body {
  font-size: 13px;
  padding: 1em;
}

h1 {
  font-size: 26px;
  margin-bottom: 1em;
}

h2 {
  font-size: 24px;
  margin-bottom: 1em;
}

h3 {
  font-size: 20px;
  margin-bottom: 1em;
  margin-top: 1em;
}

pre, code {
  line-height: 1.5;
  font-family: Monaco, 'DejaVu Sans Mono', 'Bitstream Vera Sans Mono', 'Lucida Console', monospace;
}

pre {
  margin-top: 0.5em;
}

h1, h2, h3, p {
  font-family: Arial, sans serif;
}

h1, h2, h3 {
  border-bottom: solid #CCC 1px;
}

.toc_element {
  margin-top: 0.5em;
}

.firstline {
  margin-left: 2 em;
}

.method  {
  margin-top: 1em;
  border: solid 1px #CCC;
  padding: 1em;
  background: #EEE;
}

.details {
  font-weight: bold;
  font-size: 14px;
}

</style>

<h1><a href="sqladmin_v1.html">Cloud SQL Admin API</a> . <a href="sqladmin_v1.operations.html">operations</a></h1>
<h2>Instance Methods</h2>
<p class="toc_element">
  <code><a href="#cancel">cancel(project, operation, x__xgafv=None)</a></code></p>
<p class="firstline">Cancels an instance operation that has been performed on an instance.</p>
<p class="toc_element">
  <code><a href="#close">close()</a></code></p>
<p class="firstline">Close httplib2 connections.</p>
<p class="toc_element">
  <code><a href="#get">get(project, operation, x__xgafv=None)</a></code></p>
<p class="firstline">Retrieves an instance operation that has been performed on an instance.</p>
<p class="toc_element">
  <code><a href="#list">list(project, filter=None, instance=None, maxResults=None, pageToken=None, x__xgafv=None)</a></code></p>
<p class="firstline">Lists all instance operations that have been performed on the given Cloud SQL instance in the reverse chronological order of the start time.</p>
<p class="toc_element">
  <code><a href="#list_next">list_next()</a></code></p>
<p class="firstline">Retrieves the next page of results.</p>
<h3>Method Details</h3>
<div class="method">
    <code class="details" id="cancel">cancel(project, operation, x__xgafv=None)</code>
  <pre>Cancels an instance operation that has been performed on an instance.

Args:
  project: string, Project ID of the project that contains the instance. (required)
  operation: string, Instance operation ID. (required)
  x__xgafv: string, V1 error format.
    Allowed values
      1 - v1 error format
      2 - v2 error format

Returns:
  An object of the form:

    { # A generic empty message that you can re-use to avoid defining duplicated empty messages in your APIs. A typical example is to use it as the request or the response type of an API method. For instance: service Foo { rpc Bar(google.protobuf.Empty) returns (google.protobuf.Empty); }
}</pre>
</div>

<div class="method">
    <code class="details" id="close">close()</code>
  <pre>Close httplib2 connections.</pre>
</div>

<div class="method">
    <code class="details" id="get">get(project, operation, x__xgafv=None)</code>
  <pre>Retrieves an instance operation that has been performed on an instance.

Args:
  project: string, Project ID of the project that contains the instance. (required)
  operation: string, Instance operation ID. (required)
  x__xgafv: string, V1 error format.
    Allowed values
      1 - v1 error format
      2 - v2 error format

Returns:
  An object of the form:

    { # An Operation resource. For successful operations that return an Operation resource, only the fields relevant to the operation are populated in the resource.
  &quot;acquireSsrsLeaseContext&quot;: { # Acquire SSRS lease context. # The context for acquire SSRS lease operation, if applicable.
    &quot;duration&quot;: &quot;A String&quot;, # Lease duration needed for SSRS setup.
    &quot;reportDatabase&quot;: &quot;A String&quot;, # The report database to be used for SSRS setup.
    &quot;serviceLogin&quot;: &quot;A String&quot;, # The username to be used as the service login to connect to the report database for SSRS setup.
    &quot;setupLogin&quot;: &quot;A String&quot;, # The username to be used as the setup login to connect to the database server for SSRS setup.
  },
  &quot;apiWarning&quot;: { # An Admin API warning message. # An Admin API warning message.
    &quot;code&quot;: &quot;A String&quot;, # Code to uniquely identify the warning type.
    &quot;message&quot;: &quot;A String&quot;, # The warning message.
    &quot;region&quot;: &quot;A String&quot;, # The region name for REGION_UNREACHABLE warning.
  },
  &quot;backupContext&quot;: { # Backup context. # The context for backup operation, if applicable.
    &quot;backupId&quot;: &quot;A String&quot;, # The identifier of the backup.
    &quot;kind&quot;: &quot;A String&quot;, # This is always `sql#backupContext`.
    &quot;name&quot;: &quot;A String&quot;, # The name of the backup. Format: projects/{project}/backups/{backup}
  },
  &quot;endTime&quot;: &quot;A String&quot;, # The time this operation finished in UTC timezone in [RFC 3339](https://tools.ietf.org/html/rfc3339) format, for example `2012-11-15T16:19:00.094Z`.
  &quot;error&quot;: { # Database instance operation errors list wrapper. # If errors occurred during processing of this operation, this field will be populated.
    &quot;errors&quot;: [ # The list of errors encountered while processing this operation.
      { # Database instance operation error.
        &quot;code&quot;: &quot;A String&quot;, # Identifies the specific error that occurred.
        &quot;kind&quot;: &quot;A String&quot;, # This is always `sql#operationError`.
        &quot;message&quot;: &quot;A String&quot;, # Additional information about the error encountered.
      },
    ],
    &quot;kind&quot;: &quot;A String&quot;, # This is always `sql#operationErrors`.
  },
  &quot;exportContext&quot;: { # Database instance export context. # The context for export operation, if applicable.
    &quot;bakExportOptions&quot;: { # Options for exporting BAK files (SQL Server-only)
      &quot;bakType&quot;: &quot;A String&quot;, # Type of this bak file will be export, FULL or DIFF, SQL Server only
      &quot;copyOnly&quot;: True or False, # Deprecated: copy_only is deprecated. Use differential_base instead
      &quot;differentialBase&quot;: True or False, # Whether or not the backup can be used as a differential base copy_only backup can not be served as differential base
      &quot;exportLogEndTime&quot;: &quot;A String&quot;, # Optional. The end timestamp when transaction log will be included in the export operation. [RFC 3339](https://tools.ietf.org/html/rfc3339) format (for example, `2023-10-01T16:19:00.094`) in UTC. When omitted, all available logs until current time will be included. Only applied to Cloud SQL for SQL Server.
      &quot;exportLogStartTime&quot;: &quot;A String&quot;, # Optional. The begin timestamp when transaction log will be included in the export operation. [RFC 3339](https://tools.ietf.org/html/rfc3339) format (for example, `2023-10-01T16:19:00.094`) in UTC. When omitted, all available logs from the beginning of retention period will be included. Only applied to Cloud SQL for SQL Server.
      &quot;stripeCount&quot;: 42, # Option for specifying how many stripes to use for the export. If blank, and the value of the striped field is true, the number of stripes is automatically chosen.
      &quot;striped&quot;: True or False, # Whether or not the export should be striped.
    },
    &quot;csvExportOptions&quot;: { # Options for exporting data as CSV. `MySQL` and `PostgreSQL` instances only.
      &quot;escapeCharacter&quot;: &quot;A String&quot;, # Specifies the character that should appear before a data character that needs to be escaped.
      &quot;fieldsTerminatedBy&quot;: &quot;A String&quot;, # Specifies the character that separates columns within each row (line) of the file.
      &quot;linesTerminatedBy&quot;: &quot;A String&quot;, # This is used to separate lines. If a line does not contain all fields, the rest of the columns are set to their default values.
      &quot;quoteCharacter&quot;: &quot;A String&quot;, # Specifies the quoting character to be used when a data value is quoted.
      &quot;selectQuery&quot;: &quot;A String&quot;, # The select query used to extract the data.
    },
    &quot;databases&quot;: [ # Databases to be exported. `MySQL instances:` If `fileType` is `SQL` and no database is specified, all databases are exported, except for the `mysql` system database. If `fileType` is `CSV`, you can specify one database, either by using this property or by using the `csvExportOptions.selectQuery` property, which takes precedence over this property. `PostgreSQL instances:` You must specify one database to be exported. If `fileType` is `CSV`, this database must match the one specified in the `csvExportOptions.selectQuery` property. `SQL Server instances:` You must specify one database to be exported, and the `fileType` must be `BAK`.
      &quot;A String&quot;,
    ],
    &quot;fileType&quot;: &quot;A String&quot;, # The file type for the specified uri.
    &quot;kind&quot;: &quot;A String&quot;, # This is always `sql#exportContext`.
    &quot;offload&quot;: True or False, # Option for export offload.
    &quot;sqlExportOptions&quot;: { # Options for exporting data as SQL statements.
      &quot;mysqlExportOptions&quot;: { # Options for exporting from MySQL.
        &quot;masterData&quot;: 42, # Option to include SQL statement required to set up replication. If set to `1`, the dump file includes a CHANGE MASTER TO statement with the binary log coordinates, and --set-gtid-purged is set to ON. If set to `2`, the CHANGE MASTER TO statement is written as a SQL comment and has no effect. If set to any value other than `1`, --set-gtid-purged is set to OFF.
      },
      &quot;parallel&quot;: True or False, # Optional. Whether or not the export should be parallel.
      &quot;postgresExportOptions&quot;: { # Options for exporting from a Cloud SQL for PostgreSQL instance.
        &quot;clean&quot;: True or False, # Optional. Use this option to include DROP SQL statements. These statements are used to delete database objects before running the import operation.
        &quot;ifExists&quot;: True or False, # Optional. Option to include an IF EXISTS SQL statement with each DROP statement produced by clean.
      },
      &quot;schemaOnly&quot;: True or False, # Export only schemas.
      &quot;tables&quot;: [ # Tables to export, or that were exported, from the specified database. If you specify tables, specify one and only one database. For PostgreSQL instances, you can specify only one table.
        &quot;A String&quot;,
      ],
      &quot;threads&quot;: 42, # Optional. The number of threads to use for parallel export.
    },
    &quot;uri&quot;: &quot;A String&quot;, # The path to the file in Google Cloud Storage where the export will be stored. The URI is in the form `gs://bucketName/fileName`. If the file already exists, the request succeeds, but the operation fails. If `fileType` is `SQL` and the filename ends with .gz, the contents are compressed.
  },
  &quot;importContext&quot;: { # Database instance import context. # The context for import operation, if applicable.
    &quot;bakImportOptions&quot;: { # Import parameters specific to SQL Server .BAK files
      &quot;bakType&quot;: &quot;A String&quot;, # Type of the bak content, FULL or DIFF
      &quot;encryptionOptions&quot;: {
        &quot;certPath&quot;: &quot;A String&quot;, # Path to the Certificate (.cer) in Cloud Storage, in the form `gs://bucketName/fileName`. The instance must have write permissions to the bucket and read access to the file.
        &quot;pvkPassword&quot;: &quot;A String&quot;, # Password that encrypts the private key
        &quot;pvkPath&quot;: &quot;A String&quot;, # Path to the Certificate Private Key (.pvk) in Cloud Storage, in the form `gs://bucketName/fileName`. The instance must have write permissions to the bucket and read access to the file.
      },
      &quot;noRecovery&quot;: True or False, # Whether or not the backup importing will restore database with NORECOVERY option Applies only to Cloud SQL for SQL Server.
      &quot;recoveryOnly&quot;: True or False, # Whether or not the backup importing request will just bring database online without downloading Bak content only one of &quot;no_recovery&quot; and &quot;recovery_only&quot; can be true otherwise error will return. Applies only to Cloud SQL for SQL Server.
      &quot;stopAt&quot;: &quot;A String&quot;, # Optional. The timestamp when the import should stop. This timestamp is in the [RFC 3339](https://tools.ietf.org/html/rfc3339) format (for example, `2023-10-01T16:19:00.094`). This field is equivalent to the STOPAT keyword and applies to Cloud SQL for SQL Server only.
      &quot;stopAtMark&quot;: &quot;A String&quot;, # Optional. The marked transaction where the import should stop. This field is equivalent to the STOPATMARK keyword and applies to Cloud SQL for SQL Server only.
      &quot;striped&quot;: True or False, # Whether or not the backup set being restored is striped. Applies only to Cloud SQL for SQL Server.
    },
    &quot;csvImportOptions&quot;: { # Options for importing data as CSV.
      &quot;columns&quot;: [ # The columns to which CSV data is imported. If not specified, all columns of the database table are loaded with CSV data.
        &quot;A String&quot;,
      ],
      &quot;escapeCharacter&quot;: &quot;A String&quot;, # Specifies the character that should appear before a data character that needs to be escaped.
      &quot;fieldsTerminatedBy&quot;: &quot;A String&quot;, # Specifies the character that separates columns within each row (line) of the file.
      &quot;linesTerminatedBy&quot;: &quot;A String&quot;, # This is used to separate lines. If a line does not contain all fields, the rest of the columns are set to their default values.
      &quot;quoteCharacter&quot;: &quot;A String&quot;, # Specifies the quoting character to be used when a data value is quoted.
      &quot;table&quot;: &quot;A String&quot;, # The table to which CSV data is imported.
    },
    &quot;database&quot;: &quot;A String&quot;, # The target database for the import. If `fileType` is `SQL`, this field is required only if the import file does not specify a database, and is overridden by any database specification in the import file. If `fileType` is `CSV`, one database must be specified.
    &quot;fileType&quot;: &quot;A String&quot;, # The file type for the specified uri.\`SQL`: The file contains SQL statements. \`CSV`: The file contains CSV data.
    &quot;importUser&quot;: &quot;A String&quot;, # The PostgreSQL user for this import operation. PostgreSQL instances only.
    &quot;kind&quot;: &quot;A String&quot;, # This is always `sql#importContext`.
    &quot;sqlImportOptions&quot;: { # Optional. Options for importing data from SQL statements.
      &quot;parallel&quot;: True or False, # Optional. Whether or not the import should be parallel.
      &quot;postgresImportOptions&quot;: { # Optional. Options for importing from a Cloud SQL for PostgreSQL instance.
        &quot;clean&quot;: True or False, # Optional. The --clean flag for the pg_restore utility. This flag applies only if you enabled Cloud SQL to import files in parallel.
        &quot;ifExists&quot;: True or False, # Optional. The --if-exists flag for the pg_restore utility. This flag applies only if you enabled Cloud SQL to import files in parallel.
      },
      &quot;threads&quot;: 42, # Optional. The number of threads to use for parallel import.
    },
    &quot;uri&quot;: &quot;A String&quot;, # Path to the import file in Cloud Storage, in the form `gs://bucketName/fileName`. Compressed gzip files (.gz) are supported when `fileType` is `SQL`. The instance must have write permissions to the bucket and read access to the file.
  },
  &quot;insertTime&quot;: &quot;A String&quot;, # The time this operation was enqueued in UTC timezone in [RFC 3339](https://tools.ietf.org/html/rfc3339) format, for example `2012-11-15T16:19:00.094Z`.
  &quot;kind&quot;: &quot;A String&quot;, # This is always `sql#operation`.
  &quot;name&quot;: &quot;A String&quot;, # An identifier that uniquely identifies the operation. You can use this identifier to retrieve the Operations resource that has information about the operation.
  &quot;operationType&quot;: &quot;A String&quot;, # The type of the operation. Valid values are: * `CREATE` * `DELETE` * `UPDATE` * `RESTART` * `IMPORT` * `EXPORT` * `BACKUP_VOLUME` * `RESTORE_VOLUME` * `CREATE_USER` * `DELETE_USER` * `CREATE_DATABASE` * `DELETE_DATABASE`
  &quot;selfLink&quot;: &quot;A String&quot;, # The URI of this resource.
  &quot;startTime&quot;: &quot;A String&quot;, # The time this operation actually started in UTC timezone in [RFC 3339](https://tools.ietf.org/html/rfc3339) format, for example `2012-11-15T16:19:00.094Z`.
  &quot;status&quot;: &quot;A String&quot;, # The status of an operation.
  &quot;targetId&quot;: &quot;A String&quot;, # Name of the database instance related to this operation.
  &quot;targetLink&quot;: &quot;A String&quot;,
  &quot;targetProject&quot;: &quot;A String&quot;, # The project ID of the target instance related to this operation.
  &quot;user&quot;: &quot;A String&quot;, # The email address of the user who initiated this operation.
}</pre>
</div>

<div class="method">
    <code class="details" id="list">list(project, filter=None, instance=None, maxResults=None, pageToken=None, x__xgafv=None)</code>
  <pre>Lists all instance operations that have been performed on the given Cloud SQL instance in the reverse chronological order of the start time.

Args:
  project: string, Project ID of the project that contains the instance. (required)
  filter: string, Optional. A filter string that follows the rules of EBNF grammar (https://google.aip.dev/assets/misc/ebnf-filtering.txt). Cloud SQL provides filters for status, operationType, and startTime.
  instance: string, Cloud SQL instance ID. This does not include the project ID.
  maxResults: integer, Maximum number of operations per response.
  pageToken: string, A previously-returned page token representing part of the larger set of results to view.
  x__xgafv: string, V1 error format.
    Allowed values
      1 - v1 error format
      2 - v2 error format

Returns:
  An object of the form:

    { # Operations list response.
  &quot;items&quot;: [ # List of operation resources.
    { # An Operation resource. For successful operations that return an Operation resource, only the fields relevant to the operation are populated in the resource.
      &quot;acquireSsrsLeaseContext&quot;: { # Acquire SSRS lease context. # The context for acquire SSRS lease operation, if applicable.
        &quot;duration&quot;: &quot;A String&quot;, # Lease duration needed for SSRS setup.
        &quot;reportDatabase&quot;: &quot;A String&quot;, # The report database to be used for SSRS setup.
        &quot;serviceLogin&quot;: &quot;A String&quot;, # The username to be used as the service login to connect to the report database for SSRS setup.
        &quot;setupLogin&quot;: &quot;A String&quot;, # The username to be used as the setup login to connect to the database server for SSRS setup.
      },
      &quot;apiWarning&quot;: { # An Admin API warning message. # An Admin API warning message.
        &quot;code&quot;: &quot;A String&quot;, # Code to uniquely identify the warning type.
        &quot;message&quot;: &quot;A String&quot;, # The warning message.
        &quot;region&quot;: &quot;A String&quot;, # The region name for REGION_UNREACHABLE warning.
      },
      &quot;backupContext&quot;: { # Backup context. # The context for backup operation, if applicable.
        &quot;backupId&quot;: &quot;A String&quot;, # The identifier of the backup.
        &quot;kind&quot;: &quot;A String&quot;, # This is always `sql#backupContext`.
        &quot;name&quot;: &quot;A String&quot;, # The name of the backup. Format: projects/{project}/backups/{backup}
      },
      &quot;endTime&quot;: &quot;A String&quot;, # The time this operation finished in UTC timezone in [RFC 3339](https://tools.ietf.org/html/rfc3339) format, for example `2012-11-15T16:19:00.094Z`.
      &quot;error&quot;: { # Database instance operation errors list wrapper. # If errors occurred during processing of this operation, this field will be populated.
        &quot;errors&quot;: [ # The list of errors encountered while processing this operation.
          { # Database instance operation error.
            &quot;code&quot;: &quot;A String&quot;, # Identifies the specific error that occurred.
            &quot;kind&quot;: &quot;A String&quot;, # This is always `sql#operationError`.
            &quot;message&quot;: &quot;A String&quot;, # Additional information about the error encountered.
          },
        ],
        &quot;kind&quot;: &quot;A String&quot;, # This is always `sql#operationErrors`.
      },
      &quot;exportContext&quot;: { # Database instance export context. # The context for export operation, if applicable.
        &quot;bakExportOptions&quot;: { # Options for exporting BAK files (SQL Server-only)
          &quot;bakType&quot;: &quot;A String&quot;, # Type of this bak file will be export, FULL or DIFF, SQL Server only
          &quot;copyOnly&quot;: True or False, # Deprecated: copy_only is deprecated. Use differential_base instead
          &quot;differentialBase&quot;: True or False, # Whether or not the backup can be used as a differential base copy_only backup can not be served as differential base
          &quot;exportLogEndTime&quot;: &quot;A String&quot;, # Optional. The end timestamp when transaction log will be included in the export operation. [RFC 3339](https://tools.ietf.org/html/rfc3339) format (for example, `2023-10-01T16:19:00.094`) in UTC. When omitted, all available logs until current time will be included. Only applied to Cloud SQL for SQL Server.
          &quot;exportLogStartTime&quot;: &quot;A String&quot;, # Optional. The begin timestamp when transaction log will be included in the export operation. [RFC 3339](https://tools.ietf.org/html/rfc3339) format (for example, `2023-10-01T16:19:00.094`) in UTC. When omitted, all available logs from the beginning of retention period will be included. Only applied to Cloud SQL for SQL Server.
          &quot;stripeCount&quot;: 42, # Option for specifying how many stripes to use for the export. If blank, and the value of the striped field is true, the number of stripes is automatically chosen.
          &quot;striped&quot;: True or False, # Whether or not the export should be striped.
        },
        &quot;csvExportOptions&quot;: { # Options for exporting data as CSV. `MySQL` and `PostgreSQL` instances only.
          &quot;escapeCharacter&quot;: &quot;A String&quot;, # Specifies the character that should appear before a data character that needs to be escaped.
          &quot;fieldsTerminatedBy&quot;: &quot;A String&quot;, # Specifies the character that separates columns within each row (line) of the file.
          &quot;linesTerminatedBy&quot;: &quot;A String&quot;, # This is used to separate lines. If a line does not contain all fields, the rest of the columns are set to their default values.
          &quot;quoteCharacter&quot;: &quot;A String&quot;, # Specifies the quoting character to be used when a data value is quoted.
          &quot;selectQuery&quot;: &quot;A String&quot;, # The select query used to extract the data.
        },
        &quot;databases&quot;: [ # Databases to be exported. `MySQL instances:` If `fileType` is `SQL` and no database is specified, all databases are exported, except for the `mysql` system database. If `fileType` is `CSV`, you can specify one database, either by using this property or by using the `csvExportOptions.selectQuery` property, which takes precedence over this property. `PostgreSQL instances:` You must specify one database to be exported. If `fileType` is `CSV`, this database must match the one specified in the `csvExportOptions.selectQuery` property. `SQL Server instances:` You must specify one database to be exported, and the `fileType` must be `BAK`.
          &quot;A String&quot;,
        ],
        &quot;fileType&quot;: &quot;A String&quot;, # The file type for the specified uri.
        &quot;kind&quot;: &quot;A String&quot;, # This is always `sql#exportContext`.
        &quot;offload&quot;: True or False, # Option for export offload.
        &quot;sqlExportOptions&quot;: { # Options for exporting data as SQL statements.
          &quot;mysqlExportOptions&quot;: { # Options for exporting from MySQL.
            &quot;masterData&quot;: 42, # Option to include SQL statement required to set up replication. If set to `1`, the dump file includes a CHANGE MASTER TO statement with the binary log coordinates, and --set-gtid-purged is set to ON. If set to `2`, the CHANGE MASTER TO statement is written as a SQL comment and has no effect. If set to any value other than `1`, --set-gtid-purged is set to OFF.
          },
          &quot;parallel&quot;: True or False, # Optional. Whether or not the export should be parallel.
          &quot;postgresExportOptions&quot;: { # Options for exporting from a Cloud SQL for PostgreSQL instance.
            &quot;clean&quot;: True or False, # Optional. Use this option to include DROP SQL statements. These statements are used to delete database objects before running the import operation.
            &quot;ifExists&quot;: True or False, # Optional. Option to include an IF EXISTS SQL statement with each DROP statement produced by clean.
          },
          &quot;schemaOnly&quot;: True or False, # Export only schemas.
          &quot;tables&quot;: [ # Tables to export, or that were exported, from the specified database. If you specify tables, specify one and only one database. For PostgreSQL instances, you can specify only one table.
            &quot;A String&quot;,
          ],
          &quot;threads&quot;: 42, # Optional. The number of threads to use for parallel export.
        },
        &quot;uri&quot;: &quot;A String&quot;, # The path to the file in Google Cloud Storage where the export will be stored. The URI is in the form `gs://bucketName/fileName`. If the file already exists, the request succeeds, but the operation fails. If `fileType` is `SQL` and the filename ends with .gz, the contents are compressed.
      },
      &quot;importContext&quot;: { # Database instance import context. # The context for import operation, if applicable.
        &quot;bakImportOptions&quot;: { # Import parameters specific to SQL Server .BAK files
          &quot;bakType&quot;: &quot;A String&quot;, # Type of the bak content, FULL or DIFF
          &quot;encryptionOptions&quot;: {
            &quot;certPath&quot;: &quot;A String&quot;, # Path to the Certificate (.cer) in Cloud Storage, in the form `gs://bucketName/fileName`. The instance must have write permissions to the bucket and read access to the file.
            &quot;pvkPassword&quot;: &quot;A String&quot;, # Password that encrypts the private key
            &quot;pvkPath&quot;: &quot;A String&quot;, # Path to the Certificate Private Key (.pvk) in Cloud Storage, in the form `gs://bucketName/fileName`. The instance must have write permissions to the bucket and read access to the file.
          },
          &quot;noRecovery&quot;: True or False, # Whether or not the backup importing will restore database with NORECOVERY option Applies only to Cloud SQL for SQL Server.
          &quot;recoveryOnly&quot;: True or False, # Whether or not the backup importing request will just bring database online without downloading Bak content only one of &quot;no_recovery&quot; and &quot;recovery_only&quot; can be true otherwise error will return. Applies only to Cloud SQL for SQL Server.
          &quot;stopAt&quot;: &quot;A String&quot;, # Optional. The timestamp when the import should stop. This timestamp is in the [RFC 3339](https://tools.ietf.org/html/rfc3339) format (for example, `2023-10-01T16:19:00.094`). This field is equivalent to the STOPAT keyword and applies to Cloud SQL for SQL Server only.
          &quot;stopAtMark&quot;: &quot;A String&quot;, # Optional. The marked transaction where the import should stop. This field is equivalent to the STOPATMARK keyword and applies to Cloud SQL for SQL Server only.
          &quot;striped&quot;: True or False, # Whether or not the backup set being restored is striped. Applies only to Cloud SQL for SQL Server.
        },
        &quot;csvImportOptions&quot;: { # Options for importing data as CSV.
          &quot;columns&quot;: [ # The columns to which CSV data is imported. If not specified, all columns of the database table are loaded with CSV data.
            &quot;A String&quot;,
          ],
          &quot;escapeCharacter&quot;: &quot;A String&quot;, # Specifies the character that should appear before a data character that needs to be escaped.
          &quot;fieldsTerminatedBy&quot;: &quot;A String&quot;, # Specifies the character that separates columns within each row (line) of the file.
          &quot;linesTerminatedBy&quot;: &quot;A String&quot;, # This is used to separate lines. If a line does not contain all fields, the rest of the columns are set to their default values.
          &quot;quoteCharacter&quot;: &quot;A String&quot;, # Specifies the quoting character to be used when a data value is quoted.
          &quot;table&quot;: &quot;A String&quot;, # The table to which CSV data is imported.
        },
        &quot;database&quot;: &quot;A String&quot;, # The target database for the import. If `fileType` is `SQL`, this field is required only if the import file does not specify a database, and is overridden by any database specification in the import file. If `fileType` is `CSV`, one database must be specified.
        &quot;fileType&quot;: &quot;A String&quot;, # The file type for the specified uri.\`SQL`: The file contains SQL statements. \`CSV`: The file contains CSV data.
        &quot;importUser&quot;: &quot;A String&quot;, # The PostgreSQL user for this import operation. PostgreSQL instances only.
        &quot;kind&quot;: &quot;A String&quot;, # This is always `sql#importContext`.
        &quot;sqlImportOptions&quot;: { # Optional. Options for importing data from SQL statements.
          &quot;parallel&quot;: True or False, # Optional. Whether or not the import should be parallel.
          &quot;postgresImportOptions&quot;: { # Optional. Options for importing from a Cloud SQL for PostgreSQL instance.
            &quot;clean&quot;: True or False, # Optional. The --clean flag for the pg_restore utility. This flag applies only if you enabled Cloud SQL to import files in parallel.
            &quot;ifExists&quot;: True or False, # Optional. The --if-exists flag for the pg_restore utility. This flag applies only if you enabled Cloud SQL to import files in parallel.
          },
          &quot;threads&quot;: 42, # Optional. The number of threads to use for parallel import.
        },
        &quot;uri&quot;: &quot;A String&quot;, # Path to the import file in Cloud Storage, in the form `gs://bucketName/fileName`. Compressed gzip files (.gz) are supported when `fileType` is `SQL`. The instance must have write permissions to the bucket and read access to the file.
      },
      &quot;insertTime&quot;: &quot;A String&quot;, # The time this operation was enqueued in UTC timezone in [RFC 3339](https://tools.ietf.org/html/rfc3339) format, for example `2012-11-15T16:19:00.094Z`.
      &quot;kind&quot;: &quot;A String&quot;, # This is always `sql#operation`.
      &quot;name&quot;: &quot;A String&quot;, # An identifier that uniquely identifies the operation. You can use this identifier to retrieve the Operations resource that has information about the operation.
      &quot;operationType&quot;: &quot;A String&quot;, # The type of the operation. Valid values are: * `CREATE` * `DELETE` * `UPDATE` * `RESTART` * `IMPORT` * `EXPORT` * `BACKUP_VOLUME` * `RESTORE_VOLUME` * `CREATE_USER` * `DELETE_USER` * `CREATE_DATABASE` * `DELETE_DATABASE`
      &quot;selfLink&quot;: &quot;A String&quot;, # The URI of this resource.
      &quot;startTime&quot;: &quot;A String&quot;, # The time this operation actually started in UTC timezone in [RFC 3339](https://tools.ietf.org/html/rfc3339) format, for example `2012-11-15T16:19:00.094Z`.
      &quot;status&quot;: &quot;A String&quot;, # The status of an operation.
      &quot;targetId&quot;: &quot;A String&quot;, # Name of the database instance related to this operation.
      &quot;targetLink&quot;: &quot;A String&quot;,
      &quot;targetProject&quot;: &quot;A String&quot;, # The project ID of the target instance related to this operation.
      &quot;user&quot;: &quot;A String&quot;, # The email address of the user who initiated this operation.
    },
  ],
  &quot;kind&quot;: &quot;A String&quot;, # This is always `sql#operationsList`.
  &quot;nextPageToken&quot;: &quot;A String&quot;, # The continuation token, used to page through large result sets. Provide this value in a subsequent request to return the next page of results.
  &quot;warnings&quot;: [ # List of warnings that occurred while handling the request.
    { # An Admin API warning message.
      &quot;code&quot;: &quot;A String&quot;, # Code to uniquely identify the warning type.
      &quot;message&quot;: &quot;A String&quot;, # The warning message.
      &quot;region&quot;: &quot;A String&quot;, # The region name for REGION_UNREACHABLE warning.
    },
  ],
}</pre>
</div>

<div class="method">
    <code class="details" id="list_next">list_next()</code>
  <pre>Retrieves the next page of results.

        Args:
          previous_request: The request for the previous page. (required)
          previous_response: The response from the request for the previous page. (required)

        Returns:
          A request object that you can call &#x27;execute()&#x27; on to request the next
          page. Returns None if there are no more items in the collection.
        </pre>
</div>

</body></html>