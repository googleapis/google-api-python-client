<html><body>
<style>

body, h1, h2, h3, div, span, p, pre, a {
  margin: 0;
  padding: 0;
  border: 0;
  font-weight: inherit;
  font-style: inherit;
  font-size: 100%;
  font-family: inherit;
  vertical-align: baseline;
}

body {
  font-size: 13px;
  padding: 1em;
}

h1 {
  font-size: 26px;
  margin-bottom: 1em;
}

h2 {
  font-size: 24px;
  margin-bottom: 1em;
}

h3 {
  font-size: 20px;
  margin-bottom: 1em;
  margin-top: 1em;
}

pre, code {
  line-height: 1.5;
  font-family: Monaco, 'DejaVu Sans Mono', 'Bitstream Vera Sans Mono', 'Lucida Console', monospace;
}

pre {
  margin-top: 0.5em;
}

h1, h2, h3, p {
  font-family: Arial, sans serif;
}

h1, h2, h3 {
  border-bottom: solid #CCC 1px;
}

.toc_element {
  margin-top: 0.5em;
}

.firstline {
  margin-left: 2 em;
}

.method  {
  margin-top: 1em;
  border: solid 1px #CCC;
  padding: 1em;
  background: #EEE;
}

.details {
  font-weight: bold;
  font-size: 14px;
}

</style>

<h1><a href="contactcenterinsights_v1.html">Contact Center AI Insights API</a> . <a href="contactcenterinsights_v1.projects.html">projects</a> . <a href="contactcenterinsights_v1.projects.locations.html">locations</a> . <a href="contactcenterinsights_v1.projects.locations.qaScorecards.html">qaScorecards</a> . <a href="contactcenterinsights_v1.projects.locations.qaScorecards.revisions.html">revisions</a> . <a href="contactcenterinsights_v1.projects.locations.qaScorecards.revisions.qaQuestions.html">qaQuestions</a></h1>
<h2>Instance Methods</h2>
<p class="toc_element">
  <code><a href="#close">close()</a></code></p>
<p class="firstline">Close httplib2 connections.</p>
<p class="toc_element">
  <code><a href="#create">create(parent, body=None, qaQuestionId=None, x__xgafv=None)</a></code></p>
<p class="firstline">Create a QaQuestion.</p>
<p class="toc_element">
  <code><a href="#delete">delete(name, x__xgafv=None)</a></code></p>
<p class="firstline">Deletes a QaQuestion.</p>
<p class="toc_element">
  <code><a href="#get">get(name, x__xgafv=None)</a></code></p>
<p class="firstline">Gets a QaQuestion.</p>
<p class="toc_element">
  <code><a href="#list">list(parent, pageSize=None, pageToken=None, x__xgafv=None)</a></code></p>
<p class="firstline">Lists QaQuestions.</p>
<p class="toc_element">
  <code><a href="#list_next">list_next()</a></code></p>
<p class="firstline">Retrieves the next page of results.</p>
<p class="toc_element">
  <code><a href="#patch">patch(name, body=None, updateMask=None, x__xgafv=None)</a></code></p>
<p class="firstline">Updates a QaQuestion.</p>
<h3>Method Details</h3>
<div class="method">
    <code class="details" id="close">close()</code>
  <pre>Close httplib2 connections.</pre>
</div>

<div class="method">
    <code class="details" id="create">create(parent, body=None, qaQuestionId=None, x__xgafv=None)</code>
  <pre>Create a QaQuestion.

Args:
  parent: string, Required. The parent resource of the QaQuestion. (required)
  body: object, The request body.
    The object takes the form of:

{ # A single question to be scored by the Insights QA feature.
  &quot;abbreviation&quot;: &quot;A String&quot;, # Short, descriptive string, used in the UI where it&#x27;s not practical to display the full question body. E.g., &quot;Greeting&quot;.
  &quot;answerChoices&quot;: [ # A list of valid answers to the question, which the LLM must choose from.
    { # Message representing a possible answer to the question.
      &quot;boolValue&quot;: True or False, # Boolean value.
      &quot;key&quot;: &quot;A String&quot;, # A short string used as an identifier.
      &quot;naValue&quot;: True or False, # A value of &quot;Not Applicable (N/A)&quot;. If provided, this field may only be set to `true`. If a question receives this answer, it will be excluded from any score calculations.
      &quot;numValue&quot;: 3.14, # Numerical value.
      &quot;score&quot;: 3.14, # Numerical score of the answer, used for generating the overall score of a QaScorecardResult. If the answer uses na_value, this field is unused.
      &quot;strValue&quot;: &quot;A String&quot;, # String value.
    },
  ],
  &quot;answerInstructions&quot;: &quot;A String&quot;, # Instructions describing how to determine the answer.
  &quot;createTime&quot;: &quot;A String&quot;, # Output only. The time at which this question was created.
  &quot;metrics&quot;: { # A wrapper representing metrics calculated against a test-set on a LLM that was fine tuned for this question. # Metrics of the underlying tuned LLM over a holdout/test set while fine tuning the underlying LLM for the given question. This field will only be populated if and only if the question is part of a scorecard revision that has been tuned.
    &quot;accuracy&quot;: 3.14, # Output only. Accuracy of the model. Measures the percentage of correct answers the model gave on the test set.
  },
  &quot;name&quot;: &quot;A String&quot;, # Identifier. The resource name of the question. Format: projects/{project}/locations/{location}/qaScorecards/{qa_scorecard}/revisions/{revision}/qaQuestions/{qa_question}
  &quot;order&quot;: 42, # Defines the order of the question within its parent scorecard revision.
  &quot;questionBody&quot;: &quot;A String&quot;, # Question text. E.g., &quot;Did the agent greet the customer?&quot;
  &quot;tags&quot;: [ # User-defined list of arbitrary tags for the question. Used for grouping/organization and for weighting the score of each question.
    &quot;A String&quot;,
  ],
  &quot;tuningMetadata&quot;: { # Metadata about the tuning operation for the question. Will only be set if a scorecard containing this question has been tuned. # Metadata about the tuning operation for the question.This field will only be populated if and only if the question is part of a scorecard revision that has been tuned.
    &quot;datasetValidationWarnings&quot;: [ # A list of any applicable data validation warnings about the question&#x27;s feedback labels.
      &quot;A String&quot;,
    ],
    &quot;totalValidLabelCount&quot;: &quot;A String&quot;, # Total number of valid labels provided for the question at the time of tuining.
    &quot;tuningError&quot;: &quot;A String&quot;, # Error status of the tuning operation for the question. Will only be set if the tuning operation failed.
  },
  &quot;updateTime&quot;: &quot;A String&quot;, # Output only. The most recent time at which the question was updated.
}

  qaQuestionId: string, Optional. A unique ID for the new question. This ID will become the final component of the question&#x27;s resource name. If no ID is specified, a server-generated ID will be used. This value should be 4-64 characters and must match the regular expression `^[a-z0-9-]{4,64}$`. Valid characters are `a-z-`.
  x__xgafv: string, V1 error format.
    Allowed values
      1 - v1 error format
      2 - v2 error format

Returns:
  An object of the form:

    { # A single question to be scored by the Insights QA feature.
  &quot;abbreviation&quot;: &quot;A String&quot;, # Short, descriptive string, used in the UI where it&#x27;s not practical to display the full question body. E.g., &quot;Greeting&quot;.
  &quot;answerChoices&quot;: [ # A list of valid answers to the question, which the LLM must choose from.
    { # Message representing a possible answer to the question.
      &quot;boolValue&quot;: True or False, # Boolean value.
      &quot;key&quot;: &quot;A String&quot;, # A short string used as an identifier.
      &quot;naValue&quot;: True or False, # A value of &quot;Not Applicable (N/A)&quot;. If provided, this field may only be set to `true`. If a question receives this answer, it will be excluded from any score calculations.
      &quot;numValue&quot;: 3.14, # Numerical value.
      &quot;score&quot;: 3.14, # Numerical score of the answer, used for generating the overall score of a QaScorecardResult. If the answer uses na_value, this field is unused.
      &quot;strValue&quot;: &quot;A String&quot;, # String value.
    },
  ],
  &quot;answerInstructions&quot;: &quot;A String&quot;, # Instructions describing how to determine the answer.
  &quot;createTime&quot;: &quot;A String&quot;, # Output only. The time at which this question was created.
  &quot;metrics&quot;: { # A wrapper representing metrics calculated against a test-set on a LLM that was fine tuned for this question. # Metrics of the underlying tuned LLM over a holdout/test set while fine tuning the underlying LLM for the given question. This field will only be populated if and only if the question is part of a scorecard revision that has been tuned.
    &quot;accuracy&quot;: 3.14, # Output only. Accuracy of the model. Measures the percentage of correct answers the model gave on the test set.
  },
  &quot;name&quot;: &quot;A String&quot;, # Identifier. The resource name of the question. Format: projects/{project}/locations/{location}/qaScorecards/{qa_scorecard}/revisions/{revision}/qaQuestions/{qa_question}
  &quot;order&quot;: 42, # Defines the order of the question within its parent scorecard revision.
  &quot;questionBody&quot;: &quot;A String&quot;, # Question text. E.g., &quot;Did the agent greet the customer?&quot;
  &quot;tags&quot;: [ # User-defined list of arbitrary tags for the question. Used for grouping/organization and for weighting the score of each question.
    &quot;A String&quot;,
  ],
  &quot;tuningMetadata&quot;: { # Metadata about the tuning operation for the question. Will only be set if a scorecard containing this question has been tuned. # Metadata about the tuning operation for the question.This field will only be populated if and only if the question is part of a scorecard revision that has been tuned.
    &quot;datasetValidationWarnings&quot;: [ # A list of any applicable data validation warnings about the question&#x27;s feedback labels.
      &quot;A String&quot;,
    ],
    &quot;totalValidLabelCount&quot;: &quot;A String&quot;, # Total number of valid labels provided for the question at the time of tuining.
    &quot;tuningError&quot;: &quot;A String&quot;, # Error status of the tuning operation for the question. Will only be set if the tuning operation failed.
  },
  &quot;updateTime&quot;: &quot;A String&quot;, # Output only. The most recent time at which the question was updated.
}</pre>
</div>

<div class="method">
    <code class="details" id="delete">delete(name, x__xgafv=None)</code>
  <pre>Deletes a QaQuestion.

Args:
  name: string, Required. The name of the QaQuestion to delete. (required)
  x__xgafv: string, V1 error format.
    Allowed values
      1 - v1 error format
      2 - v2 error format

Returns:
  An object of the form:

    { # A generic empty message that you can re-use to avoid defining duplicated empty messages in your APIs. A typical example is to use it as the request or the response type of an API method. For instance: service Foo { rpc Bar(google.protobuf.Empty) returns (google.protobuf.Empty); }
}</pre>
</div>

<div class="method">
    <code class="details" id="get">get(name, x__xgafv=None)</code>
  <pre>Gets a QaQuestion.

Args:
  name: string, Required. The name of the QaQuestion to get. (required)
  x__xgafv: string, V1 error format.
    Allowed values
      1 - v1 error format
      2 - v2 error format

Returns:
  An object of the form:

    { # A single question to be scored by the Insights QA feature.
  &quot;abbreviation&quot;: &quot;A String&quot;, # Short, descriptive string, used in the UI where it&#x27;s not practical to display the full question body. E.g., &quot;Greeting&quot;.
  &quot;answerChoices&quot;: [ # A list of valid answers to the question, which the LLM must choose from.
    { # Message representing a possible answer to the question.
      &quot;boolValue&quot;: True or False, # Boolean value.
      &quot;key&quot;: &quot;A String&quot;, # A short string used as an identifier.
      &quot;naValue&quot;: True or False, # A value of &quot;Not Applicable (N/A)&quot;. If provided, this field may only be set to `true`. If a question receives this answer, it will be excluded from any score calculations.
      &quot;numValue&quot;: 3.14, # Numerical value.
      &quot;score&quot;: 3.14, # Numerical score of the answer, used for generating the overall score of a QaScorecardResult. If the answer uses na_value, this field is unused.
      &quot;strValue&quot;: &quot;A String&quot;, # String value.
    },
  ],
  &quot;answerInstructions&quot;: &quot;A String&quot;, # Instructions describing how to determine the answer.
  &quot;createTime&quot;: &quot;A String&quot;, # Output only. The time at which this question was created.
  &quot;metrics&quot;: { # A wrapper representing metrics calculated against a test-set on a LLM that was fine tuned for this question. # Metrics of the underlying tuned LLM over a holdout/test set while fine tuning the underlying LLM for the given question. This field will only be populated if and only if the question is part of a scorecard revision that has been tuned.
    &quot;accuracy&quot;: 3.14, # Output only. Accuracy of the model. Measures the percentage of correct answers the model gave on the test set.
  },
  &quot;name&quot;: &quot;A String&quot;, # Identifier. The resource name of the question. Format: projects/{project}/locations/{location}/qaScorecards/{qa_scorecard}/revisions/{revision}/qaQuestions/{qa_question}
  &quot;order&quot;: 42, # Defines the order of the question within its parent scorecard revision.
  &quot;questionBody&quot;: &quot;A String&quot;, # Question text. E.g., &quot;Did the agent greet the customer?&quot;
  &quot;tags&quot;: [ # User-defined list of arbitrary tags for the question. Used for grouping/organization and for weighting the score of each question.
    &quot;A String&quot;,
  ],
  &quot;tuningMetadata&quot;: { # Metadata about the tuning operation for the question. Will only be set if a scorecard containing this question has been tuned. # Metadata about the tuning operation for the question.This field will only be populated if and only if the question is part of a scorecard revision that has been tuned.
    &quot;datasetValidationWarnings&quot;: [ # A list of any applicable data validation warnings about the question&#x27;s feedback labels.
      &quot;A String&quot;,
    ],
    &quot;totalValidLabelCount&quot;: &quot;A String&quot;, # Total number of valid labels provided for the question at the time of tuining.
    &quot;tuningError&quot;: &quot;A String&quot;, # Error status of the tuning operation for the question. Will only be set if the tuning operation failed.
  },
  &quot;updateTime&quot;: &quot;A String&quot;, # Output only. The most recent time at which the question was updated.
}</pre>
</div>

<div class="method">
    <code class="details" id="list">list(parent, pageSize=None, pageToken=None, x__xgafv=None)</code>
  <pre>Lists QaQuestions.

Args:
  parent: string, Required. The parent resource of the questions. (required)
  pageSize: integer, Optional. The maximum number of questions to return in the response. If the value is zero, the service will select a default size. A call might return fewer objects than requested. A non-empty `next_page_token` in the response indicates that more data is available.
  pageToken: string, Optional. The value returned by the last `ListQaQuestionsResponse`. This value indicates that this is a continuation of a prior `ListQaQuestions` call and that the system should return the next page of data.
  x__xgafv: string, V1 error format.
    Allowed values
      1 - v1 error format
      2 - v2 error format

Returns:
  An object of the form:

    { # The response from a ListQaQuestions request.
  &quot;nextPageToken&quot;: &quot;A String&quot;, # A token, which can be sent as `page_token` to retrieve the next page. If this field is omitted, there are no subsequent pages.
  &quot;qaQuestions&quot;: [ # The QaQuestions under the parent.
    { # A single question to be scored by the Insights QA feature.
      &quot;abbreviation&quot;: &quot;A String&quot;, # Short, descriptive string, used in the UI where it&#x27;s not practical to display the full question body. E.g., &quot;Greeting&quot;.
      &quot;answerChoices&quot;: [ # A list of valid answers to the question, which the LLM must choose from.
        { # Message representing a possible answer to the question.
          &quot;boolValue&quot;: True or False, # Boolean value.
          &quot;key&quot;: &quot;A String&quot;, # A short string used as an identifier.
          &quot;naValue&quot;: True or False, # A value of &quot;Not Applicable (N/A)&quot;. If provided, this field may only be set to `true`. If a question receives this answer, it will be excluded from any score calculations.
          &quot;numValue&quot;: 3.14, # Numerical value.
          &quot;score&quot;: 3.14, # Numerical score of the answer, used for generating the overall score of a QaScorecardResult. If the answer uses na_value, this field is unused.
          &quot;strValue&quot;: &quot;A String&quot;, # String value.
        },
      ],
      &quot;answerInstructions&quot;: &quot;A String&quot;, # Instructions describing how to determine the answer.
      &quot;createTime&quot;: &quot;A String&quot;, # Output only. The time at which this question was created.
      &quot;metrics&quot;: { # A wrapper representing metrics calculated against a test-set on a LLM that was fine tuned for this question. # Metrics of the underlying tuned LLM over a holdout/test set while fine tuning the underlying LLM for the given question. This field will only be populated if and only if the question is part of a scorecard revision that has been tuned.
        &quot;accuracy&quot;: 3.14, # Output only. Accuracy of the model. Measures the percentage of correct answers the model gave on the test set.
      },
      &quot;name&quot;: &quot;A String&quot;, # Identifier. The resource name of the question. Format: projects/{project}/locations/{location}/qaScorecards/{qa_scorecard}/revisions/{revision}/qaQuestions/{qa_question}
      &quot;order&quot;: 42, # Defines the order of the question within its parent scorecard revision.
      &quot;questionBody&quot;: &quot;A String&quot;, # Question text. E.g., &quot;Did the agent greet the customer?&quot;
      &quot;tags&quot;: [ # User-defined list of arbitrary tags for the question. Used for grouping/organization and for weighting the score of each question.
        &quot;A String&quot;,
      ],
      &quot;tuningMetadata&quot;: { # Metadata about the tuning operation for the question. Will only be set if a scorecard containing this question has been tuned. # Metadata about the tuning operation for the question.This field will only be populated if and only if the question is part of a scorecard revision that has been tuned.
        &quot;datasetValidationWarnings&quot;: [ # A list of any applicable data validation warnings about the question&#x27;s feedback labels.
          &quot;A String&quot;,
        ],
        &quot;totalValidLabelCount&quot;: &quot;A String&quot;, # Total number of valid labels provided for the question at the time of tuining.
        &quot;tuningError&quot;: &quot;A String&quot;, # Error status of the tuning operation for the question. Will only be set if the tuning operation failed.
      },
      &quot;updateTime&quot;: &quot;A String&quot;, # Output only. The most recent time at which the question was updated.
    },
  ],
}</pre>
</div>

<div class="method">
    <code class="details" id="list_next">list_next()</code>
  <pre>Retrieves the next page of results.

        Args:
          previous_request: The request for the previous page. (required)
          previous_response: The response from the request for the previous page. (required)

        Returns:
          A request object that you can call &#x27;execute()&#x27; on to request the next
          page. Returns None if there are no more items in the collection.
        </pre>
</div>

<div class="method">
    <code class="details" id="patch">patch(name, body=None, updateMask=None, x__xgafv=None)</code>
  <pre>Updates a QaQuestion.

Args:
  name: string, Identifier. The resource name of the question. Format: projects/{project}/locations/{location}/qaScorecards/{qa_scorecard}/revisions/{revision}/qaQuestions/{qa_question} (required)
  body: object, The request body.
    The object takes the form of:

{ # A single question to be scored by the Insights QA feature.
  &quot;abbreviation&quot;: &quot;A String&quot;, # Short, descriptive string, used in the UI where it&#x27;s not practical to display the full question body. E.g., &quot;Greeting&quot;.
  &quot;answerChoices&quot;: [ # A list of valid answers to the question, which the LLM must choose from.
    { # Message representing a possible answer to the question.
      &quot;boolValue&quot;: True or False, # Boolean value.
      &quot;key&quot;: &quot;A String&quot;, # A short string used as an identifier.
      &quot;naValue&quot;: True or False, # A value of &quot;Not Applicable (N/A)&quot;. If provided, this field may only be set to `true`. If a question receives this answer, it will be excluded from any score calculations.
      &quot;numValue&quot;: 3.14, # Numerical value.
      &quot;score&quot;: 3.14, # Numerical score of the answer, used for generating the overall score of a QaScorecardResult. If the answer uses na_value, this field is unused.
      &quot;strValue&quot;: &quot;A String&quot;, # String value.
    },
  ],
  &quot;answerInstructions&quot;: &quot;A String&quot;, # Instructions describing how to determine the answer.
  &quot;createTime&quot;: &quot;A String&quot;, # Output only. The time at which this question was created.
  &quot;metrics&quot;: { # A wrapper representing metrics calculated against a test-set on a LLM that was fine tuned for this question. # Metrics of the underlying tuned LLM over a holdout/test set while fine tuning the underlying LLM for the given question. This field will only be populated if and only if the question is part of a scorecard revision that has been tuned.
    &quot;accuracy&quot;: 3.14, # Output only. Accuracy of the model. Measures the percentage of correct answers the model gave on the test set.
  },
  &quot;name&quot;: &quot;A String&quot;, # Identifier. The resource name of the question. Format: projects/{project}/locations/{location}/qaScorecards/{qa_scorecard}/revisions/{revision}/qaQuestions/{qa_question}
  &quot;order&quot;: 42, # Defines the order of the question within its parent scorecard revision.
  &quot;questionBody&quot;: &quot;A String&quot;, # Question text. E.g., &quot;Did the agent greet the customer?&quot;
  &quot;tags&quot;: [ # User-defined list of arbitrary tags for the question. Used for grouping/organization and for weighting the score of each question.
    &quot;A String&quot;,
  ],
  &quot;tuningMetadata&quot;: { # Metadata about the tuning operation for the question. Will only be set if a scorecard containing this question has been tuned. # Metadata about the tuning operation for the question.This field will only be populated if and only if the question is part of a scorecard revision that has been tuned.
    &quot;datasetValidationWarnings&quot;: [ # A list of any applicable data validation warnings about the question&#x27;s feedback labels.
      &quot;A String&quot;,
    ],
    &quot;totalValidLabelCount&quot;: &quot;A String&quot;, # Total number of valid labels provided for the question at the time of tuining.
    &quot;tuningError&quot;: &quot;A String&quot;, # Error status of the tuning operation for the question. Will only be set if the tuning operation failed.
  },
  &quot;updateTime&quot;: &quot;A String&quot;, # Output only. The most recent time at which the question was updated.
}

  updateMask: string, Required. The list of fields to be updated. All possible fields can be updated by passing `*`, or a subset of the following updateable fields can be provided: * `abbreviation` * `answer_choices` * `answer_instructions` * `order` * `question_body` * `tags`
  x__xgafv: string, V1 error format.
    Allowed values
      1 - v1 error format
      2 - v2 error format

Returns:
  An object of the form:

    { # A single question to be scored by the Insights QA feature.
  &quot;abbreviation&quot;: &quot;A String&quot;, # Short, descriptive string, used in the UI where it&#x27;s not practical to display the full question body. E.g., &quot;Greeting&quot;.
  &quot;answerChoices&quot;: [ # A list of valid answers to the question, which the LLM must choose from.
    { # Message representing a possible answer to the question.
      &quot;boolValue&quot;: True or False, # Boolean value.
      &quot;key&quot;: &quot;A String&quot;, # A short string used as an identifier.
      &quot;naValue&quot;: True or False, # A value of &quot;Not Applicable (N/A)&quot;. If provided, this field may only be set to `true`. If a question receives this answer, it will be excluded from any score calculations.
      &quot;numValue&quot;: 3.14, # Numerical value.
      &quot;score&quot;: 3.14, # Numerical score of the answer, used for generating the overall score of a QaScorecardResult. If the answer uses na_value, this field is unused.
      &quot;strValue&quot;: &quot;A String&quot;, # String value.
    },
  ],
  &quot;answerInstructions&quot;: &quot;A String&quot;, # Instructions describing how to determine the answer.
  &quot;createTime&quot;: &quot;A String&quot;, # Output only. The time at which this question was created.
  &quot;metrics&quot;: { # A wrapper representing metrics calculated against a test-set on a LLM that was fine tuned for this question. # Metrics of the underlying tuned LLM over a holdout/test set while fine tuning the underlying LLM for the given question. This field will only be populated if and only if the question is part of a scorecard revision that has been tuned.
    &quot;accuracy&quot;: 3.14, # Output only. Accuracy of the model. Measures the percentage of correct answers the model gave on the test set.
  },
  &quot;name&quot;: &quot;A String&quot;, # Identifier. The resource name of the question. Format: projects/{project}/locations/{location}/qaScorecards/{qa_scorecard}/revisions/{revision}/qaQuestions/{qa_question}
  &quot;order&quot;: 42, # Defines the order of the question within its parent scorecard revision.
  &quot;questionBody&quot;: &quot;A String&quot;, # Question text. E.g., &quot;Did the agent greet the customer?&quot;
  &quot;tags&quot;: [ # User-defined list of arbitrary tags for the question. Used for grouping/organization and for weighting the score of each question.
    &quot;A String&quot;,
  ],
  &quot;tuningMetadata&quot;: { # Metadata about the tuning operation for the question. Will only be set if a scorecard containing this question has been tuned. # Metadata about the tuning operation for the question.This field will only be populated if and only if the question is part of a scorecard revision that has been tuned.
    &quot;datasetValidationWarnings&quot;: [ # A list of any applicable data validation warnings about the question&#x27;s feedback labels.
      &quot;A String&quot;,
    ],
    &quot;totalValidLabelCount&quot;: &quot;A String&quot;, # Total number of valid labels provided for the question at the time of tuining.
    &quot;tuningError&quot;: &quot;A String&quot;, # Error status of the tuning operation for the question. Will only be set if the tuning operation failed.
  },
  &quot;updateTime&quot;: &quot;A String&quot;, # Output only. The most recent time at which the question was updated.
}</pre>
</div>

</body></html>