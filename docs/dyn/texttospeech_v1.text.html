<html><body>
<style>

body, h1, h2, h3, div, span, p, pre, a {
  margin: 0;
  padding: 0;
  border: 0;
  font-weight: inherit;
  font-style: inherit;
  font-size: 100%;
  font-family: inherit;
  vertical-align: baseline;
}

body {
  font-size: 13px;
  padding: 1em;
}

h1 {
  font-size: 26px;
  margin-bottom: 1em;
}

h2 {
  font-size: 24px;
  margin-bottom: 1em;
}

h3 {
  font-size: 20px;
  margin-bottom: 1em;
  margin-top: 1em;
}

pre, code {
  line-height: 1.5;
  font-family: Monaco, 'DejaVu Sans Mono', 'Bitstream Vera Sans Mono', 'Lucida Console', monospace;
}

pre {
  margin-top: 0.5em;
}

h1, h2, h3, p {
  font-family: Arial, sans serif;
}

h1, h2, h3 {
  border-bottom: solid #CCC 1px;
}

.toc_element {
  margin-top: 0.5em;
}

.firstline {
  margin-left: 2 em;
}

.method  {
  margin-top: 1em;
  border: solid 1px #CCC;
  padding: 1em;
  background: #EEE;
}

.details {
  font-weight: bold;
  font-size: 14px;
}

</style>

<h1><a href="texttospeech_v1.html">Cloud Text-to-Speech API</a> . <a href="texttospeech_v1.text.html">text</a></h1>
<h2>Instance Methods</h2>
<p class="toc_element">
  <code><a href="#synthesize">synthesize(body=None, x__xgafv=None)</a></code></p>
<p class="firstline">Synthesizes speech synchronously: receive results after all text input</p>
<h3>Method Details</h3>
<div class="method">
    <code class="details" id="synthesize">synthesize(body=None, x__xgafv=None)</code>
  <pre>Synthesizes speech synchronously: receive results after all text input
has been processed.

Args:
  body: object, The request body.
    The object takes the form of:

{ # The top-level message sent by the client for the `SynthesizeSpeech` method.
    &quot;input&quot;: { # Contains text input to be synthesized. Either `text` or `ssml` must be # Required. The Synthesizer requires either plain text or SSML as input.
        # supplied. Supplying both or neither returns
        # google.rpc.Code.INVALID_ARGUMENT. The input size is limited to 5000
        # characters.
      &quot;ssml&quot;: &quot;A String&quot;, # The SSML document to be synthesized. The SSML document must be valid
          # and well-formed. Otherwise the RPC will fail and return
          # google.rpc.Code.INVALID_ARGUMENT. For more information, see
          # [SSML](/speech/text-to-speech/docs/ssml).
      &quot;text&quot;: &quot;A String&quot;, # The raw text to be synthesized.
    },
    &quot;voice&quot;: { # Description of which voice to use for a synthesis request. # Required. The desired voice of the synthesized audio.
      &quot;name&quot;: &quot;A String&quot;, # The name of the voice. If not set, the service will choose a
          # voice based on the other parameters such as language_code and gender.
      &quot;ssmlGender&quot;: &quot;A String&quot;, # The preferred gender of the voice. If not set, the service will
          # choose a voice based on the other parameters such as language_code and
          # name. Note that this is only a preference, not requirement; if a
          # voice of the appropriate gender is not available, the synthesizer should
          # substitute a voice with a different gender rather than failing the request.
      &quot;languageCode&quot;: &quot;A String&quot;, # Required. The language (and potentially also the region) of the voice expressed as a
          # [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag, e.g.
          # &quot;en-US&quot;. This should not include a script tag (e.g. use
          # &quot;cmn-cn&quot; rather than &quot;cmn-Hant-cn&quot;), because the script will be inferred
          # from the input provided in the SynthesisInput.  The TTS service
          # will use this parameter to help choose an appropriate voice.  Note that
          # the TTS service may choose a voice with a slightly different language code
          # than the one selected; it may substitute a different region
          # (e.g. using en-US rather than en-CA if there isn&#x27;t a Canadian voice
          # available), or even a different language, e.g. using &quot;nb&quot; (Norwegian
          # Bokmal) instead of &quot;no&quot; (Norwegian)&quot;.
    },
    &quot;audioConfig&quot;: { # Description of audio data to be synthesized. # Required. The configuration of the synthesized audio.
      &quot;volumeGainDb&quot;: 3.14, # Optional. Input only. Volume gain (in dB) of the normal native volume
          # supported by the specific voice, in the range [-96.0, 16.0]. If unset, or
          # set to a value of 0.0 (dB), will play at normal native signal amplitude. A
          # value of -6.0 (dB) will play at approximately half the amplitude of the
          # normal native signal amplitude. A value of +6.0 (dB) will play at
          # approximately twice the amplitude of the normal native signal amplitude.
          # Strongly recommend not to exceed +10 (dB) as there&#x27;s usually no effective
          # increase in loudness for any value greater than that.
      &quot;sampleRateHertz&quot;: 42, # Optional. The synthesis sample rate (in hertz) for this audio. When this is
          # specified in SynthesizeSpeechRequest, if this is different from the voice&#x27;s
          # natural sample rate, then the synthesizer will honor this request by
          # converting to the desired sample rate (which might result in worse audio
          # quality), unless the specified sample rate is not supported for the
          # encoding chosen, in which case it will fail the request and return
          # google.rpc.Code.INVALID_ARGUMENT.
      &quot;pitch&quot;: 3.14, # Optional. Input only. Speaking pitch, in the range [-20.0, 20.0]. 20 means
          # increase 20 semitones from the original pitch. -20 means decrease 20
          # semitones from the original pitch.
      &quot;speakingRate&quot;: 3.14, # Optional. Input only. Speaking rate/speed, in the range [0.25, 4.0]. 1.0 is
          # the normal native speed supported by the specific voice. 2.0 is twice as
          # fast, and 0.5 is half as fast. If unset(0.0), defaults to the native 1.0
          # speed. Any other values &lt; 0.25 or &gt; 4.0 will return an error.
      &quot;audioEncoding&quot;: &quot;A String&quot;, # Required. The format of the audio byte stream.
      &quot;effectsProfileId&quot;: [ # Optional. Input only. An identifier which selects &#x27;audio effects&#x27; profiles
          # that are applied on (post synthesized) text to speech. Effects are applied
          # on top of each other in the order they are given. See
          # [audio
          # profiles](https://cloud.google.com/text-to-speech/docs/audio-profiles) for
          # current supported profile ids.
        &quot;A String&quot;,
      ],
    },
  }

  x__xgafv: string, V1 error format.
    Allowed values
      1 - v1 error format
      2 - v2 error format

Returns:
  An object of the form:

    { # The message returned to the client by the `SynthesizeSpeech` method.
    &quot;audioContent&quot;: &quot;A String&quot;, # The audio data bytes encoded as specified in the request, including the
        # header for encodings that are wrapped in containers (e.g. MP3, OGG_OPUS).
        # For LINEAR16 audio, we include the WAV header. Note: as
        # with all bytes fields, protobuffers use a pure binary representation,
        # whereas JSON representations use base64.
  }</pre>
</div>

</body></html>