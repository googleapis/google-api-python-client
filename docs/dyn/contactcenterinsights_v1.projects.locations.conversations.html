<html><body>
<style>

body, h1, h2, h3, div, span, p, pre, a {
  margin: 0;
  padding: 0;
  border: 0;
  font-weight: inherit;
  font-style: inherit;
  font-size: 100%;
  font-family: inherit;
  vertical-align: baseline;
}

body {
  font-size: 13px;
  padding: 1em;
}

h1 {
  font-size: 26px;
  margin-bottom: 1em;
}

h2 {
  font-size: 24px;
  margin-bottom: 1em;
}

h3 {
  font-size: 20px;
  margin-bottom: 1em;
  margin-top: 1em;
}

pre, code {
  line-height: 1.5;
  font-family: Monaco, 'DejaVu Sans Mono', 'Bitstream Vera Sans Mono', 'Lucida Console', monospace;
}

pre {
  margin-top: 0.5em;
}

h1, h2, h3, p {
  font-family: Arial, sans serif;
}

h1, h2, h3 {
  border-bottom: solid #CCC 1px;
}

.toc_element {
  margin-top: 0.5em;
}

.firstline {
  margin-left: 2 em;
}

.method  {
  margin-top: 1em;
  border: solid 1px #CCC;
  padding: 1em;
  background: #EEE;
}

.details {
  font-weight: bold;
  font-size: 14px;
}

</style>

<h1><a href="contactcenterinsights_v1.html">Contact Center AI Insights API</a> . <a href="contactcenterinsights_v1.projects.html">projects</a> . <a href="contactcenterinsights_v1.projects.locations.html">locations</a> . <a href="contactcenterinsights_v1.projects.locations.conversations.html">conversations</a></h1>
<h2>Instance Methods</h2>
<p class="toc_element">
  <code><a href="contactcenterinsights_v1.projects.locations.conversations.analyses.html">analyses()</a></code>
</p>
<p class="firstline">Returns the analyses Resource.</p>

<p class="toc_element">
  <code><a href="#calculateStats">calculateStats(location, filter=None, x__xgafv=None)</a></code></p>
<p class="firstline">Gets conversation statistics.</p>
<p class="toc_element">
  <code><a href="#close">close()</a></code></p>
<p class="firstline">Close httplib2 connections.</p>
<p class="toc_element">
  <code><a href="#create">create(parent, body=None, conversationId=None, x__xgafv=None)</a></code></p>
<p class="firstline">Creates a conversation.</p>
<p class="toc_element">
  <code><a href="#delete">delete(name, force=None, x__xgafv=None)</a></code></p>
<p class="firstline">Deletes a conversation.</p>
<p class="toc_element">
  <code><a href="#get">get(name, view=None, x__xgafv=None)</a></code></p>
<p class="firstline">Gets a conversation.</p>
<p class="toc_element">
  <code><a href="#list">list(parent, filter=None, pageSize=None, pageToken=None, view=None, x__xgafv=None)</a></code></p>
<p class="firstline">Lists conversations.</p>
<p class="toc_element">
  <code><a href="#list_next">list_next(previous_request, previous_response)</a></code></p>
<p class="firstline">Retrieves the next page of results.</p>
<p class="toc_element">
  <code><a href="#patch">patch(name, body=None, updateMask=None, x__xgafv=None)</a></code></p>
<p class="firstline">Updates a conversation.</p>
<h3>Method Details</h3>
<div class="method">
    <code class="details" id="calculateStats">calculateStats(location, filter=None, x__xgafv=None)</code>
  <pre>Gets conversation statistics.

Args:
  location: string, Required. The location of the conversations. (required)
  filter: string, A filter to reduce results to a specific subset. This field is useful for getting statistics about conversations with specific properties.
  x__xgafv: string, V1 error format.
    Allowed values
      1 - v1 error format
      2 - v2 error format

Returns:
  An object of the form:

    { # The response for calculating conversation statistics.
  &quot;averageDuration&quot;: &quot;A String&quot;, # The average duration of all conversations. The average is calculated using only conversations that have a time duration.
  &quot;averageTurnCount&quot;: 42, # The average number of turns per conversation.
  &quot;conversationCount&quot;: 42, # The total number of conversations.
  &quot;conversationCountTimeSeries&quot;: { # A time series representing conversations over time. # A time series representing the count of conversations created over time that match that requested filter criteria.
    &quot;intervalDuration&quot;: &quot;A String&quot;, # The duration of each interval.
    &quot;points&quot;: [ # An ordered list of intervals from earliest to latest, where each interval represents the number of conversations that transpired during the time window.
      { # A single interval in a time series.
        &quot;conversationCount&quot;: 42, # The number of conversations created in this interval.
        &quot;startTime&quot;: &quot;A String&quot;, # The start time of this interval.
      },
    ],
  },
  &quot;customHighlighterMatches&quot;: { # A map associating each custom highlighter resource name with its respective number of matches in the set of conversations.
    &quot;a_key&quot;: 42,
  },
  &quot;issueMatches&quot;: { # A map associating each issue resource name with its respective number of matches in the set of conversations. Key has the format: `projects//locations//issueModels//issues/` Deprecated, use `issue_matches_stats` field instead.
    &quot;a_key&quot;: 42,
  },
  &quot;issueMatchesStats&quot;: { # A map associating each issue resource name with its respective number of matches in the set of conversations. Key has the format: `projects//locations//issueModels//issues/`
    &quot;a_key&quot;: { # Aggregated statistics about an issue.
      &quot;displayName&quot;: &quot;A String&quot;, # Display name of the issue.
      &quot;issue&quot;: &quot;A String&quot;, # Issue resource. Format: projects/{project}/locations/{location}/issueModels/{issue_model}/issues/{issue}
      &quot;labeledConversationsCount&quot;: &quot;A String&quot;, # Number of conversations attached to the issue at this point in time.
    },
  },
  &quot;smartHighlighterMatches&quot;: { # A map associating each smart highlighter display name with its respective number of matches in the set of conversations.
    &quot;a_key&quot;: 42,
  },
}</pre>
</div>

<div class="method">
    <code class="details" id="close">close()</code>
  <pre>Close httplib2 connections.</pre>
</div>

<div class="method">
    <code class="details" id="create">create(parent, body=None, conversationId=None, x__xgafv=None)</code>
  <pre>Creates a conversation.

Args:
  parent: string, Required. The parent resource of the conversation. (required)
  body: object, The request body.
    The object takes the form of:

{ # The conversation resource.
  &quot;agentId&quot;: &quot;A String&quot;, # An opaque, user-specified string representing the human agent who handled the conversation.
  &quot;callMetadata&quot;: { # Call-specific metadata. # Call-specific metadata.
    &quot;agentChannel&quot;: 42, # The audio channel that contains the agent.
    &quot;customerChannel&quot;: 42, # The audio channel that contains the customer.
  },
  &quot;createTime&quot;: &quot;A String&quot;, # Output only. The time at which the conversation was created.
  &quot;dataSource&quot;: { # The conversation source, which is a combination of transcript and audio. # The source of the audio and transcription for the conversation.
    &quot;dialogflowSource&quot;: { # A Dialogflow source of conversation data. # The source when the conversation comes from Dialogflow.
      &quot;audioUri&quot;: &quot;A String&quot;, # Cloud Storage URI that points to a file that contains the conversation audio.
      &quot;dialogflowConversation&quot;: &quot;A String&quot;, # Output only. The name of the Dialogflow conversation that this conversation resource is derived from. Format: projects/{project}/locations/{location}/conversations/{conversation}
    },
    &quot;gcsSource&quot;: { # A Cloud Storage source of conversation data. # A Cloud Storage location specification for the audio and transcript.
      &quot;audioUri&quot;: &quot;A String&quot;, # Cloud Storage URI that points to a file that contains the conversation audio.
      &quot;transcriptUri&quot;: &quot;A String&quot;, # Immutable. Cloud Storage URI that points to a file that contains the conversation transcript.
    },
  },
  &quot;dialogflowIntents&quot;: { # Output only. All the matched Dialogflow intents in the call. The key corresponds to a Dialogflow intent, format: projects/{project}/agent/{agent}/intents/{intent}
    &quot;a_key&quot;: { # The data for a Dialogflow intent. Represents a detected intent in the conversation, e.g. MAKES_PROMISE.
      &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the intent.
    },
  },
  &quot;duration&quot;: &quot;A String&quot;, # Output only. The duration of the conversation.
  &quot;expireTime&quot;: &quot;A String&quot;, # The time at which this conversation should expire. After this time, the conversation data and any associated analyses will be deleted.
  &quot;labels&quot;: { # A map for the user to specify any custom fields. A maximum of 20 labels per conversation is allowed, with a maximum of 256 characters per entry.
    &quot;a_key&quot;: &quot;A String&quot;,
  },
  &quot;languageCode&quot;: &quot;A String&quot;, # A user-specified language code for the conversation.
  &quot;latestAnalysis&quot;: { # The analysis resource. # Output only. The conversation&#x27;s latest analysis, if one exists.
    &quot;analysisResult&quot;: { # The result of an analysis. # Output only. The result of the analysis, which is populated when the analysis finishes.
      &quot;callAnalysisMetadata&quot;: { # Call-specific metadata created during analysis. # Call-specific metadata created by the analysis.
        &quot;annotations&quot;: [ # A list of call annotations that apply to this call.
          { # A piece of metadata that applies to a window of a call.
            &quot;annotationEndBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation ends, inclusive.
              &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
              &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
            },
            &quot;annotationStartBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation starts, inclusive.
              &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
              &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
            },
            &quot;channelTag&quot;: 42, # The channel of the audio where the annotation occurs. For single-channel audio, this field is not populated.
            &quot;entityMentionData&quot;: { # The data for an entity mention annotation. This represents a mention of an `Entity` in the conversation. # Data specifying an entity mention.
              &quot;entityUniqueId&quot;: &quot;A String&quot;, # The key of this entity in conversation entities. Can be used to retrieve the exact `Entity` this mention is attached to.
              &quot;sentiment&quot;: { # The data for a sentiment annotation. # Sentiment expressed for this mention of the entity.
                &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
                &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
              },
              &quot;type&quot;: &quot;A String&quot;, # The type of the entity mention.
            },
            &quot;holdData&quot;: { # The data for a hold annotation. # Data specifying a hold.
            },
            &quot;intentMatchData&quot;: { # The data for an intent match. Represents an intent match for a text segment in the conversation. A text segment can be part of a sentence, a complete sentence, or an utterance with multiple sentences. # Data specifying an intent match.
              &quot;intentUniqueId&quot;: &quot;A String&quot;, # The id of the matched intent. Can be used to retrieve the corresponding intent information.
            },
            &quot;interruptionData&quot;: { # The data for an interruption annotation. # Data specifying an interruption.
            },
            &quot;phraseMatchData&quot;: { # The data for a matched phrase matcher. Represents information identifying a phrase matcher for a given match. # Data specifying a phrase match.
              &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the phrase matcher.
              &quot;phraseMatcher&quot;: &quot;A String&quot;, # The unique identifier (the resource name) of the phrase matcher.
            },
            &quot;sentimentData&quot;: { # The data for a sentiment annotation. # Data specifying sentiment.
              &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
              &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
            },
            &quot;silenceData&quot;: { # The data for a silence annotation. # Data specifying silence.
            },
          },
        ],
        &quot;entities&quot;: { # All the entities in the call.
          &quot;a_key&quot;: { # The data for an entity annotation. Represents a phrase in the conversation that is a known entity, such as a person, an organization, or location.
            &quot;displayName&quot;: &quot;A String&quot;, # The representative name for the entity.
            &quot;metadata&quot;: { # Metadata associated with the entity. For most entity types, the metadata is a Wikipedia URL (`wikipedia_url`) and Knowledge Graph MID (`mid`), if they are available. For the metadata associated with other entity types, see the Type table below.
              &quot;a_key&quot;: &quot;A String&quot;,
            },
            &quot;salience&quot;: 3.14, # The salience score associated with the entity in the [0, 1.0] range. The salience score for an entity provides information about the importance or centrality of that entity to the entire document text. Scores closer to 0 are less salient, while scores closer to 1.0 are highly salient.
            &quot;sentiment&quot;: { # The data for a sentiment annotation. # The aggregate sentiment expressed for this entity in the conversation.
              &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
              &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
            },
            &quot;type&quot;: &quot;A String&quot;, # The entity type.
          },
        },
        &quot;intents&quot;: { # All the matched intents in the call.
          &quot;a_key&quot;: { # The data for an intent. Represents a detected intent in the conversation, for example MAKES_PROMISE.
            &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the intent.
            &quot;id&quot;: &quot;A String&quot;, # The unique identifier of the intent.
          },
        },
        &quot;issueModelResult&quot;: { # Issue Modeling result on a conversation. # Overall conversation-level issue modeling result.
          &quot;issueModel&quot;: &quot;A String&quot;, # Issue model that generates the result.
          &quot;issues&quot;: [ # All the matched issues.
            { # Information about the issue.
              &quot;displayName&quot;: &quot;A String&quot;, # Immutable. Display name of the assigned issue. This field is set at time of analyis and immutable since then.
              &quot;issue&quot;: &quot;A String&quot;, # Resource name of the assigned issue.
              &quot;score&quot;: 3.14, # Score indicating the likelihood of the issue assignment. currently bounded on [0,1].
            },
          ],
        },
        &quot;phraseMatchers&quot;: { # All the matched phrase matchers in the call.
          &quot;a_key&quot;: { # The data for a matched phrase matcher. Represents information identifying a phrase matcher for a given match.
            &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the phrase matcher.
            &quot;phraseMatcher&quot;: &quot;A String&quot;, # The unique identifier (the resource name) of the phrase matcher.
          },
        },
        &quot;sentiments&quot;: [ # Overall conversation-level sentiment for each channel of the call.
          { # One channel of conversation-level sentiment data.
            &quot;channelTag&quot;: 42, # The channel of the audio that the data applies to.
            &quot;sentimentData&quot;: { # The data for a sentiment annotation. # Data specifying sentiment.
              &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
              &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
            },
          },
        ],
      },
      &quot;endTime&quot;: &quot;A String&quot;, # The time at which the analysis ended.
    },
    &quot;createTime&quot;: &quot;A String&quot;, # Output only. The time at which the analysis was created, which occurs when the long-running operation completes.
    &quot;name&quot;: &quot;A String&quot;, # Immutable. The resource name of the analysis. Format: projects/{project}/locations/{location}/conversations/{conversation}/analyses/{analysis}
    &quot;requestTime&quot;: &quot;A String&quot;, # Output only. The time at which the analysis was requested.
  },
  &quot;medium&quot;: &quot;A String&quot;, # Immutable. The conversation medium, if unspecified will default to PHONE_CALL.
  &quot;name&quot;: &quot;A String&quot;, # Immutable. The resource name of the conversation. Format: projects/{project}/locations/{location}/conversations/{conversation}
  &quot;obfuscatedUserId&quot;: &quot;A String&quot;, # Obfuscated user ID which the customer sent to us.
  &quot;runtimeAnnotations&quot;: [ # Output only. The annotations that were generated during the customer and agent interaction.
    { # An annotation that was generated during the customer and agent interaction.
      &quot;annotationId&quot;: &quot;A String&quot;, # The unique identifier of the annotation. Format: projects/{project}/locations/{location}/conversationDatasets/{dataset}/conversationDataItems/{data_item}/conversationAnnotations/{annotation}
      &quot;answerFeedback&quot;: { # The feedback that the customer has about a certain answer in the conversation. # The feedback that the customer has about the answer in `data`.
        &quot;clicked&quot;: True or False, # Indicates whether an answer or item was clicked by the human agent.
        &quot;correctnessLevel&quot;: &quot;A String&quot;, # The correctness level of an answer.
        &quot;displayed&quot;: True or False, # Indicates whether an answer or item was displayed to the human agent in the agent desktop UI.
      },
      &quot;articleSuggestion&quot;: { # Agent Assist Article Suggestion data. # Agent Assist Article Suggestion data.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this article is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the Article Suggestion and the document that it originates from.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # Name of the query record. Format: projects/{project}/locations/{location}/queryRecords/{query_record}
        &quot;source&quot;: &quot;A String&quot;, # The knowledge document that this answer was extracted from. Format: projects/{project}/knowledgeBases/{knowledge_base}/documents/{document}
        &quot;title&quot;: &quot;A String&quot;, # Article title.
        &quot;uri&quot;: &quot;A String&quot;, # Article URI.
      },
      &quot;createTime&quot;: &quot;A String&quot;, # The time at which this annotation was created.
      &quot;dialogflowInteraction&quot;: { # Dialogflow interaction data. # Dialogflow interaction data.
        &quot;confidence&quot;: 3.14, # The confidence of the match ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;dialogflowIntentId&quot;: &quot;A String&quot;, # The Dialogflow intent resource path. Format: projects/{project}/agent/{agent}/intents/{intent}
      },
      &quot;endBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation ends, inclusive.
        &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
        &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
      },
      &quot;faqAnswer&quot;: { # Agent Assist frequently-asked-question answer data. # Agent Assist FAQ answer data.
        &quot;answer&quot;: &quot;A String&quot;, # The piece of text from the `source` knowledge base document.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this answer is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the FAQ answer and the document that it originates from.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # Name of the query record. Format: projects/{project}/locations/{location}/queryRecords/{query_record}.
        &quot;question&quot;: &quot;A String&quot;, # The corresponding FAQ question.
        &quot;source&quot;: &quot;A String&quot;, # The knowledge document that this answer was extracted from. Format: projects/{project}/knowledgeBases/{knowledge_base}/documents/{document}.
      },
      &quot;smartComposeSuggestion&quot;: { # Agent Assist Smart Compose suggestion data. # Agent Assist Smart Compose suggestion data.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this suggestion is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the Smart Compose suggestion and the document from which it originates.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # Name of the query record. Format: projects/{project}/locations/{location}/queryRecords/{query_record}
        &quot;suggestion&quot;: &quot;A String&quot;, # The content of the suggestion.
      },
      &quot;smartReply&quot;: { # Agent Assist Smart Reply data. # Agent Assist Smart Reply data.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this reply is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the Smart Reply and the document from which it originates.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # Name of the query record. Format: projects/{project}/locations/{location}/queryRecords/{query_record}
        &quot;reply&quot;: &quot;A String&quot;, # The content of the reply.
      },
      &quot;startBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation starts, inclusive.
        &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
        &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
      },
    },
  ],
  &quot;startTime&quot;: &quot;A String&quot;, # The time at which the conversation started.
  &quot;transcript&quot;: { # A message representing the transcript of a conversation. # Output only. The conversation transcript.
    &quot;transcriptSegments&quot;: [ # A list of sequential transcript segments that comprise the conversation.
      { # A segment of a full transcript.
        &quot;channelTag&quot;: 42, # For conversations derived from multi-channel audio, this is the channel number corresponding to the audio from that channel. For audioChannelCount = N, its output values can range from &#x27;1&#x27; to &#x27;N&#x27;. A channel tag of 0 indicates that the audio is mono.
        &quot;confidence&quot;: 3.14, # A confidence estimate between 0.0 and 1.0 of the fidelity of this segment. A default value of 0.0 indicates that the value is unset.
        &quot;dialogflowSegmentMetadata&quot;: { # Metadata from Dialogflow relating to the current transcript segment. # CCAI metadata relating to the current transcript segment.
          &quot;smartReplyAllowlistCovered&quot;: True or False, # Whether the transcript segment was covered under the configured smart reply allowlist in Agent Assist.
        },
        &quot;languageCode&quot;: &quot;A String&quot;, # The language code of this segment as a [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag. Example: &quot;en-US&quot;.
        &quot;messageTime&quot;: &quot;A String&quot;, # The time that the message occurred, if provided.
        &quot;segmentParticipant&quot;: { # The call participant speaking for a given utterance. # The participant of this segment.
          &quot;dialogflowParticipant&quot;: &quot;A String&quot;, # Deprecated. Use `dialogflow_participant_name` instead. The name of the Dialogflow participant. Format: projects/{project}/locations/{location}/conversations/{conversation}/participants/{participant}
          &quot;dialogflowParticipantName&quot;: &quot;A String&quot;, # The name of the participant provided by Dialogflow. Format: projects/{project}/locations/{location}/conversations/{conversation}/participants/{participant}
          &quot;obfuscatedExternalUserId&quot;: &quot;A String&quot;, # Obfuscated user ID from Dialogflow.
          &quot;role&quot;: &quot;A String&quot;, # The role of the participant.
          &quot;userId&quot;: &quot;A String&quot;, # A user-specified ID representing the participant.
        },
        &quot;sentiment&quot;: { # The data for a sentiment annotation. # The sentiment for this transcript segment.
          &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
          &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
        },
        &quot;text&quot;: &quot;A String&quot;, # The text of this segment.
        &quot;words&quot;: [ # A list of the word-specific information for each word in the segment.
          { # Word-level info for words in a transcript.
            &quot;confidence&quot;: 3.14, # A confidence estimate between 0.0 and 1.0 of the fidelity of this word. A default value of 0.0 indicates that the value is unset.
            &quot;endOffset&quot;: &quot;A String&quot;, # Time offset of the end of this word relative to the beginning of the total conversation.
            &quot;startOffset&quot;: &quot;A String&quot;, # Time offset of the start of this word relative to the beginning of the total conversation.
            &quot;word&quot;: &quot;A String&quot;, # The word itself. Includes punctuation marks that surround the word.
          },
        ],
      },
    ],
  },
  &quot;ttl&quot;: &quot;A String&quot;, # Input only. The TTL for this resource. If specified, then this TTL will be used to calculate the expire time.
  &quot;turnCount&quot;: 42, # Output only. The number of turns in the conversation.
  &quot;updateTime&quot;: &quot;A String&quot;, # Output only. The most recent time at which the conversation was updated.
}

  conversationId: string, A unique ID for the new conversation. This ID will become the final component of the conversation&#x27;s resource name. If no ID is specified, a server-generated ID will be used. This value should be 4-64 characters and must match the regular expression `^[a-z0-9-]{4,64}$`. Valid characters are `a-z-`
  x__xgafv: string, V1 error format.
    Allowed values
      1 - v1 error format
      2 - v2 error format

Returns:
  An object of the form:

    { # The conversation resource.
  &quot;agentId&quot;: &quot;A String&quot;, # An opaque, user-specified string representing the human agent who handled the conversation.
  &quot;callMetadata&quot;: { # Call-specific metadata. # Call-specific metadata.
    &quot;agentChannel&quot;: 42, # The audio channel that contains the agent.
    &quot;customerChannel&quot;: 42, # The audio channel that contains the customer.
  },
  &quot;createTime&quot;: &quot;A String&quot;, # Output only. The time at which the conversation was created.
  &quot;dataSource&quot;: { # The conversation source, which is a combination of transcript and audio. # The source of the audio and transcription for the conversation.
    &quot;dialogflowSource&quot;: { # A Dialogflow source of conversation data. # The source when the conversation comes from Dialogflow.
      &quot;audioUri&quot;: &quot;A String&quot;, # Cloud Storage URI that points to a file that contains the conversation audio.
      &quot;dialogflowConversation&quot;: &quot;A String&quot;, # Output only. The name of the Dialogflow conversation that this conversation resource is derived from. Format: projects/{project}/locations/{location}/conversations/{conversation}
    },
    &quot;gcsSource&quot;: { # A Cloud Storage source of conversation data. # A Cloud Storage location specification for the audio and transcript.
      &quot;audioUri&quot;: &quot;A String&quot;, # Cloud Storage URI that points to a file that contains the conversation audio.
      &quot;transcriptUri&quot;: &quot;A String&quot;, # Immutable. Cloud Storage URI that points to a file that contains the conversation transcript.
    },
  },
  &quot;dialogflowIntents&quot;: { # Output only. All the matched Dialogflow intents in the call. The key corresponds to a Dialogflow intent, format: projects/{project}/agent/{agent}/intents/{intent}
    &quot;a_key&quot;: { # The data for a Dialogflow intent. Represents a detected intent in the conversation, e.g. MAKES_PROMISE.
      &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the intent.
    },
  },
  &quot;duration&quot;: &quot;A String&quot;, # Output only. The duration of the conversation.
  &quot;expireTime&quot;: &quot;A String&quot;, # The time at which this conversation should expire. After this time, the conversation data and any associated analyses will be deleted.
  &quot;labels&quot;: { # A map for the user to specify any custom fields. A maximum of 20 labels per conversation is allowed, with a maximum of 256 characters per entry.
    &quot;a_key&quot;: &quot;A String&quot;,
  },
  &quot;languageCode&quot;: &quot;A String&quot;, # A user-specified language code for the conversation.
  &quot;latestAnalysis&quot;: { # The analysis resource. # Output only. The conversation&#x27;s latest analysis, if one exists.
    &quot;analysisResult&quot;: { # The result of an analysis. # Output only. The result of the analysis, which is populated when the analysis finishes.
      &quot;callAnalysisMetadata&quot;: { # Call-specific metadata created during analysis. # Call-specific metadata created by the analysis.
        &quot;annotations&quot;: [ # A list of call annotations that apply to this call.
          { # A piece of metadata that applies to a window of a call.
            &quot;annotationEndBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation ends, inclusive.
              &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
              &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
            },
            &quot;annotationStartBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation starts, inclusive.
              &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
              &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
            },
            &quot;channelTag&quot;: 42, # The channel of the audio where the annotation occurs. For single-channel audio, this field is not populated.
            &quot;entityMentionData&quot;: { # The data for an entity mention annotation. This represents a mention of an `Entity` in the conversation. # Data specifying an entity mention.
              &quot;entityUniqueId&quot;: &quot;A String&quot;, # The key of this entity in conversation entities. Can be used to retrieve the exact `Entity` this mention is attached to.
              &quot;sentiment&quot;: { # The data for a sentiment annotation. # Sentiment expressed for this mention of the entity.
                &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
                &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
              },
              &quot;type&quot;: &quot;A String&quot;, # The type of the entity mention.
            },
            &quot;holdData&quot;: { # The data for a hold annotation. # Data specifying a hold.
            },
            &quot;intentMatchData&quot;: { # The data for an intent match. Represents an intent match for a text segment in the conversation. A text segment can be part of a sentence, a complete sentence, or an utterance with multiple sentences. # Data specifying an intent match.
              &quot;intentUniqueId&quot;: &quot;A String&quot;, # The id of the matched intent. Can be used to retrieve the corresponding intent information.
            },
            &quot;interruptionData&quot;: { # The data for an interruption annotation. # Data specifying an interruption.
            },
            &quot;phraseMatchData&quot;: { # The data for a matched phrase matcher. Represents information identifying a phrase matcher for a given match. # Data specifying a phrase match.
              &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the phrase matcher.
              &quot;phraseMatcher&quot;: &quot;A String&quot;, # The unique identifier (the resource name) of the phrase matcher.
            },
            &quot;sentimentData&quot;: { # The data for a sentiment annotation. # Data specifying sentiment.
              &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
              &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
            },
            &quot;silenceData&quot;: { # The data for a silence annotation. # Data specifying silence.
            },
          },
        ],
        &quot;entities&quot;: { # All the entities in the call.
          &quot;a_key&quot;: { # The data for an entity annotation. Represents a phrase in the conversation that is a known entity, such as a person, an organization, or location.
            &quot;displayName&quot;: &quot;A String&quot;, # The representative name for the entity.
            &quot;metadata&quot;: { # Metadata associated with the entity. For most entity types, the metadata is a Wikipedia URL (`wikipedia_url`) and Knowledge Graph MID (`mid`), if they are available. For the metadata associated with other entity types, see the Type table below.
              &quot;a_key&quot;: &quot;A String&quot;,
            },
            &quot;salience&quot;: 3.14, # The salience score associated with the entity in the [0, 1.0] range. The salience score for an entity provides information about the importance or centrality of that entity to the entire document text. Scores closer to 0 are less salient, while scores closer to 1.0 are highly salient.
            &quot;sentiment&quot;: { # The data for a sentiment annotation. # The aggregate sentiment expressed for this entity in the conversation.
              &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
              &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
            },
            &quot;type&quot;: &quot;A String&quot;, # The entity type.
          },
        },
        &quot;intents&quot;: { # All the matched intents in the call.
          &quot;a_key&quot;: { # The data for an intent. Represents a detected intent in the conversation, for example MAKES_PROMISE.
            &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the intent.
            &quot;id&quot;: &quot;A String&quot;, # The unique identifier of the intent.
          },
        },
        &quot;issueModelResult&quot;: { # Issue Modeling result on a conversation. # Overall conversation-level issue modeling result.
          &quot;issueModel&quot;: &quot;A String&quot;, # Issue model that generates the result.
          &quot;issues&quot;: [ # All the matched issues.
            { # Information about the issue.
              &quot;displayName&quot;: &quot;A String&quot;, # Immutable. Display name of the assigned issue. This field is set at time of analyis and immutable since then.
              &quot;issue&quot;: &quot;A String&quot;, # Resource name of the assigned issue.
              &quot;score&quot;: 3.14, # Score indicating the likelihood of the issue assignment. currently bounded on [0,1].
            },
          ],
        },
        &quot;phraseMatchers&quot;: { # All the matched phrase matchers in the call.
          &quot;a_key&quot;: { # The data for a matched phrase matcher. Represents information identifying a phrase matcher for a given match.
            &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the phrase matcher.
            &quot;phraseMatcher&quot;: &quot;A String&quot;, # The unique identifier (the resource name) of the phrase matcher.
          },
        },
        &quot;sentiments&quot;: [ # Overall conversation-level sentiment for each channel of the call.
          { # One channel of conversation-level sentiment data.
            &quot;channelTag&quot;: 42, # The channel of the audio that the data applies to.
            &quot;sentimentData&quot;: { # The data for a sentiment annotation. # Data specifying sentiment.
              &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
              &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
            },
          },
        ],
      },
      &quot;endTime&quot;: &quot;A String&quot;, # The time at which the analysis ended.
    },
    &quot;createTime&quot;: &quot;A String&quot;, # Output only. The time at which the analysis was created, which occurs when the long-running operation completes.
    &quot;name&quot;: &quot;A String&quot;, # Immutable. The resource name of the analysis. Format: projects/{project}/locations/{location}/conversations/{conversation}/analyses/{analysis}
    &quot;requestTime&quot;: &quot;A String&quot;, # Output only. The time at which the analysis was requested.
  },
  &quot;medium&quot;: &quot;A String&quot;, # Immutable. The conversation medium, if unspecified will default to PHONE_CALL.
  &quot;name&quot;: &quot;A String&quot;, # Immutable. The resource name of the conversation. Format: projects/{project}/locations/{location}/conversations/{conversation}
  &quot;obfuscatedUserId&quot;: &quot;A String&quot;, # Obfuscated user ID which the customer sent to us.
  &quot;runtimeAnnotations&quot;: [ # Output only. The annotations that were generated during the customer and agent interaction.
    { # An annotation that was generated during the customer and agent interaction.
      &quot;annotationId&quot;: &quot;A String&quot;, # The unique identifier of the annotation. Format: projects/{project}/locations/{location}/conversationDatasets/{dataset}/conversationDataItems/{data_item}/conversationAnnotations/{annotation}
      &quot;answerFeedback&quot;: { # The feedback that the customer has about a certain answer in the conversation. # The feedback that the customer has about the answer in `data`.
        &quot;clicked&quot;: True or False, # Indicates whether an answer or item was clicked by the human agent.
        &quot;correctnessLevel&quot;: &quot;A String&quot;, # The correctness level of an answer.
        &quot;displayed&quot;: True or False, # Indicates whether an answer or item was displayed to the human agent in the agent desktop UI.
      },
      &quot;articleSuggestion&quot;: { # Agent Assist Article Suggestion data. # Agent Assist Article Suggestion data.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this article is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the Article Suggestion and the document that it originates from.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # Name of the query record. Format: projects/{project}/locations/{location}/queryRecords/{query_record}
        &quot;source&quot;: &quot;A String&quot;, # The knowledge document that this answer was extracted from. Format: projects/{project}/knowledgeBases/{knowledge_base}/documents/{document}
        &quot;title&quot;: &quot;A String&quot;, # Article title.
        &quot;uri&quot;: &quot;A String&quot;, # Article URI.
      },
      &quot;createTime&quot;: &quot;A String&quot;, # The time at which this annotation was created.
      &quot;dialogflowInteraction&quot;: { # Dialogflow interaction data. # Dialogflow interaction data.
        &quot;confidence&quot;: 3.14, # The confidence of the match ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;dialogflowIntentId&quot;: &quot;A String&quot;, # The Dialogflow intent resource path. Format: projects/{project}/agent/{agent}/intents/{intent}
      },
      &quot;endBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation ends, inclusive.
        &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
        &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
      },
      &quot;faqAnswer&quot;: { # Agent Assist frequently-asked-question answer data. # Agent Assist FAQ answer data.
        &quot;answer&quot;: &quot;A String&quot;, # The piece of text from the `source` knowledge base document.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this answer is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the FAQ answer and the document that it originates from.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # Name of the query record. Format: projects/{project}/locations/{location}/queryRecords/{query_record}.
        &quot;question&quot;: &quot;A String&quot;, # The corresponding FAQ question.
        &quot;source&quot;: &quot;A String&quot;, # The knowledge document that this answer was extracted from. Format: projects/{project}/knowledgeBases/{knowledge_base}/documents/{document}.
      },
      &quot;smartComposeSuggestion&quot;: { # Agent Assist Smart Compose suggestion data. # Agent Assist Smart Compose suggestion data.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this suggestion is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the Smart Compose suggestion and the document from which it originates.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # Name of the query record. Format: projects/{project}/locations/{location}/queryRecords/{query_record}
        &quot;suggestion&quot;: &quot;A String&quot;, # The content of the suggestion.
      },
      &quot;smartReply&quot;: { # Agent Assist Smart Reply data. # Agent Assist Smart Reply data.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this reply is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the Smart Reply and the document from which it originates.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # Name of the query record. Format: projects/{project}/locations/{location}/queryRecords/{query_record}
        &quot;reply&quot;: &quot;A String&quot;, # The content of the reply.
      },
      &quot;startBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation starts, inclusive.
        &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
        &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
      },
    },
  ],
  &quot;startTime&quot;: &quot;A String&quot;, # The time at which the conversation started.
  &quot;transcript&quot;: { # A message representing the transcript of a conversation. # Output only. The conversation transcript.
    &quot;transcriptSegments&quot;: [ # A list of sequential transcript segments that comprise the conversation.
      { # A segment of a full transcript.
        &quot;channelTag&quot;: 42, # For conversations derived from multi-channel audio, this is the channel number corresponding to the audio from that channel. For audioChannelCount = N, its output values can range from &#x27;1&#x27; to &#x27;N&#x27;. A channel tag of 0 indicates that the audio is mono.
        &quot;confidence&quot;: 3.14, # A confidence estimate between 0.0 and 1.0 of the fidelity of this segment. A default value of 0.0 indicates that the value is unset.
        &quot;dialogflowSegmentMetadata&quot;: { # Metadata from Dialogflow relating to the current transcript segment. # CCAI metadata relating to the current transcript segment.
          &quot;smartReplyAllowlistCovered&quot;: True or False, # Whether the transcript segment was covered under the configured smart reply allowlist in Agent Assist.
        },
        &quot;languageCode&quot;: &quot;A String&quot;, # The language code of this segment as a [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag. Example: &quot;en-US&quot;.
        &quot;messageTime&quot;: &quot;A String&quot;, # The time that the message occurred, if provided.
        &quot;segmentParticipant&quot;: { # The call participant speaking for a given utterance. # The participant of this segment.
          &quot;dialogflowParticipant&quot;: &quot;A String&quot;, # Deprecated. Use `dialogflow_participant_name` instead. The name of the Dialogflow participant. Format: projects/{project}/locations/{location}/conversations/{conversation}/participants/{participant}
          &quot;dialogflowParticipantName&quot;: &quot;A String&quot;, # The name of the participant provided by Dialogflow. Format: projects/{project}/locations/{location}/conversations/{conversation}/participants/{participant}
          &quot;obfuscatedExternalUserId&quot;: &quot;A String&quot;, # Obfuscated user ID from Dialogflow.
          &quot;role&quot;: &quot;A String&quot;, # The role of the participant.
          &quot;userId&quot;: &quot;A String&quot;, # A user-specified ID representing the participant.
        },
        &quot;sentiment&quot;: { # The data for a sentiment annotation. # The sentiment for this transcript segment.
          &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
          &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
        },
        &quot;text&quot;: &quot;A String&quot;, # The text of this segment.
        &quot;words&quot;: [ # A list of the word-specific information for each word in the segment.
          { # Word-level info for words in a transcript.
            &quot;confidence&quot;: 3.14, # A confidence estimate between 0.0 and 1.0 of the fidelity of this word. A default value of 0.0 indicates that the value is unset.
            &quot;endOffset&quot;: &quot;A String&quot;, # Time offset of the end of this word relative to the beginning of the total conversation.
            &quot;startOffset&quot;: &quot;A String&quot;, # Time offset of the start of this word relative to the beginning of the total conversation.
            &quot;word&quot;: &quot;A String&quot;, # The word itself. Includes punctuation marks that surround the word.
          },
        ],
      },
    ],
  },
  &quot;ttl&quot;: &quot;A String&quot;, # Input only. The TTL for this resource. If specified, then this TTL will be used to calculate the expire time.
  &quot;turnCount&quot;: 42, # Output only. The number of turns in the conversation.
  &quot;updateTime&quot;: &quot;A String&quot;, # Output only. The most recent time at which the conversation was updated.
}</pre>
</div>

<div class="method">
    <code class="details" id="delete">delete(name, force=None, x__xgafv=None)</code>
  <pre>Deletes a conversation.

Args:
  name: string, Required. The name of the conversation to delete. (required)
  force: boolean, If set to true, all of this conversation&#x27;s analyses will also be deleted. Otherwise, the request will only succeed if the conversation has no analyses.
  x__xgafv: string, V1 error format.
    Allowed values
      1 - v1 error format
      2 - v2 error format

Returns:
  An object of the form:

    { # A generic empty message that you can re-use to avoid defining duplicated empty messages in your APIs. A typical example is to use it as the request or the response type of an API method. For instance: service Foo { rpc Bar(google.protobuf.Empty) returns (google.protobuf.Empty); } The JSON representation for `Empty` is empty JSON object `{}`.
}</pre>
</div>

<div class="method">
    <code class="details" id="get">get(name, view=None, x__xgafv=None)</code>
  <pre>Gets a conversation.

Args:
  name: string, Required. The name of the conversation to get. (required)
  view: string, The level of details of the conversation. Default is `FULL`.
    Allowed values
      CONVERSATION_VIEW_UNSPECIFIED - Not specified. Defaults to FULL on GetConversationRequest and BASIC for ListConversationsRequest.
      BASIC - Transcript field is not populated in the response for Insights conversation.
      FULL - All fields are populated for Insights conversation.
  x__xgafv: string, V1 error format.
    Allowed values
      1 - v1 error format
      2 - v2 error format

Returns:
  An object of the form:

    { # The conversation resource.
  &quot;agentId&quot;: &quot;A String&quot;, # An opaque, user-specified string representing the human agent who handled the conversation.
  &quot;callMetadata&quot;: { # Call-specific metadata. # Call-specific metadata.
    &quot;agentChannel&quot;: 42, # The audio channel that contains the agent.
    &quot;customerChannel&quot;: 42, # The audio channel that contains the customer.
  },
  &quot;createTime&quot;: &quot;A String&quot;, # Output only. The time at which the conversation was created.
  &quot;dataSource&quot;: { # The conversation source, which is a combination of transcript and audio. # The source of the audio and transcription for the conversation.
    &quot;dialogflowSource&quot;: { # A Dialogflow source of conversation data. # The source when the conversation comes from Dialogflow.
      &quot;audioUri&quot;: &quot;A String&quot;, # Cloud Storage URI that points to a file that contains the conversation audio.
      &quot;dialogflowConversation&quot;: &quot;A String&quot;, # Output only. The name of the Dialogflow conversation that this conversation resource is derived from. Format: projects/{project}/locations/{location}/conversations/{conversation}
    },
    &quot;gcsSource&quot;: { # A Cloud Storage source of conversation data. # A Cloud Storage location specification for the audio and transcript.
      &quot;audioUri&quot;: &quot;A String&quot;, # Cloud Storage URI that points to a file that contains the conversation audio.
      &quot;transcriptUri&quot;: &quot;A String&quot;, # Immutable. Cloud Storage URI that points to a file that contains the conversation transcript.
    },
  },
  &quot;dialogflowIntents&quot;: { # Output only. All the matched Dialogflow intents in the call. The key corresponds to a Dialogflow intent, format: projects/{project}/agent/{agent}/intents/{intent}
    &quot;a_key&quot;: { # The data for a Dialogflow intent. Represents a detected intent in the conversation, e.g. MAKES_PROMISE.
      &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the intent.
    },
  },
  &quot;duration&quot;: &quot;A String&quot;, # Output only. The duration of the conversation.
  &quot;expireTime&quot;: &quot;A String&quot;, # The time at which this conversation should expire. After this time, the conversation data and any associated analyses will be deleted.
  &quot;labels&quot;: { # A map for the user to specify any custom fields. A maximum of 20 labels per conversation is allowed, with a maximum of 256 characters per entry.
    &quot;a_key&quot;: &quot;A String&quot;,
  },
  &quot;languageCode&quot;: &quot;A String&quot;, # A user-specified language code for the conversation.
  &quot;latestAnalysis&quot;: { # The analysis resource. # Output only. The conversation&#x27;s latest analysis, if one exists.
    &quot;analysisResult&quot;: { # The result of an analysis. # Output only. The result of the analysis, which is populated when the analysis finishes.
      &quot;callAnalysisMetadata&quot;: { # Call-specific metadata created during analysis. # Call-specific metadata created by the analysis.
        &quot;annotations&quot;: [ # A list of call annotations that apply to this call.
          { # A piece of metadata that applies to a window of a call.
            &quot;annotationEndBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation ends, inclusive.
              &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
              &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
            },
            &quot;annotationStartBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation starts, inclusive.
              &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
              &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
            },
            &quot;channelTag&quot;: 42, # The channel of the audio where the annotation occurs. For single-channel audio, this field is not populated.
            &quot;entityMentionData&quot;: { # The data for an entity mention annotation. This represents a mention of an `Entity` in the conversation. # Data specifying an entity mention.
              &quot;entityUniqueId&quot;: &quot;A String&quot;, # The key of this entity in conversation entities. Can be used to retrieve the exact `Entity` this mention is attached to.
              &quot;sentiment&quot;: { # The data for a sentiment annotation. # Sentiment expressed for this mention of the entity.
                &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
                &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
              },
              &quot;type&quot;: &quot;A String&quot;, # The type of the entity mention.
            },
            &quot;holdData&quot;: { # The data for a hold annotation. # Data specifying a hold.
            },
            &quot;intentMatchData&quot;: { # The data for an intent match. Represents an intent match for a text segment in the conversation. A text segment can be part of a sentence, a complete sentence, or an utterance with multiple sentences. # Data specifying an intent match.
              &quot;intentUniqueId&quot;: &quot;A String&quot;, # The id of the matched intent. Can be used to retrieve the corresponding intent information.
            },
            &quot;interruptionData&quot;: { # The data for an interruption annotation. # Data specifying an interruption.
            },
            &quot;phraseMatchData&quot;: { # The data for a matched phrase matcher. Represents information identifying a phrase matcher for a given match. # Data specifying a phrase match.
              &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the phrase matcher.
              &quot;phraseMatcher&quot;: &quot;A String&quot;, # The unique identifier (the resource name) of the phrase matcher.
            },
            &quot;sentimentData&quot;: { # The data for a sentiment annotation. # Data specifying sentiment.
              &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
              &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
            },
            &quot;silenceData&quot;: { # The data for a silence annotation. # Data specifying silence.
            },
          },
        ],
        &quot;entities&quot;: { # All the entities in the call.
          &quot;a_key&quot;: { # The data for an entity annotation. Represents a phrase in the conversation that is a known entity, such as a person, an organization, or location.
            &quot;displayName&quot;: &quot;A String&quot;, # The representative name for the entity.
            &quot;metadata&quot;: { # Metadata associated with the entity. For most entity types, the metadata is a Wikipedia URL (`wikipedia_url`) and Knowledge Graph MID (`mid`), if they are available. For the metadata associated with other entity types, see the Type table below.
              &quot;a_key&quot;: &quot;A String&quot;,
            },
            &quot;salience&quot;: 3.14, # The salience score associated with the entity in the [0, 1.0] range. The salience score for an entity provides information about the importance or centrality of that entity to the entire document text. Scores closer to 0 are less salient, while scores closer to 1.0 are highly salient.
            &quot;sentiment&quot;: { # The data for a sentiment annotation. # The aggregate sentiment expressed for this entity in the conversation.
              &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
              &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
            },
            &quot;type&quot;: &quot;A String&quot;, # The entity type.
          },
        },
        &quot;intents&quot;: { # All the matched intents in the call.
          &quot;a_key&quot;: { # The data for an intent. Represents a detected intent in the conversation, for example MAKES_PROMISE.
            &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the intent.
            &quot;id&quot;: &quot;A String&quot;, # The unique identifier of the intent.
          },
        },
        &quot;issueModelResult&quot;: { # Issue Modeling result on a conversation. # Overall conversation-level issue modeling result.
          &quot;issueModel&quot;: &quot;A String&quot;, # Issue model that generates the result.
          &quot;issues&quot;: [ # All the matched issues.
            { # Information about the issue.
              &quot;displayName&quot;: &quot;A String&quot;, # Immutable. Display name of the assigned issue. This field is set at time of analyis and immutable since then.
              &quot;issue&quot;: &quot;A String&quot;, # Resource name of the assigned issue.
              &quot;score&quot;: 3.14, # Score indicating the likelihood of the issue assignment. currently bounded on [0,1].
            },
          ],
        },
        &quot;phraseMatchers&quot;: { # All the matched phrase matchers in the call.
          &quot;a_key&quot;: { # The data for a matched phrase matcher. Represents information identifying a phrase matcher for a given match.
            &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the phrase matcher.
            &quot;phraseMatcher&quot;: &quot;A String&quot;, # The unique identifier (the resource name) of the phrase matcher.
          },
        },
        &quot;sentiments&quot;: [ # Overall conversation-level sentiment for each channel of the call.
          { # One channel of conversation-level sentiment data.
            &quot;channelTag&quot;: 42, # The channel of the audio that the data applies to.
            &quot;sentimentData&quot;: { # The data for a sentiment annotation. # Data specifying sentiment.
              &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
              &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
            },
          },
        ],
      },
      &quot;endTime&quot;: &quot;A String&quot;, # The time at which the analysis ended.
    },
    &quot;createTime&quot;: &quot;A String&quot;, # Output only. The time at which the analysis was created, which occurs when the long-running operation completes.
    &quot;name&quot;: &quot;A String&quot;, # Immutable. The resource name of the analysis. Format: projects/{project}/locations/{location}/conversations/{conversation}/analyses/{analysis}
    &quot;requestTime&quot;: &quot;A String&quot;, # Output only. The time at which the analysis was requested.
  },
  &quot;medium&quot;: &quot;A String&quot;, # Immutable. The conversation medium, if unspecified will default to PHONE_CALL.
  &quot;name&quot;: &quot;A String&quot;, # Immutable. The resource name of the conversation. Format: projects/{project}/locations/{location}/conversations/{conversation}
  &quot;obfuscatedUserId&quot;: &quot;A String&quot;, # Obfuscated user ID which the customer sent to us.
  &quot;runtimeAnnotations&quot;: [ # Output only. The annotations that were generated during the customer and agent interaction.
    { # An annotation that was generated during the customer and agent interaction.
      &quot;annotationId&quot;: &quot;A String&quot;, # The unique identifier of the annotation. Format: projects/{project}/locations/{location}/conversationDatasets/{dataset}/conversationDataItems/{data_item}/conversationAnnotations/{annotation}
      &quot;answerFeedback&quot;: { # The feedback that the customer has about a certain answer in the conversation. # The feedback that the customer has about the answer in `data`.
        &quot;clicked&quot;: True or False, # Indicates whether an answer or item was clicked by the human agent.
        &quot;correctnessLevel&quot;: &quot;A String&quot;, # The correctness level of an answer.
        &quot;displayed&quot;: True or False, # Indicates whether an answer or item was displayed to the human agent in the agent desktop UI.
      },
      &quot;articleSuggestion&quot;: { # Agent Assist Article Suggestion data. # Agent Assist Article Suggestion data.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this article is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the Article Suggestion and the document that it originates from.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # Name of the query record. Format: projects/{project}/locations/{location}/queryRecords/{query_record}
        &quot;source&quot;: &quot;A String&quot;, # The knowledge document that this answer was extracted from. Format: projects/{project}/knowledgeBases/{knowledge_base}/documents/{document}
        &quot;title&quot;: &quot;A String&quot;, # Article title.
        &quot;uri&quot;: &quot;A String&quot;, # Article URI.
      },
      &quot;createTime&quot;: &quot;A String&quot;, # The time at which this annotation was created.
      &quot;dialogflowInteraction&quot;: { # Dialogflow interaction data. # Dialogflow interaction data.
        &quot;confidence&quot;: 3.14, # The confidence of the match ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;dialogflowIntentId&quot;: &quot;A String&quot;, # The Dialogflow intent resource path. Format: projects/{project}/agent/{agent}/intents/{intent}
      },
      &quot;endBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation ends, inclusive.
        &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
        &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
      },
      &quot;faqAnswer&quot;: { # Agent Assist frequently-asked-question answer data. # Agent Assist FAQ answer data.
        &quot;answer&quot;: &quot;A String&quot;, # The piece of text from the `source` knowledge base document.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this answer is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the FAQ answer and the document that it originates from.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # Name of the query record. Format: projects/{project}/locations/{location}/queryRecords/{query_record}.
        &quot;question&quot;: &quot;A String&quot;, # The corresponding FAQ question.
        &quot;source&quot;: &quot;A String&quot;, # The knowledge document that this answer was extracted from. Format: projects/{project}/knowledgeBases/{knowledge_base}/documents/{document}.
      },
      &quot;smartComposeSuggestion&quot;: { # Agent Assist Smart Compose suggestion data. # Agent Assist Smart Compose suggestion data.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this suggestion is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the Smart Compose suggestion and the document from which it originates.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # Name of the query record. Format: projects/{project}/locations/{location}/queryRecords/{query_record}
        &quot;suggestion&quot;: &quot;A String&quot;, # The content of the suggestion.
      },
      &quot;smartReply&quot;: { # Agent Assist Smart Reply data. # Agent Assist Smart Reply data.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this reply is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the Smart Reply and the document from which it originates.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # Name of the query record. Format: projects/{project}/locations/{location}/queryRecords/{query_record}
        &quot;reply&quot;: &quot;A String&quot;, # The content of the reply.
      },
      &quot;startBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation starts, inclusive.
        &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
        &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
      },
    },
  ],
  &quot;startTime&quot;: &quot;A String&quot;, # The time at which the conversation started.
  &quot;transcript&quot;: { # A message representing the transcript of a conversation. # Output only. The conversation transcript.
    &quot;transcriptSegments&quot;: [ # A list of sequential transcript segments that comprise the conversation.
      { # A segment of a full transcript.
        &quot;channelTag&quot;: 42, # For conversations derived from multi-channel audio, this is the channel number corresponding to the audio from that channel. For audioChannelCount = N, its output values can range from &#x27;1&#x27; to &#x27;N&#x27;. A channel tag of 0 indicates that the audio is mono.
        &quot;confidence&quot;: 3.14, # A confidence estimate between 0.0 and 1.0 of the fidelity of this segment. A default value of 0.0 indicates that the value is unset.
        &quot;dialogflowSegmentMetadata&quot;: { # Metadata from Dialogflow relating to the current transcript segment. # CCAI metadata relating to the current transcript segment.
          &quot;smartReplyAllowlistCovered&quot;: True or False, # Whether the transcript segment was covered under the configured smart reply allowlist in Agent Assist.
        },
        &quot;languageCode&quot;: &quot;A String&quot;, # The language code of this segment as a [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag. Example: &quot;en-US&quot;.
        &quot;messageTime&quot;: &quot;A String&quot;, # The time that the message occurred, if provided.
        &quot;segmentParticipant&quot;: { # The call participant speaking for a given utterance. # The participant of this segment.
          &quot;dialogflowParticipant&quot;: &quot;A String&quot;, # Deprecated. Use `dialogflow_participant_name` instead. The name of the Dialogflow participant. Format: projects/{project}/locations/{location}/conversations/{conversation}/participants/{participant}
          &quot;dialogflowParticipantName&quot;: &quot;A String&quot;, # The name of the participant provided by Dialogflow. Format: projects/{project}/locations/{location}/conversations/{conversation}/participants/{participant}
          &quot;obfuscatedExternalUserId&quot;: &quot;A String&quot;, # Obfuscated user ID from Dialogflow.
          &quot;role&quot;: &quot;A String&quot;, # The role of the participant.
          &quot;userId&quot;: &quot;A String&quot;, # A user-specified ID representing the participant.
        },
        &quot;sentiment&quot;: { # The data for a sentiment annotation. # The sentiment for this transcript segment.
          &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
          &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
        },
        &quot;text&quot;: &quot;A String&quot;, # The text of this segment.
        &quot;words&quot;: [ # A list of the word-specific information for each word in the segment.
          { # Word-level info for words in a transcript.
            &quot;confidence&quot;: 3.14, # A confidence estimate between 0.0 and 1.0 of the fidelity of this word. A default value of 0.0 indicates that the value is unset.
            &quot;endOffset&quot;: &quot;A String&quot;, # Time offset of the end of this word relative to the beginning of the total conversation.
            &quot;startOffset&quot;: &quot;A String&quot;, # Time offset of the start of this word relative to the beginning of the total conversation.
            &quot;word&quot;: &quot;A String&quot;, # The word itself. Includes punctuation marks that surround the word.
          },
        ],
      },
    ],
  },
  &quot;ttl&quot;: &quot;A String&quot;, # Input only. The TTL for this resource. If specified, then this TTL will be used to calculate the expire time.
  &quot;turnCount&quot;: 42, # Output only. The number of turns in the conversation.
  &quot;updateTime&quot;: &quot;A String&quot;, # Output only. The most recent time at which the conversation was updated.
}</pre>
</div>

<div class="method">
    <code class="details" id="list">list(parent, filter=None, pageSize=None, pageToken=None, view=None, x__xgafv=None)</code>
  <pre>Lists conversations.

Args:
  parent: string, Required. The parent resource of the conversation. (required)
  filter: string, A filter to reduce results to a specific subset. Useful for querying conversations with specific properties.
  pageSize: integer, The maximum number of conversations to return in the response. A valid page size ranges from 0 to 1,000 inclusive. If the page size is zero or unspecified, a default page size of 100 will be chosen. Note that a call might return fewer results than the requested page size.
  pageToken: string, The value returned by the last `ListConversationsResponse`. This value indicates that this is a continuation of a prior `ListConversations` call and that the system should return the next page of data.
  view: string, The level of details of the conversation. Default is `BASIC`.
    Allowed values
      CONVERSATION_VIEW_UNSPECIFIED - Not specified. Defaults to FULL on GetConversationRequest and BASIC for ListConversationsRequest.
      BASIC - Transcript field is not populated in the response for Insights conversation.
      FULL - All fields are populated for Insights conversation.
  x__xgafv: string, V1 error format.
    Allowed values
      1 - v1 error format
      2 - v2 error format

Returns:
  An object of the form:

    { # The response of listing conversations.
  &quot;conversations&quot;: [ # The conversations that match the request.
    { # The conversation resource.
      &quot;agentId&quot;: &quot;A String&quot;, # An opaque, user-specified string representing the human agent who handled the conversation.
      &quot;callMetadata&quot;: { # Call-specific metadata. # Call-specific metadata.
        &quot;agentChannel&quot;: 42, # The audio channel that contains the agent.
        &quot;customerChannel&quot;: 42, # The audio channel that contains the customer.
      },
      &quot;createTime&quot;: &quot;A String&quot;, # Output only. The time at which the conversation was created.
      &quot;dataSource&quot;: { # The conversation source, which is a combination of transcript and audio. # The source of the audio and transcription for the conversation.
        &quot;dialogflowSource&quot;: { # A Dialogflow source of conversation data. # The source when the conversation comes from Dialogflow.
          &quot;audioUri&quot;: &quot;A String&quot;, # Cloud Storage URI that points to a file that contains the conversation audio.
          &quot;dialogflowConversation&quot;: &quot;A String&quot;, # Output only. The name of the Dialogflow conversation that this conversation resource is derived from. Format: projects/{project}/locations/{location}/conversations/{conversation}
        },
        &quot;gcsSource&quot;: { # A Cloud Storage source of conversation data. # A Cloud Storage location specification for the audio and transcript.
          &quot;audioUri&quot;: &quot;A String&quot;, # Cloud Storage URI that points to a file that contains the conversation audio.
          &quot;transcriptUri&quot;: &quot;A String&quot;, # Immutable. Cloud Storage URI that points to a file that contains the conversation transcript.
        },
      },
      &quot;dialogflowIntents&quot;: { # Output only. All the matched Dialogflow intents in the call. The key corresponds to a Dialogflow intent, format: projects/{project}/agent/{agent}/intents/{intent}
        &quot;a_key&quot;: { # The data for a Dialogflow intent. Represents a detected intent in the conversation, e.g. MAKES_PROMISE.
          &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the intent.
        },
      },
      &quot;duration&quot;: &quot;A String&quot;, # Output only. The duration of the conversation.
      &quot;expireTime&quot;: &quot;A String&quot;, # The time at which this conversation should expire. After this time, the conversation data and any associated analyses will be deleted.
      &quot;labels&quot;: { # A map for the user to specify any custom fields. A maximum of 20 labels per conversation is allowed, with a maximum of 256 characters per entry.
        &quot;a_key&quot;: &quot;A String&quot;,
      },
      &quot;languageCode&quot;: &quot;A String&quot;, # A user-specified language code for the conversation.
      &quot;latestAnalysis&quot;: { # The analysis resource. # Output only. The conversation&#x27;s latest analysis, if one exists.
        &quot;analysisResult&quot;: { # The result of an analysis. # Output only. The result of the analysis, which is populated when the analysis finishes.
          &quot;callAnalysisMetadata&quot;: { # Call-specific metadata created during analysis. # Call-specific metadata created by the analysis.
            &quot;annotations&quot;: [ # A list of call annotations that apply to this call.
              { # A piece of metadata that applies to a window of a call.
                &quot;annotationEndBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation ends, inclusive.
                  &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
                  &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
                },
                &quot;annotationStartBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation starts, inclusive.
                  &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
                  &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
                },
                &quot;channelTag&quot;: 42, # The channel of the audio where the annotation occurs. For single-channel audio, this field is not populated.
                &quot;entityMentionData&quot;: { # The data for an entity mention annotation. This represents a mention of an `Entity` in the conversation. # Data specifying an entity mention.
                  &quot;entityUniqueId&quot;: &quot;A String&quot;, # The key of this entity in conversation entities. Can be used to retrieve the exact `Entity` this mention is attached to.
                  &quot;sentiment&quot;: { # The data for a sentiment annotation. # Sentiment expressed for this mention of the entity.
                    &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
                    &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
                  },
                  &quot;type&quot;: &quot;A String&quot;, # The type of the entity mention.
                },
                &quot;holdData&quot;: { # The data for a hold annotation. # Data specifying a hold.
                },
                &quot;intentMatchData&quot;: { # The data for an intent match. Represents an intent match for a text segment in the conversation. A text segment can be part of a sentence, a complete sentence, or an utterance with multiple sentences. # Data specifying an intent match.
                  &quot;intentUniqueId&quot;: &quot;A String&quot;, # The id of the matched intent. Can be used to retrieve the corresponding intent information.
                },
                &quot;interruptionData&quot;: { # The data for an interruption annotation. # Data specifying an interruption.
                },
                &quot;phraseMatchData&quot;: { # The data for a matched phrase matcher. Represents information identifying a phrase matcher for a given match. # Data specifying a phrase match.
                  &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the phrase matcher.
                  &quot;phraseMatcher&quot;: &quot;A String&quot;, # The unique identifier (the resource name) of the phrase matcher.
                },
                &quot;sentimentData&quot;: { # The data for a sentiment annotation. # Data specifying sentiment.
                  &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
                  &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
                },
                &quot;silenceData&quot;: { # The data for a silence annotation. # Data specifying silence.
                },
              },
            ],
            &quot;entities&quot;: { # All the entities in the call.
              &quot;a_key&quot;: { # The data for an entity annotation. Represents a phrase in the conversation that is a known entity, such as a person, an organization, or location.
                &quot;displayName&quot;: &quot;A String&quot;, # The representative name for the entity.
                &quot;metadata&quot;: { # Metadata associated with the entity. For most entity types, the metadata is a Wikipedia URL (`wikipedia_url`) and Knowledge Graph MID (`mid`), if they are available. For the metadata associated with other entity types, see the Type table below.
                  &quot;a_key&quot;: &quot;A String&quot;,
                },
                &quot;salience&quot;: 3.14, # The salience score associated with the entity in the [0, 1.0] range. The salience score for an entity provides information about the importance or centrality of that entity to the entire document text. Scores closer to 0 are less salient, while scores closer to 1.0 are highly salient.
                &quot;sentiment&quot;: { # The data for a sentiment annotation. # The aggregate sentiment expressed for this entity in the conversation.
                  &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
                  &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
                },
                &quot;type&quot;: &quot;A String&quot;, # The entity type.
              },
            },
            &quot;intents&quot;: { # All the matched intents in the call.
              &quot;a_key&quot;: { # The data for an intent. Represents a detected intent in the conversation, for example MAKES_PROMISE.
                &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the intent.
                &quot;id&quot;: &quot;A String&quot;, # The unique identifier of the intent.
              },
            },
            &quot;issueModelResult&quot;: { # Issue Modeling result on a conversation. # Overall conversation-level issue modeling result.
              &quot;issueModel&quot;: &quot;A String&quot;, # Issue model that generates the result.
              &quot;issues&quot;: [ # All the matched issues.
                { # Information about the issue.
                  &quot;displayName&quot;: &quot;A String&quot;, # Immutable. Display name of the assigned issue. This field is set at time of analyis and immutable since then.
                  &quot;issue&quot;: &quot;A String&quot;, # Resource name of the assigned issue.
                  &quot;score&quot;: 3.14, # Score indicating the likelihood of the issue assignment. currently bounded on [0,1].
                },
              ],
            },
            &quot;phraseMatchers&quot;: { # All the matched phrase matchers in the call.
              &quot;a_key&quot;: { # The data for a matched phrase matcher. Represents information identifying a phrase matcher for a given match.
                &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the phrase matcher.
                &quot;phraseMatcher&quot;: &quot;A String&quot;, # The unique identifier (the resource name) of the phrase matcher.
              },
            },
            &quot;sentiments&quot;: [ # Overall conversation-level sentiment for each channel of the call.
              { # One channel of conversation-level sentiment data.
                &quot;channelTag&quot;: 42, # The channel of the audio that the data applies to.
                &quot;sentimentData&quot;: { # The data for a sentiment annotation. # Data specifying sentiment.
                  &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
                  &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
                },
              },
            ],
          },
          &quot;endTime&quot;: &quot;A String&quot;, # The time at which the analysis ended.
        },
        &quot;createTime&quot;: &quot;A String&quot;, # Output only. The time at which the analysis was created, which occurs when the long-running operation completes.
        &quot;name&quot;: &quot;A String&quot;, # Immutable. The resource name of the analysis. Format: projects/{project}/locations/{location}/conversations/{conversation}/analyses/{analysis}
        &quot;requestTime&quot;: &quot;A String&quot;, # Output only. The time at which the analysis was requested.
      },
      &quot;medium&quot;: &quot;A String&quot;, # Immutable. The conversation medium, if unspecified will default to PHONE_CALL.
      &quot;name&quot;: &quot;A String&quot;, # Immutable. The resource name of the conversation. Format: projects/{project}/locations/{location}/conversations/{conversation}
      &quot;obfuscatedUserId&quot;: &quot;A String&quot;, # Obfuscated user ID which the customer sent to us.
      &quot;runtimeAnnotations&quot;: [ # Output only. The annotations that were generated during the customer and agent interaction.
        { # An annotation that was generated during the customer and agent interaction.
          &quot;annotationId&quot;: &quot;A String&quot;, # The unique identifier of the annotation. Format: projects/{project}/locations/{location}/conversationDatasets/{dataset}/conversationDataItems/{data_item}/conversationAnnotations/{annotation}
          &quot;answerFeedback&quot;: { # The feedback that the customer has about a certain answer in the conversation. # The feedback that the customer has about the answer in `data`.
            &quot;clicked&quot;: True or False, # Indicates whether an answer or item was clicked by the human agent.
            &quot;correctnessLevel&quot;: &quot;A String&quot;, # The correctness level of an answer.
            &quot;displayed&quot;: True or False, # Indicates whether an answer or item was displayed to the human agent in the agent desktop UI.
          },
          &quot;articleSuggestion&quot;: { # Agent Assist Article Suggestion data. # Agent Assist Article Suggestion data.
            &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this article is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
            &quot;metadata&quot;: { # Map that contains metadata about the Article Suggestion and the document that it originates from.
              &quot;a_key&quot;: &quot;A String&quot;,
            },
            &quot;queryRecord&quot;: &quot;A String&quot;, # Name of the query record. Format: projects/{project}/locations/{location}/queryRecords/{query_record}
            &quot;source&quot;: &quot;A String&quot;, # The knowledge document that this answer was extracted from. Format: projects/{project}/knowledgeBases/{knowledge_base}/documents/{document}
            &quot;title&quot;: &quot;A String&quot;, # Article title.
            &quot;uri&quot;: &quot;A String&quot;, # Article URI.
          },
          &quot;createTime&quot;: &quot;A String&quot;, # The time at which this annotation was created.
          &quot;dialogflowInteraction&quot;: { # Dialogflow interaction data. # Dialogflow interaction data.
            &quot;confidence&quot;: 3.14, # The confidence of the match ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
            &quot;dialogflowIntentId&quot;: &quot;A String&quot;, # The Dialogflow intent resource path. Format: projects/{project}/agent/{agent}/intents/{intent}
          },
          &quot;endBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation ends, inclusive.
            &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
            &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
          },
          &quot;faqAnswer&quot;: { # Agent Assist frequently-asked-question answer data. # Agent Assist FAQ answer data.
            &quot;answer&quot;: &quot;A String&quot;, # The piece of text from the `source` knowledge base document.
            &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this answer is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
            &quot;metadata&quot;: { # Map that contains metadata about the FAQ answer and the document that it originates from.
              &quot;a_key&quot;: &quot;A String&quot;,
            },
            &quot;queryRecord&quot;: &quot;A String&quot;, # Name of the query record. Format: projects/{project}/locations/{location}/queryRecords/{query_record}.
            &quot;question&quot;: &quot;A String&quot;, # The corresponding FAQ question.
            &quot;source&quot;: &quot;A String&quot;, # The knowledge document that this answer was extracted from. Format: projects/{project}/knowledgeBases/{knowledge_base}/documents/{document}.
          },
          &quot;smartComposeSuggestion&quot;: { # Agent Assist Smart Compose suggestion data. # Agent Assist Smart Compose suggestion data.
            &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this suggestion is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
            &quot;metadata&quot;: { # Map that contains metadata about the Smart Compose suggestion and the document from which it originates.
              &quot;a_key&quot;: &quot;A String&quot;,
            },
            &quot;queryRecord&quot;: &quot;A String&quot;, # Name of the query record. Format: projects/{project}/locations/{location}/queryRecords/{query_record}
            &quot;suggestion&quot;: &quot;A String&quot;, # The content of the suggestion.
          },
          &quot;smartReply&quot;: { # Agent Assist Smart Reply data. # Agent Assist Smart Reply data.
            &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this reply is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
            &quot;metadata&quot;: { # Map that contains metadata about the Smart Reply and the document from which it originates.
              &quot;a_key&quot;: &quot;A String&quot;,
            },
            &quot;queryRecord&quot;: &quot;A String&quot;, # Name of the query record. Format: projects/{project}/locations/{location}/queryRecords/{query_record}
            &quot;reply&quot;: &quot;A String&quot;, # The content of the reply.
          },
          &quot;startBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation starts, inclusive.
            &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
            &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
          },
        },
      ],
      &quot;startTime&quot;: &quot;A String&quot;, # The time at which the conversation started.
      &quot;transcript&quot;: { # A message representing the transcript of a conversation. # Output only. The conversation transcript.
        &quot;transcriptSegments&quot;: [ # A list of sequential transcript segments that comprise the conversation.
          { # A segment of a full transcript.
            &quot;channelTag&quot;: 42, # For conversations derived from multi-channel audio, this is the channel number corresponding to the audio from that channel. For audioChannelCount = N, its output values can range from &#x27;1&#x27; to &#x27;N&#x27;. A channel tag of 0 indicates that the audio is mono.
            &quot;confidence&quot;: 3.14, # A confidence estimate between 0.0 and 1.0 of the fidelity of this segment. A default value of 0.0 indicates that the value is unset.
            &quot;dialogflowSegmentMetadata&quot;: { # Metadata from Dialogflow relating to the current transcript segment. # CCAI metadata relating to the current transcript segment.
              &quot;smartReplyAllowlistCovered&quot;: True or False, # Whether the transcript segment was covered under the configured smart reply allowlist in Agent Assist.
            },
            &quot;languageCode&quot;: &quot;A String&quot;, # The language code of this segment as a [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag. Example: &quot;en-US&quot;.
            &quot;messageTime&quot;: &quot;A String&quot;, # The time that the message occurred, if provided.
            &quot;segmentParticipant&quot;: { # The call participant speaking for a given utterance. # The participant of this segment.
              &quot;dialogflowParticipant&quot;: &quot;A String&quot;, # Deprecated. Use `dialogflow_participant_name` instead. The name of the Dialogflow participant. Format: projects/{project}/locations/{location}/conversations/{conversation}/participants/{participant}
              &quot;dialogflowParticipantName&quot;: &quot;A String&quot;, # The name of the participant provided by Dialogflow. Format: projects/{project}/locations/{location}/conversations/{conversation}/participants/{participant}
              &quot;obfuscatedExternalUserId&quot;: &quot;A String&quot;, # Obfuscated user ID from Dialogflow.
              &quot;role&quot;: &quot;A String&quot;, # The role of the participant.
              &quot;userId&quot;: &quot;A String&quot;, # A user-specified ID representing the participant.
            },
            &quot;sentiment&quot;: { # The data for a sentiment annotation. # The sentiment for this transcript segment.
              &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
              &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
            },
            &quot;text&quot;: &quot;A String&quot;, # The text of this segment.
            &quot;words&quot;: [ # A list of the word-specific information for each word in the segment.
              { # Word-level info for words in a transcript.
                &quot;confidence&quot;: 3.14, # A confidence estimate between 0.0 and 1.0 of the fidelity of this word. A default value of 0.0 indicates that the value is unset.
                &quot;endOffset&quot;: &quot;A String&quot;, # Time offset of the end of this word relative to the beginning of the total conversation.
                &quot;startOffset&quot;: &quot;A String&quot;, # Time offset of the start of this word relative to the beginning of the total conversation.
                &quot;word&quot;: &quot;A String&quot;, # The word itself. Includes punctuation marks that surround the word.
              },
            ],
          },
        ],
      },
      &quot;ttl&quot;: &quot;A String&quot;, # Input only. The TTL for this resource. If specified, then this TTL will be used to calculate the expire time.
      &quot;turnCount&quot;: 42, # Output only. The number of turns in the conversation.
      &quot;updateTime&quot;: &quot;A String&quot;, # Output only. The most recent time at which the conversation was updated.
    },
  ],
  &quot;nextPageToken&quot;: &quot;A String&quot;, # A token which can be sent as `page_token` to retrieve the next page. If this field is set, it means there is another page available. If it is not set, it means no other pages are available.
}</pre>
</div>

<div class="method">
    <code class="details" id="list_next">list_next(previous_request, previous_response)</code>
  <pre>Retrieves the next page of results.

Args:
  previous_request: The request for the previous page. (required)
  previous_response: The response from the request for the previous page. (required)

Returns:
  A request object that you can call &#x27;execute()&#x27; on to request the next
  page. Returns None if there are no more items in the collection.
    </pre>
</div>

<div class="method">
    <code class="details" id="patch">patch(name, body=None, updateMask=None, x__xgafv=None)</code>
  <pre>Updates a conversation.

Args:
  name: string, Immutable. The resource name of the conversation. Format: projects/{project}/locations/{location}/conversations/{conversation} (required)
  body: object, The request body.
    The object takes the form of:

{ # The conversation resource.
  &quot;agentId&quot;: &quot;A String&quot;, # An opaque, user-specified string representing the human agent who handled the conversation.
  &quot;callMetadata&quot;: { # Call-specific metadata. # Call-specific metadata.
    &quot;agentChannel&quot;: 42, # The audio channel that contains the agent.
    &quot;customerChannel&quot;: 42, # The audio channel that contains the customer.
  },
  &quot;createTime&quot;: &quot;A String&quot;, # Output only. The time at which the conversation was created.
  &quot;dataSource&quot;: { # The conversation source, which is a combination of transcript and audio. # The source of the audio and transcription for the conversation.
    &quot;dialogflowSource&quot;: { # A Dialogflow source of conversation data. # The source when the conversation comes from Dialogflow.
      &quot;audioUri&quot;: &quot;A String&quot;, # Cloud Storage URI that points to a file that contains the conversation audio.
      &quot;dialogflowConversation&quot;: &quot;A String&quot;, # Output only. The name of the Dialogflow conversation that this conversation resource is derived from. Format: projects/{project}/locations/{location}/conversations/{conversation}
    },
    &quot;gcsSource&quot;: { # A Cloud Storage source of conversation data. # A Cloud Storage location specification for the audio and transcript.
      &quot;audioUri&quot;: &quot;A String&quot;, # Cloud Storage URI that points to a file that contains the conversation audio.
      &quot;transcriptUri&quot;: &quot;A String&quot;, # Immutable. Cloud Storage URI that points to a file that contains the conversation transcript.
    },
  },
  &quot;dialogflowIntents&quot;: { # Output only. All the matched Dialogflow intents in the call. The key corresponds to a Dialogflow intent, format: projects/{project}/agent/{agent}/intents/{intent}
    &quot;a_key&quot;: { # The data for a Dialogflow intent. Represents a detected intent in the conversation, e.g. MAKES_PROMISE.
      &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the intent.
    },
  },
  &quot;duration&quot;: &quot;A String&quot;, # Output only. The duration of the conversation.
  &quot;expireTime&quot;: &quot;A String&quot;, # The time at which this conversation should expire. After this time, the conversation data and any associated analyses will be deleted.
  &quot;labels&quot;: { # A map for the user to specify any custom fields. A maximum of 20 labels per conversation is allowed, with a maximum of 256 characters per entry.
    &quot;a_key&quot;: &quot;A String&quot;,
  },
  &quot;languageCode&quot;: &quot;A String&quot;, # A user-specified language code for the conversation.
  &quot;latestAnalysis&quot;: { # The analysis resource. # Output only. The conversation&#x27;s latest analysis, if one exists.
    &quot;analysisResult&quot;: { # The result of an analysis. # Output only. The result of the analysis, which is populated when the analysis finishes.
      &quot;callAnalysisMetadata&quot;: { # Call-specific metadata created during analysis. # Call-specific metadata created by the analysis.
        &quot;annotations&quot;: [ # A list of call annotations that apply to this call.
          { # A piece of metadata that applies to a window of a call.
            &quot;annotationEndBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation ends, inclusive.
              &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
              &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
            },
            &quot;annotationStartBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation starts, inclusive.
              &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
              &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
            },
            &quot;channelTag&quot;: 42, # The channel of the audio where the annotation occurs. For single-channel audio, this field is not populated.
            &quot;entityMentionData&quot;: { # The data for an entity mention annotation. This represents a mention of an `Entity` in the conversation. # Data specifying an entity mention.
              &quot;entityUniqueId&quot;: &quot;A String&quot;, # The key of this entity in conversation entities. Can be used to retrieve the exact `Entity` this mention is attached to.
              &quot;sentiment&quot;: { # The data for a sentiment annotation. # Sentiment expressed for this mention of the entity.
                &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
                &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
              },
              &quot;type&quot;: &quot;A String&quot;, # The type of the entity mention.
            },
            &quot;holdData&quot;: { # The data for a hold annotation. # Data specifying a hold.
            },
            &quot;intentMatchData&quot;: { # The data for an intent match. Represents an intent match for a text segment in the conversation. A text segment can be part of a sentence, a complete sentence, or an utterance with multiple sentences. # Data specifying an intent match.
              &quot;intentUniqueId&quot;: &quot;A String&quot;, # The id of the matched intent. Can be used to retrieve the corresponding intent information.
            },
            &quot;interruptionData&quot;: { # The data for an interruption annotation. # Data specifying an interruption.
            },
            &quot;phraseMatchData&quot;: { # The data for a matched phrase matcher. Represents information identifying a phrase matcher for a given match. # Data specifying a phrase match.
              &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the phrase matcher.
              &quot;phraseMatcher&quot;: &quot;A String&quot;, # The unique identifier (the resource name) of the phrase matcher.
            },
            &quot;sentimentData&quot;: { # The data for a sentiment annotation. # Data specifying sentiment.
              &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
              &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
            },
            &quot;silenceData&quot;: { # The data for a silence annotation. # Data specifying silence.
            },
          },
        ],
        &quot;entities&quot;: { # All the entities in the call.
          &quot;a_key&quot;: { # The data for an entity annotation. Represents a phrase in the conversation that is a known entity, such as a person, an organization, or location.
            &quot;displayName&quot;: &quot;A String&quot;, # The representative name for the entity.
            &quot;metadata&quot;: { # Metadata associated with the entity. For most entity types, the metadata is a Wikipedia URL (`wikipedia_url`) and Knowledge Graph MID (`mid`), if they are available. For the metadata associated with other entity types, see the Type table below.
              &quot;a_key&quot;: &quot;A String&quot;,
            },
            &quot;salience&quot;: 3.14, # The salience score associated with the entity in the [0, 1.0] range. The salience score for an entity provides information about the importance or centrality of that entity to the entire document text. Scores closer to 0 are less salient, while scores closer to 1.0 are highly salient.
            &quot;sentiment&quot;: { # The data for a sentiment annotation. # The aggregate sentiment expressed for this entity in the conversation.
              &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
              &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
            },
            &quot;type&quot;: &quot;A String&quot;, # The entity type.
          },
        },
        &quot;intents&quot;: { # All the matched intents in the call.
          &quot;a_key&quot;: { # The data for an intent. Represents a detected intent in the conversation, for example MAKES_PROMISE.
            &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the intent.
            &quot;id&quot;: &quot;A String&quot;, # The unique identifier of the intent.
          },
        },
        &quot;issueModelResult&quot;: { # Issue Modeling result on a conversation. # Overall conversation-level issue modeling result.
          &quot;issueModel&quot;: &quot;A String&quot;, # Issue model that generates the result.
          &quot;issues&quot;: [ # All the matched issues.
            { # Information about the issue.
              &quot;displayName&quot;: &quot;A String&quot;, # Immutable. Display name of the assigned issue. This field is set at time of analyis and immutable since then.
              &quot;issue&quot;: &quot;A String&quot;, # Resource name of the assigned issue.
              &quot;score&quot;: 3.14, # Score indicating the likelihood of the issue assignment. currently bounded on [0,1].
            },
          ],
        },
        &quot;phraseMatchers&quot;: { # All the matched phrase matchers in the call.
          &quot;a_key&quot;: { # The data for a matched phrase matcher. Represents information identifying a phrase matcher for a given match.
            &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the phrase matcher.
            &quot;phraseMatcher&quot;: &quot;A String&quot;, # The unique identifier (the resource name) of the phrase matcher.
          },
        },
        &quot;sentiments&quot;: [ # Overall conversation-level sentiment for each channel of the call.
          { # One channel of conversation-level sentiment data.
            &quot;channelTag&quot;: 42, # The channel of the audio that the data applies to.
            &quot;sentimentData&quot;: { # The data for a sentiment annotation. # Data specifying sentiment.
              &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
              &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
            },
          },
        ],
      },
      &quot;endTime&quot;: &quot;A String&quot;, # The time at which the analysis ended.
    },
    &quot;createTime&quot;: &quot;A String&quot;, # Output only. The time at which the analysis was created, which occurs when the long-running operation completes.
    &quot;name&quot;: &quot;A String&quot;, # Immutable. The resource name of the analysis. Format: projects/{project}/locations/{location}/conversations/{conversation}/analyses/{analysis}
    &quot;requestTime&quot;: &quot;A String&quot;, # Output only. The time at which the analysis was requested.
  },
  &quot;medium&quot;: &quot;A String&quot;, # Immutable. The conversation medium, if unspecified will default to PHONE_CALL.
  &quot;name&quot;: &quot;A String&quot;, # Immutable. The resource name of the conversation. Format: projects/{project}/locations/{location}/conversations/{conversation}
  &quot;obfuscatedUserId&quot;: &quot;A String&quot;, # Obfuscated user ID which the customer sent to us.
  &quot;runtimeAnnotations&quot;: [ # Output only. The annotations that were generated during the customer and agent interaction.
    { # An annotation that was generated during the customer and agent interaction.
      &quot;annotationId&quot;: &quot;A String&quot;, # The unique identifier of the annotation. Format: projects/{project}/locations/{location}/conversationDatasets/{dataset}/conversationDataItems/{data_item}/conversationAnnotations/{annotation}
      &quot;answerFeedback&quot;: { # The feedback that the customer has about a certain answer in the conversation. # The feedback that the customer has about the answer in `data`.
        &quot;clicked&quot;: True or False, # Indicates whether an answer or item was clicked by the human agent.
        &quot;correctnessLevel&quot;: &quot;A String&quot;, # The correctness level of an answer.
        &quot;displayed&quot;: True or False, # Indicates whether an answer or item was displayed to the human agent in the agent desktop UI.
      },
      &quot;articleSuggestion&quot;: { # Agent Assist Article Suggestion data. # Agent Assist Article Suggestion data.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this article is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the Article Suggestion and the document that it originates from.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # Name of the query record. Format: projects/{project}/locations/{location}/queryRecords/{query_record}
        &quot;source&quot;: &quot;A String&quot;, # The knowledge document that this answer was extracted from. Format: projects/{project}/knowledgeBases/{knowledge_base}/documents/{document}
        &quot;title&quot;: &quot;A String&quot;, # Article title.
        &quot;uri&quot;: &quot;A String&quot;, # Article URI.
      },
      &quot;createTime&quot;: &quot;A String&quot;, # The time at which this annotation was created.
      &quot;dialogflowInteraction&quot;: { # Dialogflow interaction data. # Dialogflow interaction data.
        &quot;confidence&quot;: 3.14, # The confidence of the match ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;dialogflowIntentId&quot;: &quot;A String&quot;, # The Dialogflow intent resource path. Format: projects/{project}/agent/{agent}/intents/{intent}
      },
      &quot;endBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation ends, inclusive.
        &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
        &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
      },
      &quot;faqAnswer&quot;: { # Agent Assist frequently-asked-question answer data. # Agent Assist FAQ answer data.
        &quot;answer&quot;: &quot;A String&quot;, # The piece of text from the `source` knowledge base document.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this answer is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the FAQ answer and the document that it originates from.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # Name of the query record. Format: projects/{project}/locations/{location}/queryRecords/{query_record}.
        &quot;question&quot;: &quot;A String&quot;, # The corresponding FAQ question.
        &quot;source&quot;: &quot;A String&quot;, # The knowledge document that this answer was extracted from. Format: projects/{project}/knowledgeBases/{knowledge_base}/documents/{document}.
      },
      &quot;smartComposeSuggestion&quot;: { # Agent Assist Smart Compose suggestion data. # Agent Assist Smart Compose suggestion data.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this suggestion is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the Smart Compose suggestion and the document from which it originates.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # Name of the query record. Format: projects/{project}/locations/{location}/queryRecords/{query_record}
        &quot;suggestion&quot;: &quot;A String&quot;, # The content of the suggestion.
      },
      &quot;smartReply&quot;: { # Agent Assist Smart Reply data. # Agent Assist Smart Reply data.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this reply is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the Smart Reply and the document from which it originates.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # Name of the query record. Format: projects/{project}/locations/{location}/queryRecords/{query_record}
        &quot;reply&quot;: &quot;A String&quot;, # The content of the reply.
      },
      &quot;startBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation starts, inclusive.
        &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
        &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
      },
    },
  ],
  &quot;startTime&quot;: &quot;A String&quot;, # The time at which the conversation started.
  &quot;transcript&quot;: { # A message representing the transcript of a conversation. # Output only. The conversation transcript.
    &quot;transcriptSegments&quot;: [ # A list of sequential transcript segments that comprise the conversation.
      { # A segment of a full transcript.
        &quot;channelTag&quot;: 42, # For conversations derived from multi-channel audio, this is the channel number corresponding to the audio from that channel. For audioChannelCount = N, its output values can range from &#x27;1&#x27; to &#x27;N&#x27;. A channel tag of 0 indicates that the audio is mono.
        &quot;confidence&quot;: 3.14, # A confidence estimate between 0.0 and 1.0 of the fidelity of this segment. A default value of 0.0 indicates that the value is unset.
        &quot;dialogflowSegmentMetadata&quot;: { # Metadata from Dialogflow relating to the current transcript segment. # CCAI metadata relating to the current transcript segment.
          &quot;smartReplyAllowlistCovered&quot;: True or False, # Whether the transcript segment was covered under the configured smart reply allowlist in Agent Assist.
        },
        &quot;languageCode&quot;: &quot;A String&quot;, # The language code of this segment as a [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag. Example: &quot;en-US&quot;.
        &quot;messageTime&quot;: &quot;A String&quot;, # The time that the message occurred, if provided.
        &quot;segmentParticipant&quot;: { # The call participant speaking for a given utterance. # The participant of this segment.
          &quot;dialogflowParticipant&quot;: &quot;A String&quot;, # Deprecated. Use `dialogflow_participant_name` instead. The name of the Dialogflow participant. Format: projects/{project}/locations/{location}/conversations/{conversation}/participants/{participant}
          &quot;dialogflowParticipantName&quot;: &quot;A String&quot;, # The name of the participant provided by Dialogflow. Format: projects/{project}/locations/{location}/conversations/{conversation}/participants/{participant}
          &quot;obfuscatedExternalUserId&quot;: &quot;A String&quot;, # Obfuscated user ID from Dialogflow.
          &quot;role&quot;: &quot;A String&quot;, # The role of the participant.
          &quot;userId&quot;: &quot;A String&quot;, # A user-specified ID representing the participant.
        },
        &quot;sentiment&quot;: { # The data for a sentiment annotation. # The sentiment for this transcript segment.
          &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
          &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
        },
        &quot;text&quot;: &quot;A String&quot;, # The text of this segment.
        &quot;words&quot;: [ # A list of the word-specific information for each word in the segment.
          { # Word-level info for words in a transcript.
            &quot;confidence&quot;: 3.14, # A confidence estimate between 0.0 and 1.0 of the fidelity of this word. A default value of 0.0 indicates that the value is unset.
            &quot;endOffset&quot;: &quot;A String&quot;, # Time offset of the end of this word relative to the beginning of the total conversation.
            &quot;startOffset&quot;: &quot;A String&quot;, # Time offset of the start of this word relative to the beginning of the total conversation.
            &quot;word&quot;: &quot;A String&quot;, # The word itself. Includes punctuation marks that surround the word.
          },
        ],
      },
    ],
  },
  &quot;ttl&quot;: &quot;A String&quot;, # Input only. The TTL for this resource. If specified, then this TTL will be used to calculate the expire time.
  &quot;turnCount&quot;: 42, # Output only. The number of turns in the conversation.
  &quot;updateTime&quot;: &quot;A String&quot;, # Output only. The most recent time at which the conversation was updated.
}

  updateMask: string, The list of fields to be updated.
  x__xgafv: string, V1 error format.
    Allowed values
      1 - v1 error format
      2 - v2 error format

Returns:
  An object of the form:

    { # The conversation resource.
  &quot;agentId&quot;: &quot;A String&quot;, # An opaque, user-specified string representing the human agent who handled the conversation.
  &quot;callMetadata&quot;: { # Call-specific metadata. # Call-specific metadata.
    &quot;agentChannel&quot;: 42, # The audio channel that contains the agent.
    &quot;customerChannel&quot;: 42, # The audio channel that contains the customer.
  },
  &quot;createTime&quot;: &quot;A String&quot;, # Output only. The time at which the conversation was created.
  &quot;dataSource&quot;: { # The conversation source, which is a combination of transcript and audio. # The source of the audio and transcription for the conversation.
    &quot;dialogflowSource&quot;: { # A Dialogflow source of conversation data. # The source when the conversation comes from Dialogflow.
      &quot;audioUri&quot;: &quot;A String&quot;, # Cloud Storage URI that points to a file that contains the conversation audio.
      &quot;dialogflowConversation&quot;: &quot;A String&quot;, # Output only. The name of the Dialogflow conversation that this conversation resource is derived from. Format: projects/{project}/locations/{location}/conversations/{conversation}
    },
    &quot;gcsSource&quot;: { # A Cloud Storage source of conversation data. # A Cloud Storage location specification for the audio and transcript.
      &quot;audioUri&quot;: &quot;A String&quot;, # Cloud Storage URI that points to a file that contains the conversation audio.
      &quot;transcriptUri&quot;: &quot;A String&quot;, # Immutable. Cloud Storage URI that points to a file that contains the conversation transcript.
    },
  },
  &quot;dialogflowIntents&quot;: { # Output only. All the matched Dialogflow intents in the call. The key corresponds to a Dialogflow intent, format: projects/{project}/agent/{agent}/intents/{intent}
    &quot;a_key&quot;: { # The data for a Dialogflow intent. Represents a detected intent in the conversation, e.g. MAKES_PROMISE.
      &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the intent.
    },
  },
  &quot;duration&quot;: &quot;A String&quot;, # Output only. The duration of the conversation.
  &quot;expireTime&quot;: &quot;A String&quot;, # The time at which this conversation should expire. After this time, the conversation data and any associated analyses will be deleted.
  &quot;labels&quot;: { # A map for the user to specify any custom fields. A maximum of 20 labels per conversation is allowed, with a maximum of 256 characters per entry.
    &quot;a_key&quot;: &quot;A String&quot;,
  },
  &quot;languageCode&quot;: &quot;A String&quot;, # A user-specified language code for the conversation.
  &quot;latestAnalysis&quot;: { # The analysis resource. # Output only. The conversation&#x27;s latest analysis, if one exists.
    &quot;analysisResult&quot;: { # The result of an analysis. # Output only. The result of the analysis, which is populated when the analysis finishes.
      &quot;callAnalysisMetadata&quot;: { # Call-specific metadata created during analysis. # Call-specific metadata created by the analysis.
        &quot;annotations&quot;: [ # A list of call annotations that apply to this call.
          { # A piece of metadata that applies to a window of a call.
            &quot;annotationEndBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation ends, inclusive.
              &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
              &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
            },
            &quot;annotationStartBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation starts, inclusive.
              &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
              &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
            },
            &quot;channelTag&quot;: 42, # The channel of the audio where the annotation occurs. For single-channel audio, this field is not populated.
            &quot;entityMentionData&quot;: { # The data for an entity mention annotation. This represents a mention of an `Entity` in the conversation. # Data specifying an entity mention.
              &quot;entityUniqueId&quot;: &quot;A String&quot;, # The key of this entity in conversation entities. Can be used to retrieve the exact `Entity` this mention is attached to.
              &quot;sentiment&quot;: { # The data for a sentiment annotation. # Sentiment expressed for this mention of the entity.
                &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
                &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
              },
              &quot;type&quot;: &quot;A String&quot;, # The type of the entity mention.
            },
            &quot;holdData&quot;: { # The data for a hold annotation. # Data specifying a hold.
            },
            &quot;intentMatchData&quot;: { # The data for an intent match. Represents an intent match for a text segment in the conversation. A text segment can be part of a sentence, a complete sentence, or an utterance with multiple sentences. # Data specifying an intent match.
              &quot;intentUniqueId&quot;: &quot;A String&quot;, # The id of the matched intent. Can be used to retrieve the corresponding intent information.
            },
            &quot;interruptionData&quot;: { # The data for an interruption annotation. # Data specifying an interruption.
            },
            &quot;phraseMatchData&quot;: { # The data for a matched phrase matcher. Represents information identifying a phrase matcher for a given match. # Data specifying a phrase match.
              &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the phrase matcher.
              &quot;phraseMatcher&quot;: &quot;A String&quot;, # The unique identifier (the resource name) of the phrase matcher.
            },
            &quot;sentimentData&quot;: { # The data for a sentiment annotation. # Data specifying sentiment.
              &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
              &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
            },
            &quot;silenceData&quot;: { # The data for a silence annotation. # Data specifying silence.
            },
          },
        ],
        &quot;entities&quot;: { # All the entities in the call.
          &quot;a_key&quot;: { # The data for an entity annotation. Represents a phrase in the conversation that is a known entity, such as a person, an organization, or location.
            &quot;displayName&quot;: &quot;A String&quot;, # The representative name for the entity.
            &quot;metadata&quot;: { # Metadata associated with the entity. For most entity types, the metadata is a Wikipedia URL (`wikipedia_url`) and Knowledge Graph MID (`mid`), if they are available. For the metadata associated with other entity types, see the Type table below.
              &quot;a_key&quot;: &quot;A String&quot;,
            },
            &quot;salience&quot;: 3.14, # The salience score associated with the entity in the [0, 1.0] range. The salience score for an entity provides information about the importance or centrality of that entity to the entire document text. Scores closer to 0 are less salient, while scores closer to 1.0 are highly salient.
            &quot;sentiment&quot;: { # The data for a sentiment annotation. # The aggregate sentiment expressed for this entity in the conversation.
              &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
              &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
            },
            &quot;type&quot;: &quot;A String&quot;, # The entity type.
          },
        },
        &quot;intents&quot;: { # All the matched intents in the call.
          &quot;a_key&quot;: { # The data for an intent. Represents a detected intent in the conversation, for example MAKES_PROMISE.
            &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the intent.
            &quot;id&quot;: &quot;A String&quot;, # The unique identifier of the intent.
          },
        },
        &quot;issueModelResult&quot;: { # Issue Modeling result on a conversation. # Overall conversation-level issue modeling result.
          &quot;issueModel&quot;: &quot;A String&quot;, # Issue model that generates the result.
          &quot;issues&quot;: [ # All the matched issues.
            { # Information about the issue.
              &quot;displayName&quot;: &quot;A String&quot;, # Immutable. Display name of the assigned issue. This field is set at time of analyis and immutable since then.
              &quot;issue&quot;: &quot;A String&quot;, # Resource name of the assigned issue.
              &quot;score&quot;: 3.14, # Score indicating the likelihood of the issue assignment. currently bounded on [0,1].
            },
          ],
        },
        &quot;phraseMatchers&quot;: { # All the matched phrase matchers in the call.
          &quot;a_key&quot;: { # The data for a matched phrase matcher. Represents information identifying a phrase matcher for a given match.
            &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the phrase matcher.
            &quot;phraseMatcher&quot;: &quot;A String&quot;, # The unique identifier (the resource name) of the phrase matcher.
          },
        },
        &quot;sentiments&quot;: [ # Overall conversation-level sentiment for each channel of the call.
          { # One channel of conversation-level sentiment data.
            &quot;channelTag&quot;: 42, # The channel of the audio that the data applies to.
            &quot;sentimentData&quot;: { # The data for a sentiment annotation. # Data specifying sentiment.
              &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
              &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
            },
          },
        ],
      },
      &quot;endTime&quot;: &quot;A String&quot;, # The time at which the analysis ended.
    },
    &quot;createTime&quot;: &quot;A String&quot;, # Output only. The time at which the analysis was created, which occurs when the long-running operation completes.
    &quot;name&quot;: &quot;A String&quot;, # Immutable. The resource name of the analysis. Format: projects/{project}/locations/{location}/conversations/{conversation}/analyses/{analysis}
    &quot;requestTime&quot;: &quot;A String&quot;, # Output only. The time at which the analysis was requested.
  },
  &quot;medium&quot;: &quot;A String&quot;, # Immutable. The conversation medium, if unspecified will default to PHONE_CALL.
  &quot;name&quot;: &quot;A String&quot;, # Immutable. The resource name of the conversation. Format: projects/{project}/locations/{location}/conversations/{conversation}
  &quot;obfuscatedUserId&quot;: &quot;A String&quot;, # Obfuscated user ID which the customer sent to us.
  &quot;runtimeAnnotations&quot;: [ # Output only. The annotations that were generated during the customer and agent interaction.
    { # An annotation that was generated during the customer and agent interaction.
      &quot;annotationId&quot;: &quot;A String&quot;, # The unique identifier of the annotation. Format: projects/{project}/locations/{location}/conversationDatasets/{dataset}/conversationDataItems/{data_item}/conversationAnnotations/{annotation}
      &quot;answerFeedback&quot;: { # The feedback that the customer has about a certain answer in the conversation. # The feedback that the customer has about the answer in `data`.
        &quot;clicked&quot;: True or False, # Indicates whether an answer or item was clicked by the human agent.
        &quot;correctnessLevel&quot;: &quot;A String&quot;, # The correctness level of an answer.
        &quot;displayed&quot;: True or False, # Indicates whether an answer or item was displayed to the human agent in the agent desktop UI.
      },
      &quot;articleSuggestion&quot;: { # Agent Assist Article Suggestion data. # Agent Assist Article Suggestion data.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this article is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the Article Suggestion and the document that it originates from.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # Name of the query record. Format: projects/{project}/locations/{location}/queryRecords/{query_record}
        &quot;source&quot;: &quot;A String&quot;, # The knowledge document that this answer was extracted from. Format: projects/{project}/knowledgeBases/{knowledge_base}/documents/{document}
        &quot;title&quot;: &quot;A String&quot;, # Article title.
        &quot;uri&quot;: &quot;A String&quot;, # Article URI.
      },
      &quot;createTime&quot;: &quot;A String&quot;, # The time at which this annotation was created.
      &quot;dialogflowInteraction&quot;: { # Dialogflow interaction data. # Dialogflow interaction data.
        &quot;confidence&quot;: 3.14, # The confidence of the match ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;dialogflowIntentId&quot;: &quot;A String&quot;, # The Dialogflow intent resource path. Format: projects/{project}/agent/{agent}/intents/{intent}
      },
      &quot;endBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation ends, inclusive.
        &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
        &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
      },
      &quot;faqAnswer&quot;: { # Agent Assist frequently-asked-question answer data. # Agent Assist FAQ answer data.
        &quot;answer&quot;: &quot;A String&quot;, # The piece of text from the `source` knowledge base document.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this answer is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the FAQ answer and the document that it originates from.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # Name of the query record. Format: projects/{project}/locations/{location}/queryRecords/{query_record}.
        &quot;question&quot;: &quot;A String&quot;, # The corresponding FAQ question.
        &quot;source&quot;: &quot;A String&quot;, # The knowledge document that this answer was extracted from. Format: projects/{project}/knowledgeBases/{knowledge_base}/documents/{document}.
      },
      &quot;smartComposeSuggestion&quot;: { # Agent Assist Smart Compose suggestion data. # Agent Assist Smart Compose suggestion data.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this suggestion is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the Smart Compose suggestion and the document from which it originates.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # Name of the query record. Format: projects/{project}/locations/{location}/queryRecords/{query_record}
        &quot;suggestion&quot;: &quot;A String&quot;, # The content of the suggestion.
      },
      &quot;smartReply&quot;: { # Agent Assist Smart Reply data. # Agent Assist Smart Reply data.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this reply is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the Smart Reply and the document from which it originates.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # Name of the query record. Format: projects/{project}/locations/{location}/queryRecords/{query_record}
        &quot;reply&quot;: &quot;A String&quot;, # The content of the reply.
      },
      &quot;startBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation starts, inclusive.
        &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
        &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
      },
    },
  ],
  &quot;startTime&quot;: &quot;A String&quot;, # The time at which the conversation started.
  &quot;transcript&quot;: { # A message representing the transcript of a conversation. # Output only. The conversation transcript.
    &quot;transcriptSegments&quot;: [ # A list of sequential transcript segments that comprise the conversation.
      { # A segment of a full transcript.
        &quot;channelTag&quot;: 42, # For conversations derived from multi-channel audio, this is the channel number corresponding to the audio from that channel. For audioChannelCount = N, its output values can range from &#x27;1&#x27; to &#x27;N&#x27;. A channel tag of 0 indicates that the audio is mono.
        &quot;confidence&quot;: 3.14, # A confidence estimate between 0.0 and 1.0 of the fidelity of this segment. A default value of 0.0 indicates that the value is unset.
        &quot;dialogflowSegmentMetadata&quot;: { # Metadata from Dialogflow relating to the current transcript segment. # CCAI metadata relating to the current transcript segment.
          &quot;smartReplyAllowlistCovered&quot;: True or False, # Whether the transcript segment was covered under the configured smart reply allowlist in Agent Assist.
        },
        &quot;languageCode&quot;: &quot;A String&quot;, # The language code of this segment as a [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag. Example: &quot;en-US&quot;.
        &quot;messageTime&quot;: &quot;A String&quot;, # The time that the message occurred, if provided.
        &quot;segmentParticipant&quot;: { # The call participant speaking for a given utterance. # The participant of this segment.
          &quot;dialogflowParticipant&quot;: &quot;A String&quot;, # Deprecated. Use `dialogflow_participant_name` instead. The name of the Dialogflow participant. Format: projects/{project}/locations/{location}/conversations/{conversation}/participants/{participant}
          &quot;dialogflowParticipantName&quot;: &quot;A String&quot;, # The name of the participant provided by Dialogflow. Format: projects/{project}/locations/{location}/conversations/{conversation}/participants/{participant}
          &quot;obfuscatedExternalUserId&quot;: &quot;A String&quot;, # Obfuscated user ID from Dialogflow.
          &quot;role&quot;: &quot;A String&quot;, # The role of the participant.
          &quot;userId&quot;: &quot;A String&quot;, # A user-specified ID representing the participant.
        },
        &quot;sentiment&quot;: { # The data for a sentiment annotation. # The sentiment for this transcript segment.
          &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
          &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
        },
        &quot;text&quot;: &quot;A String&quot;, # The text of this segment.
        &quot;words&quot;: [ # A list of the word-specific information for each word in the segment.
          { # Word-level info for words in a transcript.
            &quot;confidence&quot;: 3.14, # A confidence estimate between 0.0 and 1.0 of the fidelity of this word. A default value of 0.0 indicates that the value is unset.
            &quot;endOffset&quot;: &quot;A String&quot;, # Time offset of the end of this word relative to the beginning of the total conversation.
            &quot;startOffset&quot;: &quot;A String&quot;, # Time offset of the start of this word relative to the beginning of the total conversation.
            &quot;word&quot;: &quot;A String&quot;, # The word itself. Includes punctuation marks that surround the word.
          },
        ],
      },
    ],
  },
  &quot;ttl&quot;: &quot;A String&quot;, # Input only. The TTL for this resource. If specified, then this TTL will be used to calculate the expire time.
  &quot;turnCount&quot;: 42, # Output only. The number of turns in the conversation.
  &quot;updateTime&quot;: &quot;A String&quot;, # Output only. The most recent time at which the conversation was updated.
}</pre>
</div>

</body></html>