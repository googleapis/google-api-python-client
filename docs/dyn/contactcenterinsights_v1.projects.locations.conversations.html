<html><body>
<style>

body, h1, h2, h3, div, span, p, pre, a {
  margin: 0;
  padding: 0;
  border: 0;
  font-weight: inherit;
  font-style: inherit;
  font-size: 100%;
  font-family: inherit;
  vertical-align: baseline;
}

body {
  font-size: 13px;
  padding: 1em;
}

h1 {
  font-size: 26px;
  margin-bottom: 1em;
}

h2 {
  font-size: 24px;
  margin-bottom: 1em;
}

h3 {
  font-size: 20px;
  margin-bottom: 1em;
  margin-top: 1em;
}

pre, code {
  line-height: 1.5;
  font-family: Monaco, 'DejaVu Sans Mono', 'Bitstream Vera Sans Mono', 'Lucida Console', monospace;
}

pre {
  margin-top: 0.5em;
}

h1, h2, h3, p {
  font-family: Arial, sans serif;
}

h1, h2, h3 {
  border-bottom: solid #CCC 1px;
}

.toc_element {
  margin-top: 0.5em;
}

.firstline {
  margin-left: 2 em;
}

.method  {
  margin-top: 1em;
  border: solid 1px #CCC;
  padding: 1em;
  background: #EEE;
}

.details {
  font-weight: bold;
  font-size: 14px;
}

</style>

<h1><a href="contactcenterinsights_v1.html">Contact Center AI Insights API</a> . <a href="contactcenterinsights_v1.projects.html">projects</a> . <a href="contactcenterinsights_v1.projects.locations.html">locations</a> . <a href="contactcenterinsights_v1.projects.locations.conversations.html">conversations</a></h1>
<h2>Instance Methods</h2>
<p class="toc_element">
  <code><a href="contactcenterinsights_v1.projects.locations.conversations.analyses.html">analyses()</a></code>
</p>
<p class="firstline">Returns the analyses Resource.</p>

<p class="toc_element">
  <code><a href="#bulkAnalyze">bulkAnalyze(parent, body=None, x__xgafv=None)</a></code></p>
<p class="firstline">Analyzes multiple conversations in a single request.</p>
<p class="toc_element">
  <code><a href="#bulkDelete">bulkDelete(parent, body=None, x__xgafv=None)</a></code></p>
<p class="firstline">Deletes multiple conversations in a single request.</p>
<p class="toc_element">
  <code><a href="#calculateStats">calculateStats(location, filter=None, x__xgafv=None)</a></code></p>
<p class="firstline">Gets conversation statistics.</p>
<p class="toc_element">
  <code><a href="#close">close()</a></code></p>
<p class="firstline">Close httplib2 connections.</p>
<p class="toc_element">
  <code><a href="#create">create(parent, body=None, conversationId=None, x__xgafv=None)</a></code></p>
<p class="firstline">Creates a conversation. Note that this method does not support audio transcription or redaction. Use `conversations.upload` instead.</p>
<p class="toc_element">
  <code><a href="#delete">delete(name, force=None, x__xgafv=None)</a></code></p>
<p class="firstline">Deletes a conversation.</p>
<p class="toc_element">
  <code><a href="#get">get(name, view=None, x__xgafv=None)</a></code></p>
<p class="firstline">Gets a conversation.</p>
<p class="toc_element">
  <code><a href="#ingest">ingest(parent, body=None, x__xgafv=None)</a></code></p>
<p class="firstline">Imports conversations and processes them according to the user's configuration.</p>
<p class="toc_element">
  <code><a href="#list">list(parent, filter=None, orderBy=None, pageSize=None, pageToken=None, view=None, x__xgafv=None)</a></code></p>
<p class="firstline">Lists conversations.</p>
<p class="toc_element">
  <code><a href="#list_next">list_next()</a></code></p>
<p class="firstline">Retrieves the next page of results.</p>
<p class="toc_element">
  <code><a href="#patch">patch(name, body=None, updateMask=None, x__xgafv=None)</a></code></p>
<p class="firstline">Updates a conversation.</p>
<p class="toc_element">
  <code><a href="#upload">upload(parent, body=None, x__xgafv=None)</a></code></p>
<p class="firstline">Create a long-running conversation upload operation. This method differs from `CreateConversation` by allowing audio transcription and optional DLP redaction.</p>
<h3>Method Details</h3>
<div class="method">
    <code class="details" id="bulkAnalyze">bulkAnalyze(parent, body=None, x__xgafv=None)</code>
  <pre>Analyzes multiple conversations in a single request.

Args:
  parent: string, Required. The parent resource to create analyses in. (required)
  body: object, The request body.
    The object takes the form of:

{ # The request to analyze conversations in bulk.
  &quot;analysisPercentage&quot;: 3.14, # Required. Percentage of selected conversation to analyze, between [0, 100].
  &quot;annotatorSelector&quot;: { # Selector of all available annotators and phrase matchers to run. # To select the annotators to run and the phrase matchers to use (if any). If not specified, all annotators will be run.
    &quot;issueModels&quot;: [ # The issue model to run. If not provided, the most recently deployed topic model will be used. The provided issue model will only be used for inference if the issue model is deployed and if run_issue_model_annotator is set to true. If more than one issue model is provided, only the first provided issue model will be used for inference.
      &quot;A String&quot;,
    ],
    &quot;phraseMatchers&quot;: [ # The list of phrase matchers to run. If not provided, all active phrase matchers will be used. If inactive phrase matchers are provided, they will not be used. Phrase matchers will be run only if run_phrase_matcher_annotator is set to true. Format: projects/{project}/locations/{location}/phraseMatchers/{phrase_matcher}
      &quot;A String&quot;,
    ],
    &quot;runEntityAnnotator&quot;: True or False, # Whether to run the entity annotator.
    &quot;runIntentAnnotator&quot;: True or False, # Whether to run the intent annotator.
    &quot;runInterruptionAnnotator&quot;: True or False, # Whether to run the interruption annotator.
    &quot;runIssueModelAnnotator&quot;: True or False, # Whether to run the issue model annotator. A model should have already been deployed for this to take effect.
    &quot;runPhraseMatcherAnnotator&quot;: True or False, # Whether to run the active phrase matcher annotator(s).
    &quot;runSentimentAnnotator&quot;: True or False, # Whether to run the sentiment annotator.
    &quot;runSilenceAnnotator&quot;: True or False, # Whether to run the silence annotator.
    &quot;runSummarizationAnnotator&quot;: True or False, # Whether to run the summarization annotator.
    &quot;summarizationConfig&quot;: { # Configuration for summarization. # Configuration for the summarization annotator.
      &quot;conversationProfile&quot;: &quot;A String&quot;, # Resource name of the Dialogflow conversation profile. Format: projects/{project}/locations/{location}/conversationProfiles/{conversation_profile}
      &quot;summarizationModel&quot;: &quot;A String&quot;, # Default summarization model to be used.
    },
  },
  &quot;filter&quot;: &quot;A String&quot;, # Required. Filter used to select the subset of conversations to analyze.
  &quot;parent&quot;: &quot;A String&quot;, # Required. The parent resource to create analyses in.
}

  x__xgafv: string, V1 error format.
    Allowed values
      1 - v1 error format
      2 - v2 error format

Returns:
  An object of the form:

    { # This resource represents a long-running operation that is the result of a network API call.
  &quot;done&quot;: True or False, # If the value is `false`, it means the operation is still in progress. If `true`, the operation is completed, and either `error` or `response` is available.
  &quot;error&quot;: { # The `Status` type defines a logical error model that is suitable for different programming environments, including REST APIs and RPC APIs. It is used by [gRPC](https://github.com/grpc). Each `Status` message contains three pieces of data: error code, error message, and error details. You can find out more about this error model and how to work with it in the [API Design Guide](https://cloud.google.com/apis/design/errors). # The error result of the operation in case of failure or cancellation.
    &quot;code&quot;: 42, # The status code, which should be an enum value of google.rpc.Code.
    &quot;details&quot;: [ # A list of messages that carry the error details. There is a common set of message types for APIs to use.
      {
        &quot;a_key&quot;: &quot;&quot;, # Properties of the object. Contains field @type with type URL.
      },
    ],
    &quot;message&quot;: &quot;A String&quot;, # A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client.
  },
  &quot;metadata&quot;: { # Service-specific metadata associated with the operation. It typically contains progress information and common metadata such as create time. Some services might not provide such metadata. Any method that returns a long-running operation should document the metadata type, if any.
    &quot;a_key&quot;: &quot;&quot;, # Properties of the object. Contains field @type with type URL.
  },
  &quot;name&quot;: &quot;A String&quot;, # The server-assigned name, which is only unique within the same service that originally returns it. If you use the default HTTP mapping, the `name` should be a resource name ending with `operations/{unique_id}`.
  &quot;response&quot;: { # The normal, successful response of the operation. If the original method returns no data on success, such as `Delete`, the response is `google.protobuf.Empty`. If the original method is standard `Get`/`Create`/`Update`, the response should be the resource. For other methods, the response should have the type `XxxResponse`, where `Xxx` is the original method name. For example, if the original method name is `TakeSnapshot()`, the inferred response type is `TakeSnapshotResponse`.
    &quot;a_key&quot;: &quot;&quot;, # Properties of the object. Contains field @type with type URL.
  },
}</pre>
</div>

<div class="method">
    <code class="details" id="bulkDelete">bulkDelete(parent, body=None, x__xgafv=None)</code>
  <pre>Deletes multiple conversations in a single request.

Args:
  parent: string, Required. The parent resource to delete conversations from. Format: projects/{project}/locations/{location} (required)
  body: object, The request body.
    The object takes the form of:

{ # The request to delete conversations in bulk.
  &quot;filter&quot;: &quot;A String&quot;, # Filter used to select the subset of conversations to delete.
  &quot;force&quot;: True or False, # If set to true, all of this conversation&#x27;s analyses will also be deleted. Otherwise, the request will only succeed if the conversation has no analyses.
  &quot;maxDeleteCount&quot;: 42, # Maximum number of conversations to delete.
  &quot;parent&quot;: &quot;A String&quot;, # Required. The parent resource to delete conversations from. Format: projects/{project}/locations/{location}
}

  x__xgafv: string, V1 error format.
    Allowed values
      1 - v1 error format
      2 - v2 error format

Returns:
  An object of the form:

    { # This resource represents a long-running operation that is the result of a network API call.
  &quot;done&quot;: True or False, # If the value is `false`, it means the operation is still in progress. If `true`, the operation is completed, and either `error` or `response` is available.
  &quot;error&quot;: { # The `Status` type defines a logical error model that is suitable for different programming environments, including REST APIs and RPC APIs. It is used by [gRPC](https://github.com/grpc). Each `Status` message contains three pieces of data: error code, error message, and error details. You can find out more about this error model and how to work with it in the [API Design Guide](https://cloud.google.com/apis/design/errors). # The error result of the operation in case of failure or cancellation.
    &quot;code&quot;: 42, # The status code, which should be an enum value of google.rpc.Code.
    &quot;details&quot;: [ # A list of messages that carry the error details. There is a common set of message types for APIs to use.
      {
        &quot;a_key&quot;: &quot;&quot;, # Properties of the object. Contains field @type with type URL.
      },
    ],
    &quot;message&quot;: &quot;A String&quot;, # A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client.
  },
  &quot;metadata&quot;: { # Service-specific metadata associated with the operation. It typically contains progress information and common metadata such as create time. Some services might not provide such metadata. Any method that returns a long-running operation should document the metadata type, if any.
    &quot;a_key&quot;: &quot;&quot;, # Properties of the object. Contains field @type with type URL.
  },
  &quot;name&quot;: &quot;A String&quot;, # The server-assigned name, which is only unique within the same service that originally returns it. If you use the default HTTP mapping, the `name` should be a resource name ending with `operations/{unique_id}`.
  &quot;response&quot;: { # The normal, successful response of the operation. If the original method returns no data on success, such as `Delete`, the response is `google.protobuf.Empty`. If the original method is standard `Get`/`Create`/`Update`, the response should be the resource. For other methods, the response should have the type `XxxResponse`, where `Xxx` is the original method name. For example, if the original method name is `TakeSnapshot()`, the inferred response type is `TakeSnapshotResponse`.
    &quot;a_key&quot;: &quot;&quot;, # Properties of the object. Contains field @type with type URL.
  },
}</pre>
</div>

<div class="method">
    <code class="details" id="calculateStats">calculateStats(location, filter=None, x__xgafv=None)</code>
  <pre>Gets conversation statistics.

Args:
  location: string, Required. The location of the conversations. (required)
  filter: string, A filter to reduce results to a specific subset. This field is useful for getting statistics about conversations with specific properties.
  x__xgafv: string, V1 error format.
    Allowed values
      1 - v1 error format
      2 - v2 error format

Returns:
  An object of the form:

    { # The response for calculating conversation statistics.
  &quot;averageDuration&quot;: &quot;A String&quot;, # The average duration of all conversations. The average is calculated using only conversations that have a time duration.
  &quot;averageTurnCount&quot;: 42, # The average number of turns per conversation.
  &quot;conversationCount&quot;: 42, # The total number of conversations.
  &quot;conversationCountTimeSeries&quot;: { # A time series representing conversations over time. # A time series representing the count of conversations created over time that match that requested filter criteria.
    &quot;intervalDuration&quot;: &quot;A String&quot;, # The duration of each interval.
    &quot;points&quot;: [ # An ordered list of intervals from earliest to latest, where each interval represents the number of conversations that transpired during the time window.
      { # A single interval in a time series.
        &quot;conversationCount&quot;: 42, # The number of conversations created in this interval.
        &quot;startTime&quot;: &quot;A String&quot;, # The start time of this interval.
      },
    ],
  },
  &quot;customHighlighterMatches&quot;: { # A map associating each custom highlighter resource name with its respective number of matches in the set of conversations.
    &quot;a_key&quot;: 42,
  },
  &quot;issueMatches&quot;: { # A map associating each issue resource name with its respective number of matches in the set of conversations. Key has the format: `projects//locations//issueModels//issues/` Deprecated, use `issue_matches_stats` field instead.
    &quot;a_key&quot;: 42,
  },
  &quot;issueMatchesStats&quot;: { # A map associating each issue resource name with its respective number of matches in the set of conversations. Key has the format: `projects//locations//issueModels//issues/`
    &quot;a_key&quot;: { # Aggregated statistics about an issue.
      &quot;displayName&quot;: &quot;A String&quot;, # Display name of the issue.
      &quot;issue&quot;: &quot;A String&quot;, # Issue resource. Format: projects/{project}/locations/{location}/issueModels/{issue_model}/issues/{issue}
      &quot;labeledConversationsCount&quot;: &quot;A String&quot;, # Number of conversations attached to the issue at this point in time.
    },
  },
  &quot;smartHighlighterMatches&quot;: { # A map associating each smart highlighter display name with its respective number of matches in the set of conversations.
    &quot;a_key&quot;: 42,
  },
}</pre>
</div>

<div class="method">
    <code class="details" id="close">close()</code>
  <pre>Close httplib2 connections.</pre>
</div>

<div class="method">
    <code class="details" id="create">create(parent, body=None, conversationId=None, x__xgafv=None)</code>
  <pre>Creates a conversation. Note that this method does not support audio transcription or redaction. Use `conversations.upload` instead.

Args:
  parent: string, Required. The parent resource of the conversation. (required)
  body: object, The request body.
    The object takes the form of:

{ # The conversation resource.
  &quot;agentId&quot;: &quot;A String&quot;, # An opaque, user-specified string representing the human agent who handled the conversation.
  &quot;callMetadata&quot;: { # Call-specific metadata. # Call-specific metadata.
    &quot;agentChannel&quot;: 42, # The audio channel that contains the agent.
    &quot;customerChannel&quot;: 42, # The audio channel that contains the customer.
  },
  &quot;createTime&quot;: &quot;A String&quot;, # Output only. The time at which the conversation was created.
  &quot;dataSource&quot;: { # The conversation source, which is a combination of transcript and audio. # The source of the audio and transcription for the conversation.
    &quot;dialogflowSource&quot;: { # A Dialogflow source of conversation data. # The source when the conversation comes from Dialogflow.
      &quot;audioUri&quot;: &quot;A String&quot;, # Cloud Storage URI that points to a file that contains the conversation audio.
      &quot;dialogflowConversation&quot;: &quot;A String&quot;, # Output only. The name of the Dialogflow conversation that this conversation resource is derived from. Format: projects/{project}/locations/{location}/conversations/{conversation}
    },
    &quot;gcsSource&quot;: { # A Cloud Storage source of conversation data. # A Cloud Storage location specification for the audio and transcript.
      &quot;audioUri&quot;: &quot;A String&quot;, # Cloud Storage URI that points to a file that contains the conversation audio.
      &quot;transcriptUri&quot;: &quot;A String&quot;, # Immutable. Cloud Storage URI that points to a file that contains the conversation transcript.
    },
  },
  &quot;dialogflowIntents&quot;: { # Output only. All the matched Dialogflow intents in the call. The key corresponds to a Dialogflow intent, format: projects/{project}/agent/{agent}/intents/{intent}
    &quot;a_key&quot;: { # The data for a Dialogflow intent. Represents a detected intent in the conversation, e.g. MAKES_PROMISE.
      &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the intent.
    },
  },
  &quot;duration&quot;: &quot;A String&quot;, # Output only. The duration of the conversation.
  &quot;expireTime&quot;: &quot;A String&quot;, # The time at which this conversation should expire. After this time, the conversation data and any associated analyses will be deleted.
  &quot;labels&quot;: { # A map for the user to specify any custom fields. A maximum of 20 labels per conversation is allowed, with a maximum of 256 characters per entry.
    &quot;a_key&quot;: &quot;A String&quot;,
  },
  &quot;languageCode&quot;: &quot;A String&quot;, # A user-specified language code for the conversation.
  &quot;latestAnalysis&quot;: { # The analysis resource. # Output only. The conversation&#x27;s latest analysis, if one exists.
    &quot;analysisResult&quot;: { # The result of an analysis. # Output only. The result of the analysis, which is populated when the analysis finishes.
      &quot;callAnalysisMetadata&quot;: { # Call-specific metadata created during analysis. # Call-specific metadata created by the analysis.
        &quot;annotations&quot;: [ # A list of call annotations that apply to this call.
          { # A piece of metadata that applies to a window of a call.
            &quot;annotationEndBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation ends, inclusive.
              &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
              &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
            },
            &quot;annotationStartBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation starts, inclusive.
              &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
              &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
            },
            &quot;channelTag&quot;: 42, # The channel of the audio where the annotation occurs. For single-channel audio, this field is not populated.
            &quot;entityMentionData&quot;: { # The data for an entity mention annotation. This represents a mention of an `Entity` in the conversation. # Data specifying an entity mention.
              &quot;entityUniqueId&quot;: &quot;A String&quot;, # The key of this entity in conversation entities. Can be used to retrieve the exact `Entity` this mention is attached to.
              &quot;sentiment&quot;: { # The data for a sentiment annotation. # Sentiment expressed for this mention of the entity.
                &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
                &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
              },
              &quot;type&quot;: &quot;A String&quot;, # The type of the entity mention.
            },
            &quot;holdData&quot;: { # The data for a hold annotation. # Data specifying a hold.
            },
            &quot;intentMatchData&quot;: { # The data for an intent match. Represents an intent match for a text segment in the conversation. A text segment can be part of a sentence, a complete sentence, or an utterance with multiple sentences. # Data specifying an intent match.
              &quot;intentUniqueId&quot;: &quot;A String&quot;, # The id of the matched intent. Can be used to retrieve the corresponding intent information.
            },
            &quot;interruptionData&quot;: { # The data for an interruption annotation. # Data specifying an interruption.
            },
            &quot;issueMatchData&quot;: { # The data for an issue match annotation. # Data specifying an issue match.
              &quot;issueAssignment&quot;: { # Information about the issue. # Information about the issue&#x27;s assignment.
                &quot;displayName&quot;: &quot;A String&quot;, # Immutable. Display name of the assigned issue. This field is set at time of analyis and immutable since then.
                &quot;issue&quot;: &quot;A String&quot;, # Resource name of the assigned issue.
                &quot;score&quot;: 3.14, # Score indicating the likelihood of the issue assignment. currently bounded on [0,1].
              },
            },
            &quot;phraseMatchData&quot;: { # The data for a matched phrase matcher. Represents information identifying a phrase matcher for a given match. # Data specifying a phrase match.
              &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the phrase matcher.
              &quot;phraseMatcher&quot;: &quot;A String&quot;, # The unique identifier (the resource name) of the phrase matcher.
            },
            &quot;sentimentData&quot;: { # The data for a sentiment annotation. # Data specifying sentiment.
              &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
              &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
            },
            &quot;silenceData&quot;: { # The data for a silence annotation. # Data specifying silence.
            },
          },
        ],
        &quot;entities&quot;: { # All the entities in the call.
          &quot;a_key&quot;: { # The data for an entity annotation. Represents a phrase in the conversation that is a known entity, such as a person, an organization, or location.
            &quot;displayName&quot;: &quot;A String&quot;, # The representative name for the entity.
            &quot;metadata&quot;: { # Metadata associated with the entity. For most entity types, the metadata is a Wikipedia URL (`wikipedia_url`) and Knowledge Graph MID (`mid`), if they are available. For the metadata associated with other entity types, see the Type table below.
              &quot;a_key&quot;: &quot;A String&quot;,
            },
            &quot;salience&quot;: 3.14, # The salience score associated with the entity in the [0, 1.0] range. The salience score for an entity provides information about the importance or centrality of that entity to the entire document text. Scores closer to 0 are less salient, while scores closer to 1.0 are highly salient.
            &quot;sentiment&quot;: { # The data for a sentiment annotation. # The aggregate sentiment expressed for this entity in the conversation.
              &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
              &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
            },
            &quot;type&quot;: &quot;A String&quot;, # The entity type.
          },
        },
        &quot;intents&quot;: { # All the matched intents in the call.
          &quot;a_key&quot;: { # The data for an intent. Represents a detected intent in the conversation, for example MAKES_PROMISE.
            &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the intent.
            &quot;id&quot;: &quot;A String&quot;, # The unique identifier of the intent.
          },
        },
        &quot;issueModelResult&quot;: { # Issue Modeling result on a conversation. # Overall conversation-level issue modeling result.
          &quot;issueModel&quot;: &quot;A String&quot;, # Issue model that generates the result. Format: projects/{project}/locations/{location}/issueModels/{issue_model}
          &quot;issues&quot;: [ # All the matched issues.
            { # Information about the issue.
              &quot;displayName&quot;: &quot;A String&quot;, # Immutable. Display name of the assigned issue. This field is set at time of analyis and immutable since then.
              &quot;issue&quot;: &quot;A String&quot;, # Resource name of the assigned issue.
              &quot;score&quot;: 3.14, # Score indicating the likelihood of the issue assignment. currently bounded on [0,1].
            },
          ],
        },
        &quot;phraseMatchers&quot;: { # All the matched phrase matchers in the call.
          &quot;a_key&quot;: { # The data for a matched phrase matcher. Represents information identifying a phrase matcher for a given match.
            &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the phrase matcher.
            &quot;phraseMatcher&quot;: &quot;A String&quot;, # The unique identifier (the resource name) of the phrase matcher.
          },
        },
        &quot;sentiments&quot;: [ # Overall conversation-level sentiment for each channel of the call.
          { # One channel of conversation-level sentiment data.
            &quot;channelTag&quot;: 42, # The channel of the audio that the data applies to.
            &quot;sentimentData&quot;: { # The data for a sentiment annotation. # Data specifying sentiment.
              &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
              &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
            },
          },
        ],
        &quot;silence&quot;: { # Conversation-level silence data. # Overall conversation-level silence during the call.
          &quot;silenceDuration&quot;: &quot;A String&quot;, # Amount of time calculated to be in silence.
          &quot;silencePercentage&quot;: 3.14, # Percentage of the total conversation spent in silence.
        },
      },
      &quot;endTime&quot;: &quot;A String&quot;, # The time at which the analysis ended.
    },
    &quot;annotatorSelector&quot;: { # Selector of all available annotators and phrase matchers to run. # To select the annotators to run and the phrase matchers to use (if any). If not specified, all annotators will be run.
      &quot;issueModels&quot;: [ # The issue model to run. If not provided, the most recently deployed topic model will be used. The provided issue model will only be used for inference if the issue model is deployed and if run_issue_model_annotator is set to true. If more than one issue model is provided, only the first provided issue model will be used for inference.
        &quot;A String&quot;,
      ],
      &quot;phraseMatchers&quot;: [ # The list of phrase matchers to run. If not provided, all active phrase matchers will be used. If inactive phrase matchers are provided, they will not be used. Phrase matchers will be run only if run_phrase_matcher_annotator is set to true. Format: projects/{project}/locations/{location}/phraseMatchers/{phrase_matcher}
        &quot;A String&quot;,
      ],
      &quot;runEntityAnnotator&quot;: True or False, # Whether to run the entity annotator.
      &quot;runIntentAnnotator&quot;: True or False, # Whether to run the intent annotator.
      &quot;runInterruptionAnnotator&quot;: True or False, # Whether to run the interruption annotator.
      &quot;runIssueModelAnnotator&quot;: True or False, # Whether to run the issue model annotator. A model should have already been deployed for this to take effect.
      &quot;runPhraseMatcherAnnotator&quot;: True or False, # Whether to run the active phrase matcher annotator(s).
      &quot;runSentimentAnnotator&quot;: True or False, # Whether to run the sentiment annotator.
      &quot;runSilenceAnnotator&quot;: True or False, # Whether to run the silence annotator.
      &quot;runSummarizationAnnotator&quot;: True or False, # Whether to run the summarization annotator.
      &quot;summarizationConfig&quot;: { # Configuration for summarization. # Configuration for the summarization annotator.
        &quot;conversationProfile&quot;: &quot;A String&quot;, # Resource name of the Dialogflow conversation profile. Format: projects/{project}/locations/{location}/conversationProfiles/{conversation_profile}
        &quot;summarizationModel&quot;: &quot;A String&quot;, # Default summarization model to be used.
      },
    },
    &quot;createTime&quot;: &quot;A String&quot;, # Output only. The time at which the analysis was created, which occurs when the long-running operation completes.
    &quot;name&quot;: &quot;A String&quot;, # Immutable. The resource name of the analysis. Format: projects/{project}/locations/{location}/conversations/{conversation}/analyses/{analysis}
    &quot;requestTime&quot;: &quot;A String&quot;, # Output only. The time at which the analysis was requested.
  },
  &quot;latestSummary&quot;: { # Conversation summarization suggestion data. # Output only. Latest summary of the conversation.
    &quot;answerRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
    &quot;confidence&quot;: 3.14, # The confidence score of the summarization.
    &quot;conversationModel&quot;: &quot;A String&quot;, # The name of the model that generates this summary. Format: projects/{project}/locations/{location}/conversationModels/{conversation_model}
    &quot;metadata&quot;: { # A map that contains metadata about the summarization and the document from which it originates.
      &quot;a_key&quot;: &quot;A String&quot;,
    },
    &quot;text&quot;: &quot;A String&quot;, # The summarization content that is concatenated into one string.
    &quot;textSections&quot;: { # The summarization content that is divided into sections. The key is the section&#x27;s name and the value is the section&#x27;s content. There is no specific format for the key or value.
      &quot;a_key&quot;: &quot;A String&quot;,
    },
  },
  &quot;medium&quot;: &quot;A String&quot;, # Immutable. The conversation medium, if unspecified will default to PHONE_CALL.
  &quot;metadataJson&quot;: &quot;A String&quot;, # Input only. JSON Metadata encoded as a string. This field is primarily used by Insights integrations with various telphony systems and must be in one of Insights&#x27; supported formats.
  &quot;name&quot;: &quot;A String&quot;, # Immutable. The resource name of the conversation. Format: projects/{project}/locations/{location}/conversations/{conversation}
  &quot;obfuscatedUserId&quot;: &quot;A String&quot;, # Obfuscated user ID which the customer sent to us.
  &quot;qualityMetadata&quot;: { # Conversation metadata related to quality management. # Conversation metadata related to quality management.
    &quot;agentInfo&quot;: [ # Information about agents involved in the call.
      { # Information about an agent involved in the conversation.
        &quot;agentId&quot;: &quot;A String&quot;, # A user-specified string representing the agent.
        &quot;displayName&quot;: &quot;A String&quot;, # The agent&#x27;s name.
        &quot;dispositionCode&quot;: &quot;A String&quot;, # A user-provided string indicating the outcome of the agent&#x27;s segment of the call.
        &quot;team&quot;: &quot;A String&quot;, # A user-specified string representing the agent&#x27;s team.
      },
    ],
    &quot;customerSatisfactionRating&quot;: 42, # An arbitrary integer value indicating the customer&#x27;s satisfaction rating.
    &quot;menuPath&quot;: &quot;A String&quot;, # An arbitrary string value specifying the menu path the customer took.
    &quot;waitDuration&quot;: &quot;A String&quot;, # The amount of time the customer waited to connect with an agent.
  },
  &quot;runtimeAnnotations&quot;: [ # Output only. The annotations that were generated during the customer and agent interaction.
    { # An annotation that was generated during the customer and agent interaction.
      &quot;annotationId&quot;: &quot;A String&quot;, # The unique identifier of the annotation. Format: projects/{project}/locations/{location}/conversationDatasets/{dataset}/conversationDataItems/{data_item}/conversationAnnotations/{annotation}
      &quot;answerFeedback&quot;: { # The feedback that the customer has about a certain answer in the conversation. # The feedback that the customer has about the answer in `data`.
        &quot;clicked&quot;: True or False, # Indicates whether an answer or item was clicked by the human agent.
        &quot;correctnessLevel&quot;: &quot;A String&quot;, # The correctness level of an answer.
        &quot;displayed&quot;: True or False, # Indicates whether an answer or item was displayed to the human agent in the agent desktop UI.
      },
      &quot;articleSuggestion&quot;: { # Agent Assist Article Suggestion data. # Agent Assist Article Suggestion data.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this article is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the Article Suggestion and the document that it originates from.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
        &quot;source&quot;: &quot;A String&quot;, # The knowledge document that this answer was extracted from. Format: projects/{project}/knowledgeBases/{knowledge_base}/documents/{document}
        &quot;title&quot;: &quot;A String&quot;, # Article title.
        &quot;uri&quot;: &quot;A String&quot;, # Article URI.
      },
      &quot;conversationSummarizationSuggestion&quot;: { # Conversation summarization suggestion data. # Conversation summarization suggestion data.
        &quot;answerRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
        &quot;confidence&quot;: 3.14, # The confidence score of the summarization.
        &quot;conversationModel&quot;: &quot;A String&quot;, # The name of the model that generates this summary. Format: projects/{project}/locations/{location}/conversationModels/{conversation_model}
        &quot;metadata&quot;: { # A map that contains metadata about the summarization and the document from which it originates.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;text&quot;: &quot;A String&quot;, # The summarization content that is concatenated into one string.
        &quot;textSections&quot;: { # The summarization content that is divided into sections. The key is the section&#x27;s name and the value is the section&#x27;s content. There is no specific format for the key or value.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
      },
      &quot;createTime&quot;: &quot;A String&quot;, # The time at which this annotation was created.
      &quot;dialogflowInteraction&quot;: { # Dialogflow interaction data. # Dialogflow interaction data.
        &quot;confidence&quot;: 3.14, # The confidence of the match ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;dialogflowIntentId&quot;: &quot;A String&quot;, # The Dialogflow intent resource path. Format: projects/{project}/agent/{agent}/intents/{intent}
      },
      &quot;endBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation ends, inclusive.
        &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
        &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
      },
      &quot;faqAnswer&quot;: { # Agent Assist frequently-asked-question answer data. # Agent Assist FAQ answer data.
        &quot;answer&quot;: &quot;A String&quot;, # The piece of text from the `source` knowledge base document.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this answer is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the FAQ answer and the document that it originates from.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
        &quot;question&quot;: &quot;A String&quot;, # The corresponding FAQ question.
        &quot;source&quot;: &quot;A String&quot;, # The knowledge document that this answer was extracted from. Format: projects/{project}/knowledgeBases/{knowledge_base}/documents/{document}.
      },
      &quot;smartComposeSuggestion&quot;: { # Agent Assist Smart Compose suggestion data. # Agent Assist Smart Compose suggestion data.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this suggestion is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the Smart Compose suggestion and the document from which it originates.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
        &quot;suggestion&quot;: &quot;A String&quot;, # The content of the suggestion.
      },
      &quot;smartReply&quot;: { # Agent Assist Smart Reply data. # Agent Assist Smart Reply data.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this reply is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the Smart Reply and the document from which it originates.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
        &quot;reply&quot;: &quot;A String&quot;, # The content of the reply.
      },
      &quot;startBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation starts, inclusive.
        &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
        &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
      },
      &quot;userInput&quot;: { # Explicit input used for generating the answer # Explicit input used for generating the answer
        &quot;generatorName&quot;: &quot;A String&quot;, # The resource name of associated generator. Format: `projects//locations//generators/`
        &quot;query&quot;: &quot;A String&quot;, # Query text. Article Search uses this to store the input query used to generate the search results.
        &quot;querySource&quot;: &quot;A String&quot;, # Query source for the answer.
      },
    },
  ],
  &quot;startTime&quot;: &quot;A String&quot;, # The time at which the conversation started.
  &quot;transcript&quot;: { # A message representing the transcript of a conversation. # Output only. The conversation transcript.
    &quot;transcriptSegments&quot;: [ # A list of sequential transcript segments that comprise the conversation.
      { # A segment of a full transcript.
        &quot;channelTag&quot;: 42, # For conversations derived from multi-channel audio, this is the channel number corresponding to the audio from that channel. For audioChannelCount = N, its output values can range from &#x27;1&#x27; to &#x27;N&#x27;. A channel tag of 0 indicates that the audio is mono.
        &quot;confidence&quot;: 3.14, # A confidence estimate between 0.0 and 1.0 of the fidelity of this segment. A default value of 0.0 indicates that the value is unset.
        &quot;dialogflowSegmentMetadata&quot;: { # Metadata from Dialogflow relating to the current transcript segment. # CCAI metadata relating to the current transcript segment.
          &quot;smartReplyAllowlistCovered&quot;: True or False, # Whether the transcript segment was covered under the configured smart reply allowlist in Agent Assist.
        },
        &quot;languageCode&quot;: &quot;A String&quot;, # The language code of this segment as a [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag. Example: &quot;en-US&quot;.
        &quot;messageTime&quot;: &quot;A String&quot;, # The time that the message occurred, if provided.
        &quot;segmentParticipant&quot;: { # The call participant speaking for a given utterance. # The participant of this segment.
          &quot;dialogflowParticipant&quot;: &quot;A String&quot;, # Deprecated. Use `dialogflow_participant_name` instead. The name of the Dialogflow participant. Format: projects/{project}/locations/{location}/conversations/{conversation}/participants/{participant}
          &quot;dialogflowParticipantName&quot;: &quot;A String&quot;, # The name of the participant provided by Dialogflow. Format: projects/{project}/locations/{location}/conversations/{conversation}/participants/{participant}
          &quot;obfuscatedExternalUserId&quot;: &quot;A String&quot;, # Obfuscated user ID from Dialogflow.
          &quot;role&quot;: &quot;A String&quot;, # The role of the participant.
          &quot;userId&quot;: &quot;A String&quot;, # A user-specified ID representing the participant.
        },
        &quot;sentiment&quot;: { # The data for a sentiment annotation. # The sentiment for this transcript segment.
          &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
          &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
        },
        &quot;text&quot;: &quot;A String&quot;, # The text of this segment.
        &quot;words&quot;: [ # A list of the word-specific information for each word in the segment.
          { # Word-level info for words in a transcript.
            &quot;confidence&quot;: 3.14, # A confidence estimate between 0.0 and 1.0 of the fidelity of this word. A default value of 0.0 indicates that the value is unset.
            &quot;endOffset&quot;: &quot;A String&quot;, # Time offset of the end of this word relative to the beginning of the total conversation.
            &quot;startOffset&quot;: &quot;A String&quot;, # Time offset of the start of this word relative to the beginning of the total conversation.
            &quot;word&quot;: &quot;A String&quot;, # The word itself. Includes punctuation marks that surround the word.
          },
        ],
      },
    ],
  },
  &quot;ttl&quot;: &quot;A String&quot;, # Input only. The TTL for this resource. If specified, then this TTL will be used to calculate the expire time.
  &quot;turnCount&quot;: 42, # Output only. The number of turns in the conversation.
  &quot;updateTime&quot;: &quot;A String&quot;, # Output only. The most recent time at which the conversation was updated.
}

  conversationId: string, A unique ID for the new conversation. This ID will become the final component of the conversation&#x27;s resource name. If no ID is specified, a server-generated ID will be used. This value should be 4-64 characters and must match the regular expression `^[a-z0-9-]{4,64}$`. Valid characters are `a-z-`
  x__xgafv: string, V1 error format.
    Allowed values
      1 - v1 error format
      2 - v2 error format

Returns:
  An object of the form:

    { # The conversation resource.
  &quot;agentId&quot;: &quot;A String&quot;, # An opaque, user-specified string representing the human agent who handled the conversation.
  &quot;callMetadata&quot;: { # Call-specific metadata. # Call-specific metadata.
    &quot;agentChannel&quot;: 42, # The audio channel that contains the agent.
    &quot;customerChannel&quot;: 42, # The audio channel that contains the customer.
  },
  &quot;createTime&quot;: &quot;A String&quot;, # Output only. The time at which the conversation was created.
  &quot;dataSource&quot;: { # The conversation source, which is a combination of transcript and audio. # The source of the audio and transcription for the conversation.
    &quot;dialogflowSource&quot;: { # A Dialogflow source of conversation data. # The source when the conversation comes from Dialogflow.
      &quot;audioUri&quot;: &quot;A String&quot;, # Cloud Storage URI that points to a file that contains the conversation audio.
      &quot;dialogflowConversation&quot;: &quot;A String&quot;, # Output only. The name of the Dialogflow conversation that this conversation resource is derived from. Format: projects/{project}/locations/{location}/conversations/{conversation}
    },
    &quot;gcsSource&quot;: { # A Cloud Storage source of conversation data. # A Cloud Storage location specification for the audio and transcript.
      &quot;audioUri&quot;: &quot;A String&quot;, # Cloud Storage URI that points to a file that contains the conversation audio.
      &quot;transcriptUri&quot;: &quot;A String&quot;, # Immutable. Cloud Storage URI that points to a file that contains the conversation transcript.
    },
  },
  &quot;dialogflowIntents&quot;: { # Output only. All the matched Dialogflow intents in the call. The key corresponds to a Dialogflow intent, format: projects/{project}/agent/{agent}/intents/{intent}
    &quot;a_key&quot;: { # The data for a Dialogflow intent. Represents a detected intent in the conversation, e.g. MAKES_PROMISE.
      &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the intent.
    },
  },
  &quot;duration&quot;: &quot;A String&quot;, # Output only. The duration of the conversation.
  &quot;expireTime&quot;: &quot;A String&quot;, # The time at which this conversation should expire. After this time, the conversation data and any associated analyses will be deleted.
  &quot;labels&quot;: { # A map for the user to specify any custom fields. A maximum of 20 labels per conversation is allowed, with a maximum of 256 characters per entry.
    &quot;a_key&quot;: &quot;A String&quot;,
  },
  &quot;languageCode&quot;: &quot;A String&quot;, # A user-specified language code for the conversation.
  &quot;latestAnalysis&quot;: { # The analysis resource. # Output only. The conversation&#x27;s latest analysis, if one exists.
    &quot;analysisResult&quot;: { # The result of an analysis. # Output only. The result of the analysis, which is populated when the analysis finishes.
      &quot;callAnalysisMetadata&quot;: { # Call-specific metadata created during analysis. # Call-specific metadata created by the analysis.
        &quot;annotations&quot;: [ # A list of call annotations that apply to this call.
          { # A piece of metadata that applies to a window of a call.
            &quot;annotationEndBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation ends, inclusive.
              &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
              &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
            },
            &quot;annotationStartBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation starts, inclusive.
              &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
              &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
            },
            &quot;channelTag&quot;: 42, # The channel of the audio where the annotation occurs. For single-channel audio, this field is not populated.
            &quot;entityMentionData&quot;: { # The data for an entity mention annotation. This represents a mention of an `Entity` in the conversation. # Data specifying an entity mention.
              &quot;entityUniqueId&quot;: &quot;A String&quot;, # The key of this entity in conversation entities. Can be used to retrieve the exact `Entity` this mention is attached to.
              &quot;sentiment&quot;: { # The data for a sentiment annotation. # Sentiment expressed for this mention of the entity.
                &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
                &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
              },
              &quot;type&quot;: &quot;A String&quot;, # The type of the entity mention.
            },
            &quot;holdData&quot;: { # The data for a hold annotation. # Data specifying a hold.
            },
            &quot;intentMatchData&quot;: { # The data for an intent match. Represents an intent match for a text segment in the conversation. A text segment can be part of a sentence, a complete sentence, or an utterance with multiple sentences. # Data specifying an intent match.
              &quot;intentUniqueId&quot;: &quot;A String&quot;, # The id of the matched intent. Can be used to retrieve the corresponding intent information.
            },
            &quot;interruptionData&quot;: { # The data for an interruption annotation. # Data specifying an interruption.
            },
            &quot;issueMatchData&quot;: { # The data for an issue match annotation. # Data specifying an issue match.
              &quot;issueAssignment&quot;: { # Information about the issue. # Information about the issue&#x27;s assignment.
                &quot;displayName&quot;: &quot;A String&quot;, # Immutable. Display name of the assigned issue. This field is set at time of analyis and immutable since then.
                &quot;issue&quot;: &quot;A String&quot;, # Resource name of the assigned issue.
                &quot;score&quot;: 3.14, # Score indicating the likelihood of the issue assignment. currently bounded on [0,1].
              },
            },
            &quot;phraseMatchData&quot;: { # The data for a matched phrase matcher. Represents information identifying a phrase matcher for a given match. # Data specifying a phrase match.
              &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the phrase matcher.
              &quot;phraseMatcher&quot;: &quot;A String&quot;, # The unique identifier (the resource name) of the phrase matcher.
            },
            &quot;sentimentData&quot;: { # The data for a sentiment annotation. # Data specifying sentiment.
              &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
              &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
            },
            &quot;silenceData&quot;: { # The data for a silence annotation. # Data specifying silence.
            },
          },
        ],
        &quot;entities&quot;: { # All the entities in the call.
          &quot;a_key&quot;: { # The data for an entity annotation. Represents a phrase in the conversation that is a known entity, such as a person, an organization, or location.
            &quot;displayName&quot;: &quot;A String&quot;, # The representative name for the entity.
            &quot;metadata&quot;: { # Metadata associated with the entity. For most entity types, the metadata is a Wikipedia URL (`wikipedia_url`) and Knowledge Graph MID (`mid`), if they are available. For the metadata associated with other entity types, see the Type table below.
              &quot;a_key&quot;: &quot;A String&quot;,
            },
            &quot;salience&quot;: 3.14, # The salience score associated with the entity in the [0, 1.0] range. The salience score for an entity provides information about the importance or centrality of that entity to the entire document text. Scores closer to 0 are less salient, while scores closer to 1.0 are highly salient.
            &quot;sentiment&quot;: { # The data for a sentiment annotation. # The aggregate sentiment expressed for this entity in the conversation.
              &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
              &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
            },
            &quot;type&quot;: &quot;A String&quot;, # The entity type.
          },
        },
        &quot;intents&quot;: { # All the matched intents in the call.
          &quot;a_key&quot;: { # The data for an intent. Represents a detected intent in the conversation, for example MAKES_PROMISE.
            &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the intent.
            &quot;id&quot;: &quot;A String&quot;, # The unique identifier of the intent.
          },
        },
        &quot;issueModelResult&quot;: { # Issue Modeling result on a conversation. # Overall conversation-level issue modeling result.
          &quot;issueModel&quot;: &quot;A String&quot;, # Issue model that generates the result. Format: projects/{project}/locations/{location}/issueModels/{issue_model}
          &quot;issues&quot;: [ # All the matched issues.
            { # Information about the issue.
              &quot;displayName&quot;: &quot;A String&quot;, # Immutable. Display name of the assigned issue. This field is set at time of analyis and immutable since then.
              &quot;issue&quot;: &quot;A String&quot;, # Resource name of the assigned issue.
              &quot;score&quot;: 3.14, # Score indicating the likelihood of the issue assignment. currently bounded on [0,1].
            },
          ],
        },
        &quot;phraseMatchers&quot;: { # All the matched phrase matchers in the call.
          &quot;a_key&quot;: { # The data for a matched phrase matcher. Represents information identifying a phrase matcher for a given match.
            &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the phrase matcher.
            &quot;phraseMatcher&quot;: &quot;A String&quot;, # The unique identifier (the resource name) of the phrase matcher.
          },
        },
        &quot;sentiments&quot;: [ # Overall conversation-level sentiment for each channel of the call.
          { # One channel of conversation-level sentiment data.
            &quot;channelTag&quot;: 42, # The channel of the audio that the data applies to.
            &quot;sentimentData&quot;: { # The data for a sentiment annotation. # Data specifying sentiment.
              &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
              &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
            },
          },
        ],
        &quot;silence&quot;: { # Conversation-level silence data. # Overall conversation-level silence during the call.
          &quot;silenceDuration&quot;: &quot;A String&quot;, # Amount of time calculated to be in silence.
          &quot;silencePercentage&quot;: 3.14, # Percentage of the total conversation spent in silence.
        },
      },
      &quot;endTime&quot;: &quot;A String&quot;, # The time at which the analysis ended.
    },
    &quot;annotatorSelector&quot;: { # Selector of all available annotators and phrase matchers to run. # To select the annotators to run and the phrase matchers to use (if any). If not specified, all annotators will be run.
      &quot;issueModels&quot;: [ # The issue model to run. If not provided, the most recently deployed topic model will be used. The provided issue model will only be used for inference if the issue model is deployed and if run_issue_model_annotator is set to true. If more than one issue model is provided, only the first provided issue model will be used for inference.
        &quot;A String&quot;,
      ],
      &quot;phraseMatchers&quot;: [ # The list of phrase matchers to run. If not provided, all active phrase matchers will be used. If inactive phrase matchers are provided, they will not be used. Phrase matchers will be run only if run_phrase_matcher_annotator is set to true. Format: projects/{project}/locations/{location}/phraseMatchers/{phrase_matcher}
        &quot;A String&quot;,
      ],
      &quot;runEntityAnnotator&quot;: True or False, # Whether to run the entity annotator.
      &quot;runIntentAnnotator&quot;: True or False, # Whether to run the intent annotator.
      &quot;runInterruptionAnnotator&quot;: True or False, # Whether to run the interruption annotator.
      &quot;runIssueModelAnnotator&quot;: True or False, # Whether to run the issue model annotator. A model should have already been deployed for this to take effect.
      &quot;runPhraseMatcherAnnotator&quot;: True or False, # Whether to run the active phrase matcher annotator(s).
      &quot;runSentimentAnnotator&quot;: True or False, # Whether to run the sentiment annotator.
      &quot;runSilenceAnnotator&quot;: True or False, # Whether to run the silence annotator.
      &quot;runSummarizationAnnotator&quot;: True or False, # Whether to run the summarization annotator.
      &quot;summarizationConfig&quot;: { # Configuration for summarization. # Configuration for the summarization annotator.
        &quot;conversationProfile&quot;: &quot;A String&quot;, # Resource name of the Dialogflow conversation profile. Format: projects/{project}/locations/{location}/conversationProfiles/{conversation_profile}
        &quot;summarizationModel&quot;: &quot;A String&quot;, # Default summarization model to be used.
      },
    },
    &quot;createTime&quot;: &quot;A String&quot;, # Output only. The time at which the analysis was created, which occurs when the long-running operation completes.
    &quot;name&quot;: &quot;A String&quot;, # Immutable. The resource name of the analysis. Format: projects/{project}/locations/{location}/conversations/{conversation}/analyses/{analysis}
    &quot;requestTime&quot;: &quot;A String&quot;, # Output only. The time at which the analysis was requested.
  },
  &quot;latestSummary&quot;: { # Conversation summarization suggestion data. # Output only. Latest summary of the conversation.
    &quot;answerRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
    &quot;confidence&quot;: 3.14, # The confidence score of the summarization.
    &quot;conversationModel&quot;: &quot;A String&quot;, # The name of the model that generates this summary. Format: projects/{project}/locations/{location}/conversationModels/{conversation_model}
    &quot;metadata&quot;: { # A map that contains metadata about the summarization and the document from which it originates.
      &quot;a_key&quot;: &quot;A String&quot;,
    },
    &quot;text&quot;: &quot;A String&quot;, # The summarization content that is concatenated into one string.
    &quot;textSections&quot;: { # The summarization content that is divided into sections. The key is the section&#x27;s name and the value is the section&#x27;s content. There is no specific format for the key or value.
      &quot;a_key&quot;: &quot;A String&quot;,
    },
  },
  &quot;medium&quot;: &quot;A String&quot;, # Immutable. The conversation medium, if unspecified will default to PHONE_CALL.
  &quot;metadataJson&quot;: &quot;A String&quot;, # Input only. JSON Metadata encoded as a string. This field is primarily used by Insights integrations with various telphony systems and must be in one of Insights&#x27; supported formats.
  &quot;name&quot;: &quot;A String&quot;, # Immutable. The resource name of the conversation. Format: projects/{project}/locations/{location}/conversations/{conversation}
  &quot;obfuscatedUserId&quot;: &quot;A String&quot;, # Obfuscated user ID which the customer sent to us.
  &quot;qualityMetadata&quot;: { # Conversation metadata related to quality management. # Conversation metadata related to quality management.
    &quot;agentInfo&quot;: [ # Information about agents involved in the call.
      { # Information about an agent involved in the conversation.
        &quot;agentId&quot;: &quot;A String&quot;, # A user-specified string representing the agent.
        &quot;displayName&quot;: &quot;A String&quot;, # The agent&#x27;s name.
        &quot;dispositionCode&quot;: &quot;A String&quot;, # A user-provided string indicating the outcome of the agent&#x27;s segment of the call.
        &quot;team&quot;: &quot;A String&quot;, # A user-specified string representing the agent&#x27;s team.
      },
    ],
    &quot;customerSatisfactionRating&quot;: 42, # An arbitrary integer value indicating the customer&#x27;s satisfaction rating.
    &quot;menuPath&quot;: &quot;A String&quot;, # An arbitrary string value specifying the menu path the customer took.
    &quot;waitDuration&quot;: &quot;A String&quot;, # The amount of time the customer waited to connect with an agent.
  },
  &quot;runtimeAnnotations&quot;: [ # Output only. The annotations that were generated during the customer and agent interaction.
    { # An annotation that was generated during the customer and agent interaction.
      &quot;annotationId&quot;: &quot;A String&quot;, # The unique identifier of the annotation. Format: projects/{project}/locations/{location}/conversationDatasets/{dataset}/conversationDataItems/{data_item}/conversationAnnotations/{annotation}
      &quot;answerFeedback&quot;: { # The feedback that the customer has about a certain answer in the conversation. # The feedback that the customer has about the answer in `data`.
        &quot;clicked&quot;: True or False, # Indicates whether an answer or item was clicked by the human agent.
        &quot;correctnessLevel&quot;: &quot;A String&quot;, # The correctness level of an answer.
        &quot;displayed&quot;: True or False, # Indicates whether an answer or item was displayed to the human agent in the agent desktop UI.
      },
      &quot;articleSuggestion&quot;: { # Agent Assist Article Suggestion data. # Agent Assist Article Suggestion data.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this article is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the Article Suggestion and the document that it originates from.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
        &quot;source&quot;: &quot;A String&quot;, # The knowledge document that this answer was extracted from. Format: projects/{project}/knowledgeBases/{knowledge_base}/documents/{document}
        &quot;title&quot;: &quot;A String&quot;, # Article title.
        &quot;uri&quot;: &quot;A String&quot;, # Article URI.
      },
      &quot;conversationSummarizationSuggestion&quot;: { # Conversation summarization suggestion data. # Conversation summarization suggestion data.
        &quot;answerRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
        &quot;confidence&quot;: 3.14, # The confidence score of the summarization.
        &quot;conversationModel&quot;: &quot;A String&quot;, # The name of the model that generates this summary. Format: projects/{project}/locations/{location}/conversationModels/{conversation_model}
        &quot;metadata&quot;: { # A map that contains metadata about the summarization and the document from which it originates.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;text&quot;: &quot;A String&quot;, # The summarization content that is concatenated into one string.
        &quot;textSections&quot;: { # The summarization content that is divided into sections. The key is the section&#x27;s name and the value is the section&#x27;s content. There is no specific format for the key or value.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
      },
      &quot;createTime&quot;: &quot;A String&quot;, # The time at which this annotation was created.
      &quot;dialogflowInteraction&quot;: { # Dialogflow interaction data. # Dialogflow interaction data.
        &quot;confidence&quot;: 3.14, # The confidence of the match ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;dialogflowIntentId&quot;: &quot;A String&quot;, # The Dialogflow intent resource path. Format: projects/{project}/agent/{agent}/intents/{intent}
      },
      &quot;endBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation ends, inclusive.
        &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
        &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
      },
      &quot;faqAnswer&quot;: { # Agent Assist frequently-asked-question answer data. # Agent Assist FAQ answer data.
        &quot;answer&quot;: &quot;A String&quot;, # The piece of text from the `source` knowledge base document.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this answer is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the FAQ answer and the document that it originates from.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
        &quot;question&quot;: &quot;A String&quot;, # The corresponding FAQ question.
        &quot;source&quot;: &quot;A String&quot;, # The knowledge document that this answer was extracted from. Format: projects/{project}/knowledgeBases/{knowledge_base}/documents/{document}.
      },
      &quot;smartComposeSuggestion&quot;: { # Agent Assist Smart Compose suggestion data. # Agent Assist Smart Compose suggestion data.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this suggestion is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the Smart Compose suggestion and the document from which it originates.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
        &quot;suggestion&quot;: &quot;A String&quot;, # The content of the suggestion.
      },
      &quot;smartReply&quot;: { # Agent Assist Smart Reply data. # Agent Assist Smart Reply data.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this reply is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the Smart Reply and the document from which it originates.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
        &quot;reply&quot;: &quot;A String&quot;, # The content of the reply.
      },
      &quot;startBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation starts, inclusive.
        &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
        &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
      },
      &quot;userInput&quot;: { # Explicit input used for generating the answer # Explicit input used for generating the answer
        &quot;generatorName&quot;: &quot;A String&quot;, # The resource name of associated generator. Format: `projects//locations//generators/`
        &quot;query&quot;: &quot;A String&quot;, # Query text. Article Search uses this to store the input query used to generate the search results.
        &quot;querySource&quot;: &quot;A String&quot;, # Query source for the answer.
      },
    },
  ],
  &quot;startTime&quot;: &quot;A String&quot;, # The time at which the conversation started.
  &quot;transcript&quot;: { # A message representing the transcript of a conversation. # Output only. The conversation transcript.
    &quot;transcriptSegments&quot;: [ # A list of sequential transcript segments that comprise the conversation.
      { # A segment of a full transcript.
        &quot;channelTag&quot;: 42, # For conversations derived from multi-channel audio, this is the channel number corresponding to the audio from that channel. For audioChannelCount = N, its output values can range from &#x27;1&#x27; to &#x27;N&#x27;. A channel tag of 0 indicates that the audio is mono.
        &quot;confidence&quot;: 3.14, # A confidence estimate between 0.0 and 1.0 of the fidelity of this segment. A default value of 0.0 indicates that the value is unset.
        &quot;dialogflowSegmentMetadata&quot;: { # Metadata from Dialogflow relating to the current transcript segment. # CCAI metadata relating to the current transcript segment.
          &quot;smartReplyAllowlistCovered&quot;: True or False, # Whether the transcript segment was covered under the configured smart reply allowlist in Agent Assist.
        },
        &quot;languageCode&quot;: &quot;A String&quot;, # The language code of this segment as a [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag. Example: &quot;en-US&quot;.
        &quot;messageTime&quot;: &quot;A String&quot;, # The time that the message occurred, if provided.
        &quot;segmentParticipant&quot;: { # The call participant speaking for a given utterance. # The participant of this segment.
          &quot;dialogflowParticipant&quot;: &quot;A String&quot;, # Deprecated. Use `dialogflow_participant_name` instead. The name of the Dialogflow participant. Format: projects/{project}/locations/{location}/conversations/{conversation}/participants/{participant}
          &quot;dialogflowParticipantName&quot;: &quot;A String&quot;, # The name of the participant provided by Dialogflow. Format: projects/{project}/locations/{location}/conversations/{conversation}/participants/{participant}
          &quot;obfuscatedExternalUserId&quot;: &quot;A String&quot;, # Obfuscated user ID from Dialogflow.
          &quot;role&quot;: &quot;A String&quot;, # The role of the participant.
          &quot;userId&quot;: &quot;A String&quot;, # A user-specified ID representing the participant.
        },
        &quot;sentiment&quot;: { # The data for a sentiment annotation. # The sentiment for this transcript segment.
          &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
          &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
        },
        &quot;text&quot;: &quot;A String&quot;, # The text of this segment.
        &quot;words&quot;: [ # A list of the word-specific information for each word in the segment.
          { # Word-level info for words in a transcript.
            &quot;confidence&quot;: 3.14, # A confidence estimate between 0.0 and 1.0 of the fidelity of this word. A default value of 0.0 indicates that the value is unset.
            &quot;endOffset&quot;: &quot;A String&quot;, # Time offset of the end of this word relative to the beginning of the total conversation.
            &quot;startOffset&quot;: &quot;A String&quot;, # Time offset of the start of this word relative to the beginning of the total conversation.
            &quot;word&quot;: &quot;A String&quot;, # The word itself. Includes punctuation marks that surround the word.
          },
        ],
      },
    ],
  },
  &quot;ttl&quot;: &quot;A String&quot;, # Input only. The TTL for this resource. If specified, then this TTL will be used to calculate the expire time.
  &quot;turnCount&quot;: 42, # Output only. The number of turns in the conversation.
  &quot;updateTime&quot;: &quot;A String&quot;, # Output only. The most recent time at which the conversation was updated.
}</pre>
</div>

<div class="method">
    <code class="details" id="delete">delete(name, force=None, x__xgafv=None)</code>
  <pre>Deletes a conversation.

Args:
  name: string, Required. The name of the conversation to delete. (required)
  force: boolean, If set to true, all of this conversation&#x27;s analyses will also be deleted. Otherwise, the request will only succeed if the conversation has no analyses.
  x__xgafv: string, V1 error format.
    Allowed values
      1 - v1 error format
      2 - v2 error format

Returns:
  An object of the form:

    { # A generic empty message that you can re-use to avoid defining duplicated empty messages in your APIs. A typical example is to use it as the request or the response type of an API method. For instance: service Foo { rpc Bar(google.protobuf.Empty) returns (google.protobuf.Empty); }
}</pre>
</div>

<div class="method">
    <code class="details" id="get">get(name, view=None, x__xgafv=None)</code>
  <pre>Gets a conversation.

Args:
  name: string, Required. The name of the conversation to get. (required)
  view: string, The level of details of the conversation. Default is `FULL`.
    Allowed values
      CONVERSATION_VIEW_UNSPECIFIED - The conversation view is not specified. * Defaults to `FULL` in `GetConversationRequest`. * Defaults to `BASIC` in `ListConversationsRequest`.
      FULL - Populates all fields in the conversation.
      BASIC - Populates all fields in the conversation except the transcript.
  x__xgafv: string, V1 error format.
    Allowed values
      1 - v1 error format
      2 - v2 error format

Returns:
  An object of the form:

    { # The conversation resource.
  &quot;agentId&quot;: &quot;A String&quot;, # An opaque, user-specified string representing the human agent who handled the conversation.
  &quot;callMetadata&quot;: { # Call-specific metadata. # Call-specific metadata.
    &quot;agentChannel&quot;: 42, # The audio channel that contains the agent.
    &quot;customerChannel&quot;: 42, # The audio channel that contains the customer.
  },
  &quot;createTime&quot;: &quot;A String&quot;, # Output only. The time at which the conversation was created.
  &quot;dataSource&quot;: { # The conversation source, which is a combination of transcript and audio. # The source of the audio and transcription for the conversation.
    &quot;dialogflowSource&quot;: { # A Dialogflow source of conversation data. # The source when the conversation comes from Dialogflow.
      &quot;audioUri&quot;: &quot;A String&quot;, # Cloud Storage URI that points to a file that contains the conversation audio.
      &quot;dialogflowConversation&quot;: &quot;A String&quot;, # Output only. The name of the Dialogflow conversation that this conversation resource is derived from. Format: projects/{project}/locations/{location}/conversations/{conversation}
    },
    &quot;gcsSource&quot;: { # A Cloud Storage source of conversation data. # A Cloud Storage location specification for the audio and transcript.
      &quot;audioUri&quot;: &quot;A String&quot;, # Cloud Storage URI that points to a file that contains the conversation audio.
      &quot;transcriptUri&quot;: &quot;A String&quot;, # Immutable. Cloud Storage URI that points to a file that contains the conversation transcript.
    },
  },
  &quot;dialogflowIntents&quot;: { # Output only. All the matched Dialogflow intents in the call. The key corresponds to a Dialogflow intent, format: projects/{project}/agent/{agent}/intents/{intent}
    &quot;a_key&quot;: { # The data for a Dialogflow intent. Represents a detected intent in the conversation, e.g. MAKES_PROMISE.
      &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the intent.
    },
  },
  &quot;duration&quot;: &quot;A String&quot;, # Output only. The duration of the conversation.
  &quot;expireTime&quot;: &quot;A String&quot;, # The time at which this conversation should expire. After this time, the conversation data and any associated analyses will be deleted.
  &quot;labels&quot;: { # A map for the user to specify any custom fields. A maximum of 20 labels per conversation is allowed, with a maximum of 256 characters per entry.
    &quot;a_key&quot;: &quot;A String&quot;,
  },
  &quot;languageCode&quot;: &quot;A String&quot;, # A user-specified language code for the conversation.
  &quot;latestAnalysis&quot;: { # The analysis resource. # Output only. The conversation&#x27;s latest analysis, if one exists.
    &quot;analysisResult&quot;: { # The result of an analysis. # Output only. The result of the analysis, which is populated when the analysis finishes.
      &quot;callAnalysisMetadata&quot;: { # Call-specific metadata created during analysis. # Call-specific metadata created by the analysis.
        &quot;annotations&quot;: [ # A list of call annotations that apply to this call.
          { # A piece of metadata that applies to a window of a call.
            &quot;annotationEndBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation ends, inclusive.
              &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
              &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
            },
            &quot;annotationStartBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation starts, inclusive.
              &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
              &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
            },
            &quot;channelTag&quot;: 42, # The channel of the audio where the annotation occurs. For single-channel audio, this field is not populated.
            &quot;entityMentionData&quot;: { # The data for an entity mention annotation. This represents a mention of an `Entity` in the conversation. # Data specifying an entity mention.
              &quot;entityUniqueId&quot;: &quot;A String&quot;, # The key of this entity in conversation entities. Can be used to retrieve the exact `Entity` this mention is attached to.
              &quot;sentiment&quot;: { # The data for a sentiment annotation. # Sentiment expressed for this mention of the entity.
                &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
                &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
              },
              &quot;type&quot;: &quot;A String&quot;, # The type of the entity mention.
            },
            &quot;holdData&quot;: { # The data for a hold annotation. # Data specifying a hold.
            },
            &quot;intentMatchData&quot;: { # The data for an intent match. Represents an intent match for a text segment in the conversation. A text segment can be part of a sentence, a complete sentence, or an utterance with multiple sentences. # Data specifying an intent match.
              &quot;intentUniqueId&quot;: &quot;A String&quot;, # The id of the matched intent. Can be used to retrieve the corresponding intent information.
            },
            &quot;interruptionData&quot;: { # The data for an interruption annotation. # Data specifying an interruption.
            },
            &quot;issueMatchData&quot;: { # The data for an issue match annotation. # Data specifying an issue match.
              &quot;issueAssignment&quot;: { # Information about the issue. # Information about the issue&#x27;s assignment.
                &quot;displayName&quot;: &quot;A String&quot;, # Immutable. Display name of the assigned issue. This field is set at time of analyis and immutable since then.
                &quot;issue&quot;: &quot;A String&quot;, # Resource name of the assigned issue.
                &quot;score&quot;: 3.14, # Score indicating the likelihood of the issue assignment. currently bounded on [0,1].
              },
            },
            &quot;phraseMatchData&quot;: { # The data for a matched phrase matcher. Represents information identifying a phrase matcher for a given match. # Data specifying a phrase match.
              &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the phrase matcher.
              &quot;phraseMatcher&quot;: &quot;A String&quot;, # The unique identifier (the resource name) of the phrase matcher.
            },
            &quot;sentimentData&quot;: { # The data for a sentiment annotation. # Data specifying sentiment.
              &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
              &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
            },
            &quot;silenceData&quot;: { # The data for a silence annotation. # Data specifying silence.
            },
          },
        ],
        &quot;entities&quot;: { # All the entities in the call.
          &quot;a_key&quot;: { # The data for an entity annotation. Represents a phrase in the conversation that is a known entity, such as a person, an organization, or location.
            &quot;displayName&quot;: &quot;A String&quot;, # The representative name for the entity.
            &quot;metadata&quot;: { # Metadata associated with the entity. For most entity types, the metadata is a Wikipedia URL (`wikipedia_url`) and Knowledge Graph MID (`mid`), if they are available. For the metadata associated with other entity types, see the Type table below.
              &quot;a_key&quot;: &quot;A String&quot;,
            },
            &quot;salience&quot;: 3.14, # The salience score associated with the entity in the [0, 1.0] range. The salience score for an entity provides information about the importance or centrality of that entity to the entire document text. Scores closer to 0 are less salient, while scores closer to 1.0 are highly salient.
            &quot;sentiment&quot;: { # The data for a sentiment annotation. # The aggregate sentiment expressed for this entity in the conversation.
              &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
              &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
            },
            &quot;type&quot;: &quot;A String&quot;, # The entity type.
          },
        },
        &quot;intents&quot;: { # All the matched intents in the call.
          &quot;a_key&quot;: { # The data for an intent. Represents a detected intent in the conversation, for example MAKES_PROMISE.
            &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the intent.
            &quot;id&quot;: &quot;A String&quot;, # The unique identifier of the intent.
          },
        },
        &quot;issueModelResult&quot;: { # Issue Modeling result on a conversation. # Overall conversation-level issue modeling result.
          &quot;issueModel&quot;: &quot;A String&quot;, # Issue model that generates the result. Format: projects/{project}/locations/{location}/issueModels/{issue_model}
          &quot;issues&quot;: [ # All the matched issues.
            { # Information about the issue.
              &quot;displayName&quot;: &quot;A String&quot;, # Immutable. Display name of the assigned issue. This field is set at time of analyis and immutable since then.
              &quot;issue&quot;: &quot;A String&quot;, # Resource name of the assigned issue.
              &quot;score&quot;: 3.14, # Score indicating the likelihood of the issue assignment. currently bounded on [0,1].
            },
          ],
        },
        &quot;phraseMatchers&quot;: { # All the matched phrase matchers in the call.
          &quot;a_key&quot;: { # The data for a matched phrase matcher. Represents information identifying a phrase matcher for a given match.
            &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the phrase matcher.
            &quot;phraseMatcher&quot;: &quot;A String&quot;, # The unique identifier (the resource name) of the phrase matcher.
          },
        },
        &quot;sentiments&quot;: [ # Overall conversation-level sentiment for each channel of the call.
          { # One channel of conversation-level sentiment data.
            &quot;channelTag&quot;: 42, # The channel of the audio that the data applies to.
            &quot;sentimentData&quot;: { # The data for a sentiment annotation. # Data specifying sentiment.
              &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
              &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
            },
          },
        ],
        &quot;silence&quot;: { # Conversation-level silence data. # Overall conversation-level silence during the call.
          &quot;silenceDuration&quot;: &quot;A String&quot;, # Amount of time calculated to be in silence.
          &quot;silencePercentage&quot;: 3.14, # Percentage of the total conversation spent in silence.
        },
      },
      &quot;endTime&quot;: &quot;A String&quot;, # The time at which the analysis ended.
    },
    &quot;annotatorSelector&quot;: { # Selector of all available annotators and phrase matchers to run. # To select the annotators to run and the phrase matchers to use (if any). If not specified, all annotators will be run.
      &quot;issueModels&quot;: [ # The issue model to run. If not provided, the most recently deployed topic model will be used. The provided issue model will only be used for inference if the issue model is deployed and if run_issue_model_annotator is set to true. If more than one issue model is provided, only the first provided issue model will be used for inference.
        &quot;A String&quot;,
      ],
      &quot;phraseMatchers&quot;: [ # The list of phrase matchers to run. If not provided, all active phrase matchers will be used. If inactive phrase matchers are provided, they will not be used. Phrase matchers will be run only if run_phrase_matcher_annotator is set to true. Format: projects/{project}/locations/{location}/phraseMatchers/{phrase_matcher}
        &quot;A String&quot;,
      ],
      &quot;runEntityAnnotator&quot;: True or False, # Whether to run the entity annotator.
      &quot;runIntentAnnotator&quot;: True or False, # Whether to run the intent annotator.
      &quot;runInterruptionAnnotator&quot;: True or False, # Whether to run the interruption annotator.
      &quot;runIssueModelAnnotator&quot;: True or False, # Whether to run the issue model annotator. A model should have already been deployed for this to take effect.
      &quot;runPhraseMatcherAnnotator&quot;: True or False, # Whether to run the active phrase matcher annotator(s).
      &quot;runSentimentAnnotator&quot;: True or False, # Whether to run the sentiment annotator.
      &quot;runSilenceAnnotator&quot;: True or False, # Whether to run the silence annotator.
      &quot;runSummarizationAnnotator&quot;: True or False, # Whether to run the summarization annotator.
      &quot;summarizationConfig&quot;: { # Configuration for summarization. # Configuration for the summarization annotator.
        &quot;conversationProfile&quot;: &quot;A String&quot;, # Resource name of the Dialogflow conversation profile. Format: projects/{project}/locations/{location}/conversationProfiles/{conversation_profile}
        &quot;summarizationModel&quot;: &quot;A String&quot;, # Default summarization model to be used.
      },
    },
    &quot;createTime&quot;: &quot;A String&quot;, # Output only. The time at which the analysis was created, which occurs when the long-running operation completes.
    &quot;name&quot;: &quot;A String&quot;, # Immutable. The resource name of the analysis. Format: projects/{project}/locations/{location}/conversations/{conversation}/analyses/{analysis}
    &quot;requestTime&quot;: &quot;A String&quot;, # Output only. The time at which the analysis was requested.
  },
  &quot;latestSummary&quot;: { # Conversation summarization suggestion data. # Output only. Latest summary of the conversation.
    &quot;answerRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
    &quot;confidence&quot;: 3.14, # The confidence score of the summarization.
    &quot;conversationModel&quot;: &quot;A String&quot;, # The name of the model that generates this summary. Format: projects/{project}/locations/{location}/conversationModels/{conversation_model}
    &quot;metadata&quot;: { # A map that contains metadata about the summarization and the document from which it originates.
      &quot;a_key&quot;: &quot;A String&quot;,
    },
    &quot;text&quot;: &quot;A String&quot;, # The summarization content that is concatenated into one string.
    &quot;textSections&quot;: { # The summarization content that is divided into sections. The key is the section&#x27;s name and the value is the section&#x27;s content. There is no specific format for the key or value.
      &quot;a_key&quot;: &quot;A String&quot;,
    },
  },
  &quot;medium&quot;: &quot;A String&quot;, # Immutable. The conversation medium, if unspecified will default to PHONE_CALL.
  &quot;metadataJson&quot;: &quot;A String&quot;, # Input only. JSON Metadata encoded as a string. This field is primarily used by Insights integrations with various telphony systems and must be in one of Insights&#x27; supported formats.
  &quot;name&quot;: &quot;A String&quot;, # Immutable. The resource name of the conversation. Format: projects/{project}/locations/{location}/conversations/{conversation}
  &quot;obfuscatedUserId&quot;: &quot;A String&quot;, # Obfuscated user ID which the customer sent to us.
  &quot;qualityMetadata&quot;: { # Conversation metadata related to quality management. # Conversation metadata related to quality management.
    &quot;agentInfo&quot;: [ # Information about agents involved in the call.
      { # Information about an agent involved in the conversation.
        &quot;agentId&quot;: &quot;A String&quot;, # A user-specified string representing the agent.
        &quot;displayName&quot;: &quot;A String&quot;, # The agent&#x27;s name.
        &quot;dispositionCode&quot;: &quot;A String&quot;, # A user-provided string indicating the outcome of the agent&#x27;s segment of the call.
        &quot;team&quot;: &quot;A String&quot;, # A user-specified string representing the agent&#x27;s team.
      },
    ],
    &quot;customerSatisfactionRating&quot;: 42, # An arbitrary integer value indicating the customer&#x27;s satisfaction rating.
    &quot;menuPath&quot;: &quot;A String&quot;, # An arbitrary string value specifying the menu path the customer took.
    &quot;waitDuration&quot;: &quot;A String&quot;, # The amount of time the customer waited to connect with an agent.
  },
  &quot;runtimeAnnotations&quot;: [ # Output only. The annotations that were generated during the customer and agent interaction.
    { # An annotation that was generated during the customer and agent interaction.
      &quot;annotationId&quot;: &quot;A String&quot;, # The unique identifier of the annotation. Format: projects/{project}/locations/{location}/conversationDatasets/{dataset}/conversationDataItems/{data_item}/conversationAnnotations/{annotation}
      &quot;answerFeedback&quot;: { # The feedback that the customer has about a certain answer in the conversation. # The feedback that the customer has about the answer in `data`.
        &quot;clicked&quot;: True or False, # Indicates whether an answer or item was clicked by the human agent.
        &quot;correctnessLevel&quot;: &quot;A String&quot;, # The correctness level of an answer.
        &quot;displayed&quot;: True or False, # Indicates whether an answer or item was displayed to the human agent in the agent desktop UI.
      },
      &quot;articleSuggestion&quot;: { # Agent Assist Article Suggestion data. # Agent Assist Article Suggestion data.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this article is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the Article Suggestion and the document that it originates from.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
        &quot;source&quot;: &quot;A String&quot;, # The knowledge document that this answer was extracted from. Format: projects/{project}/knowledgeBases/{knowledge_base}/documents/{document}
        &quot;title&quot;: &quot;A String&quot;, # Article title.
        &quot;uri&quot;: &quot;A String&quot;, # Article URI.
      },
      &quot;conversationSummarizationSuggestion&quot;: { # Conversation summarization suggestion data. # Conversation summarization suggestion data.
        &quot;answerRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
        &quot;confidence&quot;: 3.14, # The confidence score of the summarization.
        &quot;conversationModel&quot;: &quot;A String&quot;, # The name of the model that generates this summary. Format: projects/{project}/locations/{location}/conversationModels/{conversation_model}
        &quot;metadata&quot;: { # A map that contains metadata about the summarization and the document from which it originates.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;text&quot;: &quot;A String&quot;, # The summarization content that is concatenated into one string.
        &quot;textSections&quot;: { # The summarization content that is divided into sections. The key is the section&#x27;s name and the value is the section&#x27;s content. There is no specific format for the key or value.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
      },
      &quot;createTime&quot;: &quot;A String&quot;, # The time at which this annotation was created.
      &quot;dialogflowInteraction&quot;: { # Dialogflow interaction data. # Dialogflow interaction data.
        &quot;confidence&quot;: 3.14, # The confidence of the match ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;dialogflowIntentId&quot;: &quot;A String&quot;, # The Dialogflow intent resource path. Format: projects/{project}/agent/{agent}/intents/{intent}
      },
      &quot;endBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation ends, inclusive.
        &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
        &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
      },
      &quot;faqAnswer&quot;: { # Agent Assist frequently-asked-question answer data. # Agent Assist FAQ answer data.
        &quot;answer&quot;: &quot;A String&quot;, # The piece of text from the `source` knowledge base document.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this answer is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the FAQ answer and the document that it originates from.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
        &quot;question&quot;: &quot;A String&quot;, # The corresponding FAQ question.
        &quot;source&quot;: &quot;A String&quot;, # The knowledge document that this answer was extracted from. Format: projects/{project}/knowledgeBases/{knowledge_base}/documents/{document}.
      },
      &quot;smartComposeSuggestion&quot;: { # Agent Assist Smart Compose suggestion data. # Agent Assist Smart Compose suggestion data.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this suggestion is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the Smart Compose suggestion and the document from which it originates.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
        &quot;suggestion&quot;: &quot;A String&quot;, # The content of the suggestion.
      },
      &quot;smartReply&quot;: { # Agent Assist Smart Reply data. # Agent Assist Smart Reply data.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this reply is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the Smart Reply and the document from which it originates.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
        &quot;reply&quot;: &quot;A String&quot;, # The content of the reply.
      },
      &quot;startBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation starts, inclusive.
        &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
        &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
      },
      &quot;userInput&quot;: { # Explicit input used for generating the answer # Explicit input used for generating the answer
        &quot;generatorName&quot;: &quot;A String&quot;, # The resource name of associated generator. Format: `projects//locations//generators/`
        &quot;query&quot;: &quot;A String&quot;, # Query text. Article Search uses this to store the input query used to generate the search results.
        &quot;querySource&quot;: &quot;A String&quot;, # Query source for the answer.
      },
    },
  ],
  &quot;startTime&quot;: &quot;A String&quot;, # The time at which the conversation started.
  &quot;transcript&quot;: { # A message representing the transcript of a conversation. # Output only. The conversation transcript.
    &quot;transcriptSegments&quot;: [ # A list of sequential transcript segments that comprise the conversation.
      { # A segment of a full transcript.
        &quot;channelTag&quot;: 42, # For conversations derived from multi-channel audio, this is the channel number corresponding to the audio from that channel. For audioChannelCount = N, its output values can range from &#x27;1&#x27; to &#x27;N&#x27;. A channel tag of 0 indicates that the audio is mono.
        &quot;confidence&quot;: 3.14, # A confidence estimate between 0.0 and 1.0 of the fidelity of this segment. A default value of 0.0 indicates that the value is unset.
        &quot;dialogflowSegmentMetadata&quot;: { # Metadata from Dialogflow relating to the current transcript segment. # CCAI metadata relating to the current transcript segment.
          &quot;smartReplyAllowlistCovered&quot;: True or False, # Whether the transcript segment was covered under the configured smart reply allowlist in Agent Assist.
        },
        &quot;languageCode&quot;: &quot;A String&quot;, # The language code of this segment as a [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag. Example: &quot;en-US&quot;.
        &quot;messageTime&quot;: &quot;A String&quot;, # The time that the message occurred, if provided.
        &quot;segmentParticipant&quot;: { # The call participant speaking for a given utterance. # The participant of this segment.
          &quot;dialogflowParticipant&quot;: &quot;A String&quot;, # Deprecated. Use `dialogflow_participant_name` instead. The name of the Dialogflow participant. Format: projects/{project}/locations/{location}/conversations/{conversation}/participants/{participant}
          &quot;dialogflowParticipantName&quot;: &quot;A String&quot;, # The name of the participant provided by Dialogflow. Format: projects/{project}/locations/{location}/conversations/{conversation}/participants/{participant}
          &quot;obfuscatedExternalUserId&quot;: &quot;A String&quot;, # Obfuscated user ID from Dialogflow.
          &quot;role&quot;: &quot;A String&quot;, # The role of the participant.
          &quot;userId&quot;: &quot;A String&quot;, # A user-specified ID representing the participant.
        },
        &quot;sentiment&quot;: { # The data for a sentiment annotation. # The sentiment for this transcript segment.
          &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
          &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
        },
        &quot;text&quot;: &quot;A String&quot;, # The text of this segment.
        &quot;words&quot;: [ # A list of the word-specific information for each word in the segment.
          { # Word-level info for words in a transcript.
            &quot;confidence&quot;: 3.14, # A confidence estimate between 0.0 and 1.0 of the fidelity of this word. A default value of 0.0 indicates that the value is unset.
            &quot;endOffset&quot;: &quot;A String&quot;, # Time offset of the end of this word relative to the beginning of the total conversation.
            &quot;startOffset&quot;: &quot;A String&quot;, # Time offset of the start of this word relative to the beginning of the total conversation.
            &quot;word&quot;: &quot;A String&quot;, # The word itself. Includes punctuation marks that surround the word.
          },
        ],
      },
    ],
  },
  &quot;ttl&quot;: &quot;A String&quot;, # Input only. The TTL for this resource. If specified, then this TTL will be used to calculate the expire time.
  &quot;turnCount&quot;: 42, # Output only. The number of turns in the conversation.
  &quot;updateTime&quot;: &quot;A String&quot;, # Output only. The most recent time at which the conversation was updated.
}</pre>
</div>

<div class="method">
    <code class="details" id="ingest">ingest(parent, body=None, x__xgafv=None)</code>
  <pre>Imports conversations and processes them according to the user&#x27;s configuration.

Args:
  parent: string, Required. The parent resource for new conversations. (required)
  body: object, The request body.
    The object takes the form of:

{ # The request to ingest conversations.
  &quot;conversationConfig&quot;: { # Configuration that applies to all conversations. # Configuration that applies to all conversations.
    &quot;agentChannel&quot;: 42, # Optional. Indicates which of the channels, 1 or 2, contains the agent. Note that this must be set for conversations to be properly displayed and analyzed.
    &quot;agentId&quot;: &quot;A String&quot;, # Optional. An opaque, user-specified string representing a human agent who handled all conversations in the import. Note that this will be overridden if per-conversation metadata is provided through the `metadata_bucket_uri`.
    &quot;customerChannel&quot;: 42, # Optional. Indicates which of the channels, 1 or 2, contains the agent. Note that this must be set for conversations to be properly displayed and analyzed.
  },
  &quot;gcsSource&quot;: { # Configuration for Cloud Storage bucket sources. # A cloud storage bucket source. Note that any previously ingested objects from the source will be skipped to avoid duplication.
    &quot;bucketObjectType&quot;: &quot;A String&quot;, # Optional. Specifies the type of the objects in `bucket_uri`.
    &quot;bucketUri&quot;: &quot;A String&quot;, # Required. The Cloud Storage bucket containing source objects.
    &quot;customMetadataKeys&quot;: [ # Optional. Custom keys to extract as conversation labels from metadata files in `metadata_bucket_uri`. Keys not included in this field will be ignored. Note that there is a limit of 20 labels per conversation.
      &quot;A String&quot;,
    ],
    &quot;metadataBucketUri&quot;: &quot;A String&quot;, # Optional. The Cloud Storage path to the conversation metadata. Note that: [1] Metadata files are expected to be in JSON format. [2] Metadata and source files (transcripts or audio) must be in separate buckets. [3] A source file and its corresponding metadata file must share the same name to be properly ingested, E.g. `gs://bucket/audio/conversation1.mp3` and `gs://bucket/metadata/conversation1.json`.
  },
  &quot;parent&quot;: &quot;A String&quot;, # Required. The parent resource for new conversations.
  &quot;redactionConfig&quot;: { # DLP resources used for redaction while ingesting conversations. DLP settings are applied to conversations ingested from the `UploadConversation` and `IngestConversations` endpoints, including conversation coming from CCAI Platform. They are not applied to conversations ingested from the `CreateConversation` endpoint or the Dialogflow / Agent Assist runtime integrations. When using Dialogflow / Agent Assist runtime integrations, redaction should be performed in Dialogflow / Agent Assist. # Optional. DLP settings for transcript redaction. Optional, will default to the config specified in Settings.
    &quot;deidentifyTemplate&quot;: &quot;A String&quot;, # The fully-qualified DLP deidentify template resource name. Format: `projects/{project}/deidentifyTemplates/{template}`
    &quot;inspectTemplate&quot;: &quot;A String&quot;, # The fully-qualified DLP inspect template resource name. Format: `projects/{project}/locations/{location}/inspectTemplates/{template}`
  },
  &quot;sampleSize&quot;: 42, # Optional. If set, this fields indicates the number of objects to ingest from the Cloud Storage bucket. If empty, the entire bucket will be ingested. Unless they are first deleted, conversations produced through sampling won&#x27;t be ingested by subsequent ingest requests.
  &quot;speechConfig&quot;: { # Speech-to-Text configuration. Speech-to-Text settings are applied to conversations ingested from the `UploadConversation` and `IngestConversations` endpoints, including conversation coming from CCAI Platform. They are not applied to conversations ingested from the `CreateConversation` endpoint. # Optional. Default Speech-to-Text configuration. Optional, will default to the config specified in Settings.
    &quot;speechRecognizer&quot;: &quot;A String&quot;, # The fully-qualified Speech Recognizer resource name. Format: `projects/{project_id}/locations/{location}/recognizer/{recognizer}`
  },
  &quot;transcriptObjectConfig&quot;: { # Configuration for processing transcript objects. # Configuration for when `source` contains conversation transcripts.
    &quot;medium&quot;: &quot;A String&quot;, # Required. The medium transcript objects represent.
  },
}

  x__xgafv: string, V1 error format.
    Allowed values
      1 - v1 error format
      2 - v2 error format

Returns:
  An object of the form:

    { # This resource represents a long-running operation that is the result of a network API call.
  &quot;done&quot;: True or False, # If the value is `false`, it means the operation is still in progress. If `true`, the operation is completed, and either `error` or `response` is available.
  &quot;error&quot;: { # The `Status` type defines a logical error model that is suitable for different programming environments, including REST APIs and RPC APIs. It is used by [gRPC](https://github.com/grpc). Each `Status` message contains three pieces of data: error code, error message, and error details. You can find out more about this error model and how to work with it in the [API Design Guide](https://cloud.google.com/apis/design/errors). # The error result of the operation in case of failure or cancellation.
    &quot;code&quot;: 42, # The status code, which should be an enum value of google.rpc.Code.
    &quot;details&quot;: [ # A list of messages that carry the error details. There is a common set of message types for APIs to use.
      {
        &quot;a_key&quot;: &quot;&quot;, # Properties of the object. Contains field @type with type URL.
      },
    ],
    &quot;message&quot;: &quot;A String&quot;, # A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client.
  },
  &quot;metadata&quot;: { # Service-specific metadata associated with the operation. It typically contains progress information and common metadata such as create time. Some services might not provide such metadata. Any method that returns a long-running operation should document the metadata type, if any.
    &quot;a_key&quot;: &quot;&quot;, # Properties of the object. Contains field @type with type URL.
  },
  &quot;name&quot;: &quot;A String&quot;, # The server-assigned name, which is only unique within the same service that originally returns it. If you use the default HTTP mapping, the `name` should be a resource name ending with `operations/{unique_id}`.
  &quot;response&quot;: { # The normal, successful response of the operation. If the original method returns no data on success, such as `Delete`, the response is `google.protobuf.Empty`. If the original method is standard `Get`/`Create`/`Update`, the response should be the resource. For other methods, the response should have the type `XxxResponse`, where `Xxx` is the original method name. For example, if the original method name is `TakeSnapshot()`, the inferred response type is `TakeSnapshotResponse`.
    &quot;a_key&quot;: &quot;&quot;, # Properties of the object. Contains field @type with type URL.
  },
}</pre>
</div>

<div class="method">
    <code class="details" id="list">list(parent, filter=None, orderBy=None, pageSize=None, pageToken=None, view=None, x__xgafv=None)</code>
  <pre>Lists conversations.

Args:
  parent: string, Required. The parent resource of the conversation. (required)
  filter: string, A filter to reduce results to a specific subset. Useful for querying conversations with specific properties.
  orderBy: string, Optional. The attribute by which to order conversations in the response. If empty, conversations will be ordered by descending creation time. Supported values are one of the following: * create_time * customer_satisfaction_rating * duration * latest_analysis * start_time * turn_count The default sort order is ascending. To specify order, append `asc` or `desc` (`create_time desc`). For more details, see [Google AIPs Ordering](https://google.aip.dev/132#ordering).
  pageSize: integer, The maximum number of conversations to return in the response. A valid page size ranges from 0 to 100,000 inclusive. If the page size is zero or unspecified, a default page size of 100 will be chosen. Note that a call might return fewer results than the requested page size.
  pageToken: string, The value returned by the last `ListConversationsResponse`. This value indicates that this is a continuation of a prior `ListConversations` call and that the system should return the next page of data.
  view: string, The level of details of the conversation. Default is `BASIC`.
    Allowed values
      CONVERSATION_VIEW_UNSPECIFIED - The conversation view is not specified. * Defaults to `FULL` in `GetConversationRequest`. * Defaults to `BASIC` in `ListConversationsRequest`.
      FULL - Populates all fields in the conversation.
      BASIC - Populates all fields in the conversation except the transcript.
  x__xgafv: string, V1 error format.
    Allowed values
      1 - v1 error format
      2 - v2 error format

Returns:
  An object of the form:

    { # The response of listing conversations.
  &quot;conversations&quot;: [ # The conversations that match the request.
    { # The conversation resource.
      &quot;agentId&quot;: &quot;A String&quot;, # An opaque, user-specified string representing the human agent who handled the conversation.
      &quot;callMetadata&quot;: { # Call-specific metadata. # Call-specific metadata.
        &quot;agentChannel&quot;: 42, # The audio channel that contains the agent.
        &quot;customerChannel&quot;: 42, # The audio channel that contains the customer.
      },
      &quot;createTime&quot;: &quot;A String&quot;, # Output only. The time at which the conversation was created.
      &quot;dataSource&quot;: { # The conversation source, which is a combination of transcript and audio. # The source of the audio and transcription for the conversation.
        &quot;dialogflowSource&quot;: { # A Dialogflow source of conversation data. # The source when the conversation comes from Dialogflow.
          &quot;audioUri&quot;: &quot;A String&quot;, # Cloud Storage URI that points to a file that contains the conversation audio.
          &quot;dialogflowConversation&quot;: &quot;A String&quot;, # Output only. The name of the Dialogflow conversation that this conversation resource is derived from. Format: projects/{project}/locations/{location}/conversations/{conversation}
        },
        &quot;gcsSource&quot;: { # A Cloud Storage source of conversation data. # A Cloud Storage location specification for the audio and transcript.
          &quot;audioUri&quot;: &quot;A String&quot;, # Cloud Storage URI that points to a file that contains the conversation audio.
          &quot;transcriptUri&quot;: &quot;A String&quot;, # Immutable. Cloud Storage URI that points to a file that contains the conversation transcript.
        },
      },
      &quot;dialogflowIntents&quot;: { # Output only. All the matched Dialogflow intents in the call. The key corresponds to a Dialogflow intent, format: projects/{project}/agent/{agent}/intents/{intent}
        &quot;a_key&quot;: { # The data for a Dialogflow intent. Represents a detected intent in the conversation, e.g. MAKES_PROMISE.
          &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the intent.
        },
      },
      &quot;duration&quot;: &quot;A String&quot;, # Output only. The duration of the conversation.
      &quot;expireTime&quot;: &quot;A String&quot;, # The time at which this conversation should expire. After this time, the conversation data and any associated analyses will be deleted.
      &quot;labels&quot;: { # A map for the user to specify any custom fields. A maximum of 20 labels per conversation is allowed, with a maximum of 256 characters per entry.
        &quot;a_key&quot;: &quot;A String&quot;,
      },
      &quot;languageCode&quot;: &quot;A String&quot;, # A user-specified language code for the conversation.
      &quot;latestAnalysis&quot;: { # The analysis resource. # Output only. The conversation&#x27;s latest analysis, if one exists.
        &quot;analysisResult&quot;: { # The result of an analysis. # Output only. The result of the analysis, which is populated when the analysis finishes.
          &quot;callAnalysisMetadata&quot;: { # Call-specific metadata created during analysis. # Call-specific metadata created by the analysis.
            &quot;annotations&quot;: [ # A list of call annotations that apply to this call.
              { # A piece of metadata that applies to a window of a call.
                &quot;annotationEndBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation ends, inclusive.
                  &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
                  &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
                },
                &quot;annotationStartBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation starts, inclusive.
                  &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
                  &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
                },
                &quot;channelTag&quot;: 42, # The channel of the audio where the annotation occurs. For single-channel audio, this field is not populated.
                &quot;entityMentionData&quot;: { # The data for an entity mention annotation. This represents a mention of an `Entity` in the conversation. # Data specifying an entity mention.
                  &quot;entityUniqueId&quot;: &quot;A String&quot;, # The key of this entity in conversation entities. Can be used to retrieve the exact `Entity` this mention is attached to.
                  &quot;sentiment&quot;: { # The data for a sentiment annotation. # Sentiment expressed for this mention of the entity.
                    &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
                    &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
                  },
                  &quot;type&quot;: &quot;A String&quot;, # The type of the entity mention.
                },
                &quot;holdData&quot;: { # The data for a hold annotation. # Data specifying a hold.
                },
                &quot;intentMatchData&quot;: { # The data for an intent match. Represents an intent match for a text segment in the conversation. A text segment can be part of a sentence, a complete sentence, or an utterance with multiple sentences. # Data specifying an intent match.
                  &quot;intentUniqueId&quot;: &quot;A String&quot;, # The id of the matched intent. Can be used to retrieve the corresponding intent information.
                },
                &quot;interruptionData&quot;: { # The data for an interruption annotation. # Data specifying an interruption.
                },
                &quot;issueMatchData&quot;: { # The data for an issue match annotation. # Data specifying an issue match.
                  &quot;issueAssignment&quot;: { # Information about the issue. # Information about the issue&#x27;s assignment.
                    &quot;displayName&quot;: &quot;A String&quot;, # Immutable. Display name of the assigned issue. This field is set at time of analyis and immutable since then.
                    &quot;issue&quot;: &quot;A String&quot;, # Resource name of the assigned issue.
                    &quot;score&quot;: 3.14, # Score indicating the likelihood of the issue assignment. currently bounded on [0,1].
                  },
                },
                &quot;phraseMatchData&quot;: { # The data for a matched phrase matcher. Represents information identifying a phrase matcher for a given match. # Data specifying a phrase match.
                  &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the phrase matcher.
                  &quot;phraseMatcher&quot;: &quot;A String&quot;, # The unique identifier (the resource name) of the phrase matcher.
                },
                &quot;sentimentData&quot;: { # The data for a sentiment annotation. # Data specifying sentiment.
                  &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
                  &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
                },
                &quot;silenceData&quot;: { # The data for a silence annotation. # Data specifying silence.
                },
              },
            ],
            &quot;entities&quot;: { # All the entities in the call.
              &quot;a_key&quot;: { # The data for an entity annotation. Represents a phrase in the conversation that is a known entity, such as a person, an organization, or location.
                &quot;displayName&quot;: &quot;A String&quot;, # The representative name for the entity.
                &quot;metadata&quot;: { # Metadata associated with the entity. For most entity types, the metadata is a Wikipedia URL (`wikipedia_url`) and Knowledge Graph MID (`mid`), if they are available. For the metadata associated with other entity types, see the Type table below.
                  &quot;a_key&quot;: &quot;A String&quot;,
                },
                &quot;salience&quot;: 3.14, # The salience score associated with the entity in the [0, 1.0] range. The salience score for an entity provides information about the importance or centrality of that entity to the entire document text. Scores closer to 0 are less salient, while scores closer to 1.0 are highly salient.
                &quot;sentiment&quot;: { # The data for a sentiment annotation. # The aggregate sentiment expressed for this entity in the conversation.
                  &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
                  &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
                },
                &quot;type&quot;: &quot;A String&quot;, # The entity type.
              },
            },
            &quot;intents&quot;: { # All the matched intents in the call.
              &quot;a_key&quot;: { # The data for an intent. Represents a detected intent in the conversation, for example MAKES_PROMISE.
                &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the intent.
                &quot;id&quot;: &quot;A String&quot;, # The unique identifier of the intent.
              },
            },
            &quot;issueModelResult&quot;: { # Issue Modeling result on a conversation. # Overall conversation-level issue modeling result.
              &quot;issueModel&quot;: &quot;A String&quot;, # Issue model that generates the result. Format: projects/{project}/locations/{location}/issueModels/{issue_model}
              &quot;issues&quot;: [ # All the matched issues.
                { # Information about the issue.
                  &quot;displayName&quot;: &quot;A String&quot;, # Immutable. Display name of the assigned issue. This field is set at time of analyis and immutable since then.
                  &quot;issue&quot;: &quot;A String&quot;, # Resource name of the assigned issue.
                  &quot;score&quot;: 3.14, # Score indicating the likelihood of the issue assignment. currently bounded on [0,1].
                },
              ],
            },
            &quot;phraseMatchers&quot;: { # All the matched phrase matchers in the call.
              &quot;a_key&quot;: { # The data for a matched phrase matcher. Represents information identifying a phrase matcher for a given match.
                &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the phrase matcher.
                &quot;phraseMatcher&quot;: &quot;A String&quot;, # The unique identifier (the resource name) of the phrase matcher.
              },
            },
            &quot;sentiments&quot;: [ # Overall conversation-level sentiment for each channel of the call.
              { # One channel of conversation-level sentiment data.
                &quot;channelTag&quot;: 42, # The channel of the audio that the data applies to.
                &quot;sentimentData&quot;: { # The data for a sentiment annotation. # Data specifying sentiment.
                  &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
                  &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
                },
              },
            ],
            &quot;silence&quot;: { # Conversation-level silence data. # Overall conversation-level silence during the call.
              &quot;silenceDuration&quot;: &quot;A String&quot;, # Amount of time calculated to be in silence.
              &quot;silencePercentage&quot;: 3.14, # Percentage of the total conversation spent in silence.
            },
          },
          &quot;endTime&quot;: &quot;A String&quot;, # The time at which the analysis ended.
        },
        &quot;annotatorSelector&quot;: { # Selector of all available annotators and phrase matchers to run. # To select the annotators to run and the phrase matchers to use (if any). If not specified, all annotators will be run.
          &quot;issueModels&quot;: [ # The issue model to run. If not provided, the most recently deployed topic model will be used. The provided issue model will only be used for inference if the issue model is deployed and if run_issue_model_annotator is set to true. If more than one issue model is provided, only the first provided issue model will be used for inference.
            &quot;A String&quot;,
          ],
          &quot;phraseMatchers&quot;: [ # The list of phrase matchers to run. If not provided, all active phrase matchers will be used. If inactive phrase matchers are provided, they will not be used. Phrase matchers will be run only if run_phrase_matcher_annotator is set to true. Format: projects/{project}/locations/{location}/phraseMatchers/{phrase_matcher}
            &quot;A String&quot;,
          ],
          &quot;runEntityAnnotator&quot;: True or False, # Whether to run the entity annotator.
          &quot;runIntentAnnotator&quot;: True or False, # Whether to run the intent annotator.
          &quot;runInterruptionAnnotator&quot;: True or False, # Whether to run the interruption annotator.
          &quot;runIssueModelAnnotator&quot;: True or False, # Whether to run the issue model annotator. A model should have already been deployed for this to take effect.
          &quot;runPhraseMatcherAnnotator&quot;: True or False, # Whether to run the active phrase matcher annotator(s).
          &quot;runSentimentAnnotator&quot;: True or False, # Whether to run the sentiment annotator.
          &quot;runSilenceAnnotator&quot;: True or False, # Whether to run the silence annotator.
          &quot;runSummarizationAnnotator&quot;: True or False, # Whether to run the summarization annotator.
          &quot;summarizationConfig&quot;: { # Configuration for summarization. # Configuration for the summarization annotator.
            &quot;conversationProfile&quot;: &quot;A String&quot;, # Resource name of the Dialogflow conversation profile. Format: projects/{project}/locations/{location}/conversationProfiles/{conversation_profile}
            &quot;summarizationModel&quot;: &quot;A String&quot;, # Default summarization model to be used.
          },
        },
        &quot;createTime&quot;: &quot;A String&quot;, # Output only. The time at which the analysis was created, which occurs when the long-running operation completes.
        &quot;name&quot;: &quot;A String&quot;, # Immutable. The resource name of the analysis. Format: projects/{project}/locations/{location}/conversations/{conversation}/analyses/{analysis}
        &quot;requestTime&quot;: &quot;A String&quot;, # Output only. The time at which the analysis was requested.
      },
      &quot;latestSummary&quot;: { # Conversation summarization suggestion data. # Output only. Latest summary of the conversation.
        &quot;answerRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
        &quot;confidence&quot;: 3.14, # The confidence score of the summarization.
        &quot;conversationModel&quot;: &quot;A String&quot;, # The name of the model that generates this summary. Format: projects/{project}/locations/{location}/conversationModels/{conversation_model}
        &quot;metadata&quot;: { # A map that contains metadata about the summarization and the document from which it originates.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;text&quot;: &quot;A String&quot;, # The summarization content that is concatenated into one string.
        &quot;textSections&quot;: { # The summarization content that is divided into sections. The key is the section&#x27;s name and the value is the section&#x27;s content. There is no specific format for the key or value.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
      },
      &quot;medium&quot;: &quot;A String&quot;, # Immutable. The conversation medium, if unspecified will default to PHONE_CALL.
      &quot;metadataJson&quot;: &quot;A String&quot;, # Input only. JSON Metadata encoded as a string. This field is primarily used by Insights integrations with various telphony systems and must be in one of Insights&#x27; supported formats.
      &quot;name&quot;: &quot;A String&quot;, # Immutable. The resource name of the conversation. Format: projects/{project}/locations/{location}/conversations/{conversation}
      &quot;obfuscatedUserId&quot;: &quot;A String&quot;, # Obfuscated user ID which the customer sent to us.
      &quot;qualityMetadata&quot;: { # Conversation metadata related to quality management. # Conversation metadata related to quality management.
        &quot;agentInfo&quot;: [ # Information about agents involved in the call.
          { # Information about an agent involved in the conversation.
            &quot;agentId&quot;: &quot;A String&quot;, # A user-specified string representing the agent.
            &quot;displayName&quot;: &quot;A String&quot;, # The agent&#x27;s name.
            &quot;dispositionCode&quot;: &quot;A String&quot;, # A user-provided string indicating the outcome of the agent&#x27;s segment of the call.
            &quot;team&quot;: &quot;A String&quot;, # A user-specified string representing the agent&#x27;s team.
          },
        ],
        &quot;customerSatisfactionRating&quot;: 42, # An arbitrary integer value indicating the customer&#x27;s satisfaction rating.
        &quot;menuPath&quot;: &quot;A String&quot;, # An arbitrary string value specifying the menu path the customer took.
        &quot;waitDuration&quot;: &quot;A String&quot;, # The amount of time the customer waited to connect with an agent.
      },
      &quot;runtimeAnnotations&quot;: [ # Output only. The annotations that were generated during the customer and agent interaction.
        { # An annotation that was generated during the customer and agent interaction.
          &quot;annotationId&quot;: &quot;A String&quot;, # The unique identifier of the annotation. Format: projects/{project}/locations/{location}/conversationDatasets/{dataset}/conversationDataItems/{data_item}/conversationAnnotations/{annotation}
          &quot;answerFeedback&quot;: { # The feedback that the customer has about a certain answer in the conversation. # The feedback that the customer has about the answer in `data`.
            &quot;clicked&quot;: True or False, # Indicates whether an answer or item was clicked by the human agent.
            &quot;correctnessLevel&quot;: &quot;A String&quot;, # The correctness level of an answer.
            &quot;displayed&quot;: True or False, # Indicates whether an answer or item was displayed to the human agent in the agent desktop UI.
          },
          &quot;articleSuggestion&quot;: { # Agent Assist Article Suggestion data. # Agent Assist Article Suggestion data.
            &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this article is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
            &quot;metadata&quot;: { # Map that contains metadata about the Article Suggestion and the document that it originates from.
              &quot;a_key&quot;: &quot;A String&quot;,
            },
            &quot;queryRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
            &quot;source&quot;: &quot;A String&quot;, # The knowledge document that this answer was extracted from. Format: projects/{project}/knowledgeBases/{knowledge_base}/documents/{document}
            &quot;title&quot;: &quot;A String&quot;, # Article title.
            &quot;uri&quot;: &quot;A String&quot;, # Article URI.
          },
          &quot;conversationSummarizationSuggestion&quot;: { # Conversation summarization suggestion data. # Conversation summarization suggestion data.
            &quot;answerRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
            &quot;confidence&quot;: 3.14, # The confidence score of the summarization.
            &quot;conversationModel&quot;: &quot;A String&quot;, # The name of the model that generates this summary. Format: projects/{project}/locations/{location}/conversationModels/{conversation_model}
            &quot;metadata&quot;: { # A map that contains metadata about the summarization and the document from which it originates.
              &quot;a_key&quot;: &quot;A String&quot;,
            },
            &quot;text&quot;: &quot;A String&quot;, # The summarization content that is concatenated into one string.
            &quot;textSections&quot;: { # The summarization content that is divided into sections. The key is the section&#x27;s name and the value is the section&#x27;s content. There is no specific format for the key or value.
              &quot;a_key&quot;: &quot;A String&quot;,
            },
          },
          &quot;createTime&quot;: &quot;A String&quot;, # The time at which this annotation was created.
          &quot;dialogflowInteraction&quot;: { # Dialogflow interaction data. # Dialogflow interaction data.
            &quot;confidence&quot;: 3.14, # The confidence of the match ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
            &quot;dialogflowIntentId&quot;: &quot;A String&quot;, # The Dialogflow intent resource path. Format: projects/{project}/agent/{agent}/intents/{intent}
          },
          &quot;endBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation ends, inclusive.
            &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
            &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
          },
          &quot;faqAnswer&quot;: { # Agent Assist frequently-asked-question answer data. # Agent Assist FAQ answer data.
            &quot;answer&quot;: &quot;A String&quot;, # The piece of text from the `source` knowledge base document.
            &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this answer is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
            &quot;metadata&quot;: { # Map that contains metadata about the FAQ answer and the document that it originates from.
              &quot;a_key&quot;: &quot;A String&quot;,
            },
            &quot;queryRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
            &quot;question&quot;: &quot;A String&quot;, # The corresponding FAQ question.
            &quot;source&quot;: &quot;A String&quot;, # The knowledge document that this answer was extracted from. Format: projects/{project}/knowledgeBases/{knowledge_base}/documents/{document}.
          },
          &quot;smartComposeSuggestion&quot;: { # Agent Assist Smart Compose suggestion data. # Agent Assist Smart Compose suggestion data.
            &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this suggestion is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
            &quot;metadata&quot;: { # Map that contains metadata about the Smart Compose suggestion and the document from which it originates.
              &quot;a_key&quot;: &quot;A String&quot;,
            },
            &quot;queryRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
            &quot;suggestion&quot;: &quot;A String&quot;, # The content of the suggestion.
          },
          &quot;smartReply&quot;: { # Agent Assist Smart Reply data. # Agent Assist Smart Reply data.
            &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this reply is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
            &quot;metadata&quot;: { # Map that contains metadata about the Smart Reply and the document from which it originates.
              &quot;a_key&quot;: &quot;A String&quot;,
            },
            &quot;queryRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
            &quot;reply&quot;: &quot;A String&quot;, # The content of the reply.
          },
          &quot;startBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation starts, inclusive.
            &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
            &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
          },
          &quot;userInput&quot;: { # Explicit input used for generating the answer # Explicit input used for generating the answer
            &quot;generatorName&quot;: &quot;A String&quot;, # The resource name of associated generator. Format: `projects//locations//generators/`
            &quot;query&quot;: &quot;A String&quot;, # Query text. Article Search uses this to store the input query used to generate the search results.
            &quot;querySource&quot;: &quot;A String&quot;, # Query source for the answer.
          },
        },
      ],
      &quot;startTime&quot;: &quot;A String&quot;, # The time at which the conversation started.
      &quot;transcript&quot;: { # A message representing the transcript of a conversation. # Output only. The conversation transcript.
        &quot;transcriptSegments&quot;: [ # A list of sequential transcript segments that comprise the conversation.
          { # A segment of a full transcript.
            &quot;channelTag&quot;: 42, # For conversations derived from multi-channel audio, this is the channel number corresponding to the audio from that channel. For audioChannelCount = N, its output values can range from &#x27;1&#x27; to &#x27;N&#x27;. A channel tag of 0 indicates that the audio is mono.
            &quot;confidence&quot;: 3.14, # A confidence estimate between 0.0 and 1.0 of the fidelity of this segment. A default value of 0.0 indicates that the value is unset.
            &quot;dialogflowSegmentMetadata&quot;: { # Metadata from Dialogflow relating to the current transcript segment. # CCAI metadata relating to the current transcript segment.
              &quot;smartReplyAllowlistCovered&quot;: True or False, # Whether the transcript segment was covered under the configured smart reply allowlist in Agent Assist.
            },
            &quot;languageCode&quot;: &quot;A String&quot;, # The language code of this segment as a [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag. Example: &quot;en-US&quot;.
            &quot;messageTime&quot;: &quot;A String&quot;, # The time that the message occurred, if provided.
            &quot;segmentParticipant&quot;: { # The call participant speaking for a given utterance. # The participant of this segment.
              &quot;dialogflowParticipant&quot;: &quot;A String&quot;, # Deprecated. Use `dialogflow_participant_name` instead. The name of the Dialogflow participant. Format: projects/{project}/locations/{location}/conversations/{conversation}/participants/{participant}
              &quot;dialogflowParticipantName&quot;: &quot;A String&quot;, # The name of the participant provided by Dialogflow. Format: projects/{project}/locations/{location}/conversations/{conversation}/participants/{participant}
              &quot;obfuscatedExternalUserId&quot;: &quot;A String&quot;, # Obfuscated user ID from Dialogflow.
              &quot;role&quot;: &quot;A String&quot;, # The role of the participant.
              &quot;userId&quot;: &quot;A String&quot;, # A user-specified ID representing the participant.
            },
            &quot;sentiment&quot;: { # The data for a sentiment annotation. # The sentiment for this transcript segment.
              &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
              &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
            },
            &quot;text&quot;: &quot;A String&quot;, # The text of this segment.
            &quot;words&quot;: [ # A list of the word-specific information for each word in the segment.
              { # Word-level info for words in a transcript.
                &quot;confidence&quot;: 3.14, # A confidence estimate between 0.0 and 1.0 of the fidelity of this word. A default value of 0.0 indicates that the value is unset.
                &quot;endOffset&quot;: &quot;A String&quot;, # Time offset of the end of this word relative to the beginning of the total conversation.
                &quot;startOffset&quot;: &quot;A String&quot;, # Time offset of the start of this word relative to the beginning of the total conversation.
                &quot;word&quot;: &quot;A String&quot;, # The word itself. Includes punctuation marks that surround the word.
              },
            ],
          },
        ],
      },
      &quot;ttl&quot;: &quot;A String&quot;, # Input only. The TTL for this resource. If specified, then this TTL will be used to calculate the expire time.
      &quot;turnCount&quot;: 42, # Output only. The number of turns in the conversation.
      &quot;updateTime&quot;: &quot;A String&quot;, # Output only. The most recent time at which the conversation was updated.
    },
  ],
  &quot;nextPageToken&quot;: &quot;A String&quot;, # A token which can be sent as `page_token` to retrieve the next page. If this field is set, it means there is another page available. If it is not set, it means no other pages are available.
}</pre>
</div>

<div class="method">
    <code class="details" id="list_next">list_next()</code>
  <pre>Retrieves the next page of results.

        Args:
          previous_request: The request for the previous page. (required)
          previous_response: The response from the request for the previous page. (required)

        Returns:
          A request object that you can call &#x27;execute()&#x27; on to request the next
          page. Returns None if there are no more items in the collection.
        </pre>
</div>

<div class="method">
    <code class="details" id="patch">patch(name, body=None, updateMask=None, x__xgafv=None)</code>
  <pre>Updates a conversation.

Args:
  name: string, Immutable. The resource name of the conversation. Format: projects/{project}/locations/{location}/conversations/{conversation} (required)
  body: object, The request body.
    The object takes the form of:

{ # The conversation resource.
  &quot;agentId&quot;: &quot;A String&quot;, # An opaque, user-specified string representing the human agent who handled the conversation.
  &quot;callMetadata&quot;: { # Call-specific metadata. # Call-specific metadata.
    &quot;agentChannel&quot;: 42, # The audio channel that contains the agent.
    &quot;customerChannel&quot;: 42, # The audio channel that contains the customer.
  },
  &quot;createTime&quot;: &quot;A String&quot;, # Output only. The time at which the conversation was created.
  &quot;dataSource&quot;: { # The conversation source, which is a combination of transcript and audio. # The source of the audio and transcription for the conversation.
    &quot;dialogflowSource&quot;: { # A Dialogflow source of conversation data. # The source when the conversation comes from Dialogflow.
      &quot;audioUri&quot;: &quot;A String&quot;, # Cloud Storage URI that points to a file that contains the conversation audio.
      &quot;dialogflowConversation&quot;: &quot;A String&quot;, # Output only. The name of the Dialogflow conversation that this conversation resource is derived from. Format: projects/{project}/locations/{location}/conversations/{conversation}
    },
    &quot;gcsSource&quot;: { # A Cloud Storage source of conversation data. # A Cloud Storage location specification for the audio and transcript.
      &quot;audioUri&quot;: &quot;A String&quot;, # Cloud Storage URI that points to a file that contains the conversation audio.
      &quot;transcriptUri&quot;: &quot;A String&quot;, # Immutable. Cloud Storage URI that points to a file that contains the conversation transcript.
    },
  },
  &quot;dialogflowIntents&quot;: { # Output only. All the matched Dialogflow intents in the call. The key corresponds to a Dialogflow intent, format: projects/{project}/agent/{agent}/intents/{intent}
    &quot;a_key&quot;: { # The data for a Dialogflow intent. Represents a detected intent in the conversation, e.g. MAKES_PROMISE.
      &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the intent.
    },
  },
  &quot;duration&quot;: &quot;A String&quot;, # Output only. The duration of the conversation.
  &quot;expireTime&quot;: &quot;A String&quot;, # The time at which this conversation should expire. After this time, the conversation data and any associated analyses will be deleted.
  &quot;labels&quot;: { # A map for the user to specify any custom fields. A maximum of 20 labels per conversation is allowed, with a maximum of 256 characters per entry.
    &quot;a_key&quot;: &quot;A String&quot;,
  },
  &quot;languageCode&quot;: &quot;A String&quot;, # A user-specified language code for the conversation.
  &quot;latestAnalysis&quot;: { # The analysis resource. # Output only. The conversation&#x27;s latest analysis, if one exists.
    &quot;analysisResult&quot;: { # The result of an analysis. # Output only. The result of the analysis, which is populated when the analysis finishes.
      &quot;callAnalysisMetadata&quot;: { # Call-specific metadata created during analysis. # Call-specific metadata created by the analysis.
        &quot;annotations&quot;: [ # A list of call annotations that apply to this call.
          { # A piece of metadata that applies to a window of a call.
            &quot;annotationEndBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation ends, inclusive.
              &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
              &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
            },
            &quot;annotationStartBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation starts, inclusive.
              &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
              &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
            },
            &quot;channelTag&quot;: 42, # The channel of the audio where the annotation occurs. For single-channel audio, this field is not populated.
            &quot;entityMentionData&quot;: { # The data for an entity mention annotation. This represents a mention of an `Entity` in the conversation. # Data specifying an entity mention.
              &quot;entityUniqueId&quot;: &quot;A String&quot;, # The key of this entity in conversation entities. Can be used to retrieve the exact `Entity` this mention is attached to.
              &quot;sentiment&quot;: { # The data for a sentiment annotation. # Sentiment expressed for this mention of the entity.
                &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
                &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
              },
              &quot;type&quot;: &quot;A String&quot;, # The type of the entity mention.
            },
            &quot;holdData&quot;: { # The data for a hold annotation. # Data specifying a hold.
            },
            &quot;intentMatchData&quot;: { # The data for an intent match. Represents an intent match for a text segment in the conversation. A text segment can be part of a sentence, a complete sentence, or an utterance with multiple sentences. # Data specifying an intent match.
              &quot;intentUniqueId&quot;: &quot;A String&quot;, # The id of the matched intent. Can be used to retrieve the corresponding intent information.
            },
            &quot;interruptionData&quot;: { # The data for an interruption annotation. # Data specifying an interruption.
            },
            &quot;issueMatchData&quot;: { # The data for an issue match annotation. # Data specifying an issue match.
              &quot;issueAssignment&quot;: { # Information about the issue. # Information about the issue&#x27;s assignment.
                &quot;displayName&quot;: &quot;A String&quot;, # Immutable. Display name of the assigned issue. This field is set at time of analyis and immutable since then.
                &quot;issue&quot;: &quot;A String&quot;, # Resource name of the assigned issue.
                &quot;score&quot;: 3.14, # Score indicating the likelihood of the issue assignment. currently bounded on [0,1].
              },
            },
            &quot;phraseMatchData&quot;: { # The data for a matched phrase matcher. Represents information identifying a phrase matcher for a given match. # Data specifying a phrase match.
              &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the phrase matcher.
              &quot;phraseMatcher&quot;: &quot;A String&quot;, # The unique identifier (the resource name) of the phrase matcher.
            },
            &quot;sentimentData&quot;: { # The data for a sentiment annotation. # Data specifying sentiment.
              &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
              &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
            },
            &quot;silenceData&quot;: { # The data for a silence annotation. # Data specifying silence.
            },
          },
        ],
        &quot;entities&quot;: { # All the entities in the call.
          &quot;a_key&quot;: { # The data for an entity annotation. Represents a phrase in the conversation that is a known entity, such as a person, an organization, or location.
            &quot;displayName&quot;: &quot;A String&quot;, # The representative name for the entity.
            &quot;metadata&quot;: { # Metadata associated with the entity. For most entity types, the metadata is a Wikipedia URL (`wikipedia_url`) and Knowledge Graph MID (`mid`), if they are available. For the metadata associated with other entity types, see the Type table below.
              &quot;a_key&quot;: &quot;A String&quot;,
            },
            &quot;salience&quot;: 3.14, # The salience score associated with the entity in the [0, 1.0] range. The salience score for an entity provides information about the importance or centrality of that entity to the entire document text. Scores closer to 0 are less salient, while scores closer to 1.0 are highly salient.
            &quot;sentiment&quot;: { # The data for a sentiment annotation. # The aggregate sentiment expressed for this entity in the conversation.
              &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
              &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
            },
            &quot;type&quot;: &quot;A String&quot;, # The entity type.
          },
        },
        &quot;intents&quot;: { # All the matched intents in the call.
          &quot;a_key&quot;: { # The data for an intent. Represents a detected intent in the conversation, for example MAKES_PROMISE.
            &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the intent.
            &quot;id&quot;: &quot;A String&quot;, # The unique identifier of the intent.
          },
        },
        &quot;issueModelResult&quot;: { # Issue Modeling result on a conversation. # Overall conversation-level issue modeling result.
          &quot;issueModel&quot;: &quot;A String&quot;, # Issue model that generates the result. Format: projects/{project}/locations/{location}/issueModels/{issue_model}
          &quot;issues&quot;: [ # All the matched issues.
            { # Information about the issue.
              &quot;displayName&quot;: &quot;A String&quot;, # Immutable. Display name of the assigned issue. This field is set at time of analyis and immutable since then.
              &quot;issue&quot;: &quot;A String&quot;, # Resource name of the assigned issue.
              &quot;score&quot;: 3.14, # Score indicating the likelihood of the issue assignment. currently bounded on [0,1].
            },
          ],
        },
        &quot;phraseMatchers&quot;: { # All the matched phrase matchers in the call.
          &quot;a_key&quot;: { # The data for a matched phrase matcher. Represents information identifying a phrase matcher for a given match.
            &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the phrase matcher.
            &quot;phraseMatcher&quot;: &quot;A String&quot;, # The unique identifier (the resource name) of the phrase matcher.
          },
        },
        &quot;sentiments&quot;: [ # Overall conversation-level sentiment for each channel of the call.
          { # One channel of conversation-level sentiment data.
            &quot;channelTag&quot;: 42, # The channel of the audio that the data applies to.
            &quot;sentimentData&quot;: { # The data for a sentiment annotation. # Data specifying sentiment.
              &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
              &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
            },
          },
        ],
        &quot;silence&quot;: { # Conversation-level silence data. # Overall conversation-level silence during the call.
          &quot;silenceDuration&quot;: &quot;A String&quot;, # Amount of time calculated to be in silence.
          &quot;silencePercentage&quot;: 3.14, # Percentage of the total conversation spent in silence.
        },
      },
      &quot;endTime&quot;: &quot;A String&quot;, # The time at which the analysis ended.
    },
    &quot;annotatorSelector&quot;: { # Selector of all available annotators and phrase matchers to run. # To select the annotators to run and the phrase matchers to use (if any). If not specified, all annotators will be run.
      &quot;issueModels&quot;: [ # The issue model to run. If not provided, the most recently deployed topic model will be used. The provided issue model will only be used for inference if the issue model is deployed and if run_issue_model_annotator is set to true. If more than one issue model is provided, only the first provided issue model will be used for inference.
        &quot;A String&quot;,
      ],
      &quot;phraseMatchers&quot;: [ # The list of phrase matchers to run. If not provided, all active phrase matchers will be used. If inactive phrase matchers are provided, they will not be used. Phrase matchers will be run only if run_phrase_matcher_annotator is set to true. Format: projects/{project}/locations/{location}/phraseMatchers/{phrase_matcher}
        &quot;A String&quot;,
      ],
      &quot;runEntityAnnotator&quot;: True or False, # Whether to run the entity annotator.
      &quot;runIntentAnnotator&quot;: True or False, # Whether to run the intent annotator.
      &quot;runInterruptionAnnotator&quot;: True or False, # Whether to run the interruption annotator.
      &quot;runIssueModelAnnotator&quot;: True or False, # Whether to run the issue model annotator. A model should have already been deployed for this to take effect.
      &quot;runPhraseMatcherAnnotator&quot;: True or False, # Whether to run the active phrase matcher annotator(s).
      &quot;runSentimentAnnotator&quot;: True or False, # Whether to run the sentiment annotator.
      &quot;runSilenceAnnotator&quot;: True or False, # Whether to run the silence annotator.
      &quot;runSummarizationAnnotator&quot;: True or False, # Whether to run the summarization annotator.
      &quot;summarizationConfig&quot;: { # Configuration for summarization. # Configuration for the summarization annotator.
        &quot;conversationProfile&quot;: &quot;A String&quot;, # Resource name of the Dialogflow conversation profile. Format: projects/{project}/locations/{location}/conversationProfiles/{conversation_profile}
        &quot;summarizationModel&quot;: &quot;A String&quot;, # Default summarization model to be used.
      },
    },
    &quot;createTime&quot;: &quot;A String&quot;, # Output only. The time at which the analysis was created, which occurs when the long-running operation completes.
    &quot;name&quot;: &quot;A String&quot;, # Immutable. The resource name of the analysis. Format: projects/{project}/locations/{location}/conversations/{conversation}/analyses/{analysis}
    &quot;requestTime&quot;: &quot;A String&quot;, # Output only. The time at which the analysis was requested.
  },
  &quot;latestSummary&quot;: { # Conversation summarization suggestion data. # Output only. Latest summary of the conversation.
    &quot;answerRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
    &quot;confidence&quot;: 3.14, # The confidence score of the summarization.
    &quot;conversationModel&quot;: &quot;A String&quot;, # The name of the model that generates this summary. Format: projects/{project}/locations/{location}/conversationModels/{conversation_model}
    &quot;metadata&quot;: { # A map that contains metadata about the summarization and the document from which it originates.
      &quot;a_key&quot;: &quot;A String&quot;,
    },
    &quot;text&quot;: &quot;A String&quot;, # The summarization content that is concatenated into one string.
    &quot;textSections&quot;: { # The summarization content that is divided into sections. The key is the section&#x27;s name and the value is the section&#x27;s content. There is no specific format for the key or value.
      &quot;a_key&quot;: &quot;A String&quot;,
    },
  },
  &quot;medium&quot;: &quot;A String&quot;, # Immutable. The conversation medium, if unspecified will default to PHONE_CALL.
  &quot;metadataJson&quot;: &quot;A String&quot;, # Input only. JSON Metadata encoded as a string. This field is primarily used by Insights integrations with various telphony systems and must be in one of Insights&#x27; supported formats.
  &quot;name&quot;: &quot;A String&quot;, # Immutable. The resource name of the conversation. Format: projects/{project}/locations/{location}/conversations/{conversation}
  &quot;obfuscatedUserId&quot;: &quot;A String&quot;, # Obfuscated user ID which the customer sent to us.
  &quot;qualityMetadata&quot;: { # Conversation metadata related to quality management. # Conversation metadata related to quality management.
    &quot;agentInfo&quot;: [ # Information about agents involved in the call.
      { # Information about an agent involved in the conversation.
        &quot;agentId&quot;: &quot;A String&quot;, # A user-specified string representing the agent.
        &quot;displayName&quot;: &quot;A String&quot;, # The agent&#x27;s name.
        &quot;dispositionCode&quot;: &quot;A String&quot;, # A user-provided string indicating the outcome of the agent&#x27;s segment of the call.
        &quot;team&quot;: &quot;A String&quot;, # A user-specified string representing the agent&#x27;s team.
      },
    ],
    &quot;customerSatisfactionRating&quot;: 42, # An arbitrary integer value indicating the customer&#x27;s satisfaction rating.
    &quot;menuPath&quot;: &quot;A String&quot;, # An arbitrary string value specifying the menu path the customer took.
    &quot;waitDuration&quot;: &quot;A String&quot;, # The amount of time the customer waited to connect with an agent.
  },
  &quot;runtimeAnnotations&quot;: [ # Output only. The annotations that were generated during the customer and agent interaction.
    { # An annotation that was generated during the customer and agent interaction.
      &quot;annotationId&quot;: &quot;A String&quot;, # The unique identifier of the annotation. Format: projects/{project}/locations/{location}/conversationDatasets/{dataset}/conversationDataItems/{data_item}/conversationAnnotations/{annotation}
      &quot;answerFeedback&quot;: { # The feedback that the customer has about a certain answer in the conversation. # The feedback that the customer has about the answer in `data`.
        &quot;clicked&quot;: True or False, # Indicates whether an answer or item was clicked by the human agent.
        &quot;correctnessLevel&quot;: &quot;A String&quot;, # The correctness level of an answer.
        &quot;displayed&quot;: True or False, # Indicates whether an answer or item was displayed to the human agent in the agent desktop UI.
      },
      &quot;articleSuggestion&quot;: { # Agent Assist Article Suggestion data. # Agent Assist Article Suggestion data.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this article is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the Article Suggestion and the document that it originates from.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
        &quot;source&quot;: &quot;A String&quot;, # The knowledge document that this answer was extracted from. Format: projects/{project}/knowledgeBases/{knowledge_base}/documents/{document}
        &quot;title&quot;: &quot;A String&quot;, # Article title.
        &quot;uri&quot;: &quot;A String&quot;, # Article URI.
      },
      &quot;conversationSummarizationSuggestion&quot;: { # Conversation summarization suggestion data. # Conversation summarization suggestion data.
        &quot;answerRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
        &quot;confidence&quot;: 3.14, # The confidence score of the summarization.
        &quot;conversationModel&quot;: &quot;A String&quot;, # The name of the model that generates this summary. Format: projects/{project}/locations/{location}/conversationModels/{conversation_model}
        &quot;metadata&quot;: { # A map that contains metadata about the summarization and the document from which it originates.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;text&quot;: &quot;A String&quot;, # The summarization content that is concatenated into one string.
        &quot;textSections&quot;: { # The summarization content that is divided into sections. The key is the section&#x27;s name and the value is the section&#x27;s content. There is no specific format for the key or value.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
      },
      &quot;createTime&quot;: &quot;A String&quot;, # The time at which this annotation was created.
      &quot;dialogflowInteraction&quot;: { # Dialogflow interaction data. # Dialogflow interaction data.
        &quot;confidence&quot;: 3.14, # The confidence of the match ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;dialogflowIntentId&quot;: &quot;A String&quot;, # The Dialogflow intent resource path. Format: projects/{project}/agent/{agent}/intents/{intent}
      },
      &quot;endBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation ends, inclusive.
        &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
        &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
      },
      &quot;faqAnswer&quot;: { # Agent Assist frequently-asked-question answer data. # Agent Assist FAQ answer data.
        &quot;answer&quot;: &quot;A String&quot;, # The piece of text from the `source` knowledge base document.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this answer is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the FAQ answer and the document that it originates from.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
        &quot;question&quot;: &quot;A String&quot;, # The corresponding FAQ question.
        &quot;source&quot;: &quot;A String&quot;, # The knowledge document that this answer was extracted from. Format: projects/{project}/knowledgeBases/{knowledge_base}/documents/{document}.
      },
      &quot;smartComposeSuggestion&quot;: { # Agent Assist Smart Compose suggestion data. # Agent Assist Smart Compose suggestion data.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this suggestion is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the Smart Compose suggestion and the document from which it originates.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
        &quot;suggestion&quot;: &quot;A String&quot;, # The content of the suggestion.
      },
      &quot;smartReply&quot;: { # Agent Assist Smart Reply data. # Agent Assist Smart Reply data.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this reply is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the Smart Reply and the document from which it originates.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
        &quot;reply&quot;: &quot;A String&quot;, # The content of the reply.
      },
      &quot;startBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation starts, inclusive.
        &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
        &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
      },
      &quot;userInput&quot;: { # Explicit input used for generating the answer # Explicit input used for generating the answer
        &quot;generatorName&quot;: &quot;A String&quot;, # The resource name of associated generator. Format: `projects//locations//generators/`
        &quot;query&quot;: &quot;A String&quot;, # Query text. Article Search uses this to store the input query used to generate the search results.
        &quot;querySource&quot;: &quot;A String&quot;, # Query source for the answer.
      },
    },
  ],
  &quot;startTime&quot;: &quot;A String&quot;, # The time at which the conversation started.
  &quot;transcript&quot;: { # A message representing the transcript of a conversation. # Output only. The conversation transcript.
    &quot;transcriptSegments&quot;: [ # A list of sequential transcript segments that comprise the conversation.
      { # A segment of a full transcript.
        &quot;channelTag&quot;: 42, # For conversations derived from multi-channel audio, this is the channel number corresponding to the audio from that channel. For audioChannelCount = N, its output values can range from &#x27;1&#x27; to &#x27;N&#x27;. A channel tag of 0 indicates that the audio is mono.
        &quot;confidence&quot;: 3.14, # A confidence estimate between 0.0 and 1.0 of the fidelity of this segment. A default value of 0.0 indicates that the value is unset.
        &quot;dialogflowSegmentMetadata&quot;: { # Metadata from Dialogflow relating to the current transcript segment. # CCAI metadata relating to the current transcript segment.
          &quot;smartReplyAllowlistCovered&quot;: True or False, # Whether the transcript segment was covered under the configured smart reply allowlist in Agent Assist.
        },
        &quot;languageCode&quot;: &quot;A String&quot;, # The language code of this segment as a [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag. Example: &quot;en-US&quot;.
        &quot;messageTime&quot;: &quot;A String&quot;, # The time that the message occurred, if provided.
        &quot;segmentParticipant&quot;: { # The call participant speaking for a given utterance. # The participant of this segment.
          &quot;dialogflowParticipant&quot;: &quot;A String&quot;, # Deprecated. Use `dialogflow_participant_name` instead. The name of the Dialogflow participant. Format: projects/{project}/locations/{location}/conversations/{conversation}/participants/{participant}
          &quot;dialogflowParticipantName&quot;: &quot;A String&quot;, # The name of the participant provided by Dialogflow. Format: projects/{project}/locations/{location}/conversations/{conversation}/participants/{participant}
          &quot;obfuscatedExternalUserId&quot;: &quot;A String&quot;, # Obfuscated user ID from Dialogflow.
          &quot;role&quot;: &quot;A String&quot;, # The role of the participant.
          &quot;userId&quot;: &quot;A String&quot;, # A user-specified ID representing the participant.
        },
        &quot;sentiment&quot;: { # The data for a sentiment annotation. # The sentiment for this transcript segment.
          &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
          &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
        },
        &quot;text&quot;: &quot;A String&quot;, # The text of this segment.
        &quot;words&quot;: [ # A list of the word-specific information for each word in the segment.
          { # Word-level info for words in a transcript.
            &quot;confidence&quot;: 3.14, # A confidence estimate between 0.0 and 1.0 of the fidelity of this word. A default value of 0.0 indicates that the value is unset.
            &quot;endOffset&quot;: &quot;A String&quot;, # Time offset of the end of this word relative to the beginning of the total conversation.
            &quot;startOffset&quot;: &quot;A String&quot;, # Time offset of the start of this word relative to the beginning of the total conversation.
            &quot;word&quot;: &quot;A String&quot;, # The word itself. Includes punctuation marks that surround the word.
          },
        ],
      },
    ],
  },
  &quot;ttl&quot;: &quot;A String&quot;, # Input only. The TTL for this resource. If specified, then this TTL will be used to calculate the expire time.
  &quot;turnCount&quot;: 42, # Output only. The number of turns in the conversation.
  &quot;updateTime&quot;: &quot;A String&quot;, # Output only. The most recent time at which the conversation was updated.
}

  updateMask: string, The list of fields to be updated. All possible fields can be updated by passing `*`, or a subset of the following updateable fields can be provided: * `agent_id` * `language_code` * `labels` * `metadata` * `quality_metadata` * `call_metadata` * `start_time` * `expire_time` or `ttl` * `data_source.gcs_source.audio_uri` or `data_source.dialogflow_source.audio_uri`
  x__xgafv: string, V1 error format.
    Allowed values
      1 - v1 error format
      2 - v2 error format

Returns:
  An object of the form:

    { # The conversation resource.
  &quot;agentId&quot;: &quot;A String&quot;, # An opaque, user-specified string representing the human agent who handled the conversation.
  &quot;callMetadata&quot;: { # Call-specific metadata. # Call-specific metadata.
    &quot;agentChannel&quot;: 42, # The audio channel that contains the agent.
    &quot;customerChannel&quot;: 42, # The audio channel that contains the customer.
  },
  &quot;createTime&quot;: &quot;A String&quot;, # Output only. The time at which the conversation was created.
  &quot;dataSource&quot;: { # The conversation source, which is a combination of transcript and audio. # The source of the audio and transcription for the conversation.
    &quot;dialogflowSource&quot;: { # A Dialogflow source of conversation data. # The source when the conversation comes from Dialogflow.
      &quot;audioUri&quot;: &quot;A String&quot;, # Cloud Storage URI that points to a file that contains the conversation audio.
      &quot;dialogflowConversation&quot;: &quot;A String&quot;, # Output only. The name of the Dialogflow conversation that this conversation resource is derived from. Format: projects/{project}/locations/{location}/conversations/{conversation}
    },
    &quot;gcsSource&quot;: { # A Cloud Storage source of conversation data. # A Cloud Storage location specification for the audio and transcript.
      &quot;audioUri&quot;: &quot;A String&quot;, # Cloud Storage URI that points to a file that contains the conversation audio.
      &quot;transcriptUri&quot;: &quot;A String&quot;, # Immutable. Cloud Storage URI that points to a file that contains the conversation transcript.
    },
  },
  &quot;dialogflowIntents&quot;: { # Output only. All the matched Dialogflow intents in the call. The key corresponds to a Dialogflow intent, format: projects/{project}/agent/{agent}/intents/{intent}
    &quot;a_key&quot;: { # The data for a Dialogflow intent. Represents a detected intent in the conversation, e.g. MAKES_PROMISE.
      &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the intent.
    },
  },
  &quot;duration&quot;: &quot;A String&quot;, # Output only. The duration of the conversation.
  &quot;expireTime&quot;: &quot;A String&quot;, # The time at which this conversation should expire. After this time, the conversation data and any associated analyses will be deleted.
  &quot;labels&quot;: { # A map for the user to specify any custom fields. A maximum of 20 labels per conversation is allowed, with a maximum of 256 characters per entry.
    &quot;a_key&quot;: &quot;A String&quot;,
  },
  &quot;languageCode&quot;: &quot;A String&quot;, # A user-specified language code for the conversation.
  &quot;latestAnalysis&quot;: { # The analysis resource. # Output only. The conversation&#x27;s latest analysis, if one exists.
    &quot;analysisResult&quot;: { # The result of an analysis. # Output only. The result of the analysis, which is populated when the analysis finishes.
      &quot;callAnalysisMetadata&quot;: { # Call-specific metadata created during analysis. # Call-specific metadata created by the analysis.
        &quot;annotations&quot;: [ # A list of call annotations that apply to this call.
          { # A piece of metadata that applies to a window of a call.
            &quot;annotationEndBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation ends, inclusive.
              &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
              &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
            },
            &quot;annotationStartBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation starts, inclusive.
              &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
              &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
            },
            &quot;channelTag&quot;: 42, # The channel of the audio where the annotation occurs. For single-channel audio, this field is not populated.
            &quot;entityMentionData&quot;: { # The data for an entity mention annotation. This represents a mention of an `Entity` in the conversation. # Data specifying an entity mention.
              &quot;entityUniqueId&quot;: &quot;A String&quot;, # The key of this entity in conversation entities. Can be used to retrieve the exact `Entity` this mention is attached to.
              &quot;sentiment&quot;: { # The data for a sentiment annotation. # Sentiment expressed for this mention of the entity.
                &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
                &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
              },
              &quot;type&quot;: &quot;A String&quot;, # The type of the entity mention.
            },
            &quot;holdData&quot;: { # The data for a hold annotation. # Data specifying a hold.
            },
            &quot;intentMatchData&quot;: { # The data for an intent match. Represents an intent match for a text segment in the conversation. A text segment can be part of a sentence, a complete sentence, or an utterance with multiple sentences. # Data specifying an intent match.
              &quot;intentUniqueId&quot;: &quot;A String&quot;, # The id of the matched intent. Can be used to retrieve the corresponding intent information.
            },
            &quot;interruptionData&quot;: { # The data for an interruption annotation. # Data specifying an interruption.
            },
            &quot;issueMatchData&quot;: { # The data for an issue match annotation. # Data specifying an issue match.
              &quot;issueAssignment&quot;: { # Information about the issue. # Information about the issue&#x27;s assignment.
                &quot;displayName&quot;: &quot;A String&quot;, # Immutable. Display name of the assigned issue. This field is set at time of analyis and immutable since then.
                &quot;issue&quot;: &quot;A String&quot;, # Resource name of the assigned issue.
                &quot;score&quot;: 3.14, # Score indicating the likelihood of the issue assignment. currently bounded on [0,1].
              },
            },
            &quot;phraseMatchData&quot;: { # The data for a matched phrase matcher. Represents information identifying a phrase matcher for a given match. # Data specifying a phrase match.
              &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the phrase matcher.
              &quot;phraseMatcher&quot;: &quot;A String&quot;, # The unique identifier (the resource name) of the phrase matcher.
            },
            &quot;sentimentData&quot;: { # The data for a sentiment annotation. # Data specifying sentiment.
              &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
              &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
            },
            &quot;silenceData&quot;: { # The data for a silence annotation. # Data specifying silence.
            },
          },
        ],
        &quot;entities&quot;: { # All the entities in the call.
          &quot;a_key&quot;: { # The data for an entity annotation. Represents a phrase in the conversation that is a known entity, such as a person, an organization, or location.
            &quot;displayName&quot;: &quot;A String&quot;, # The representative name for the entity.
            &quot;metadata&quot;: { # Metadata associated with the entity. For most entity types, the metadata is a Wikipedia URL (`wikipedia_url`) and Knowledge Graph MID (`mid`), if they are available. For the metadata associated with other entity types, see the Type table below.
              &quot;a_key&quot;: &quot;A String&quot;,
            },
            &quot;salience&quot;: 3.14, # The salience score associated with the entity in the [0, 1.0] range. The salience score for an entity provides information about the importance or centrality of that entity to the entire document text. Scores closer to 0 are less salient, while scores closer to 1.0 are highly salient.
            &quot;sentiment&quot;: { # The data for a sentiment annotation. # The aggregate sentiment expressed for this entity in the conversation.
              &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
              &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
            },
            &quot;type&quot;: &quot;A String&quot;, # The entity type.
          },
        },
        &quot;intents&quot;: { # All the matched intents in the call.
          &quot;a_key&quot;: { # The data for an intent. Represents a detected intent in the conversation, for example MAKES_PROMISE.
            &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the intent.
            &quot;id&quot;: &quot;A String&quot;, # The unique identifier of the intent.
          },
        },
        &quot;issueModelResult&quot;: { # Issue Modeling result on a conversation. # Overall conversation-level issue modeling result.
          &quot;issueModel&quot;: &quot;A String&quot;, # Issue model that generates the result. Format: projects/{project}/locations/{location}/issueModels/{issue_model}
          &quot;issues&quot;: [ # All the matched issues.
            { # Information about the issue.
              &quot;displayName&quot;: &quot;A String&quot;, # Immutable. Display name of the assigned issue. This field is set at time of analyis and immutable since then.
              &quot;issue&quot;: &quot;A String&quot;, # Resource name of the assigned issue.
              &quot;score&quot;: 3.14, # Score indicating the likelihood of the issue assignment. currently bounded on [0,1].
            },
          ],
        },
        &quot;phraseMatchers&quot;: { # All the matched phrase matchers in the call.
          &quot;a_key&quot;: { # The data for a matched phrase matcher. Represents information identifying a phrase matcher for a given match.
            &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the phrase matcher.
            &quot;phraseMatcher&quot;: &quot;A String&quot;, # The unique identifier (the resource name) of the phrase matcher.
          },
        },
        &quot;sentiments&quot;: [ # Overall conversation-level sentiment for each channel of the call.
          { # One channel of conversation-level sentiment data.
            &quot;channelTag&quot;: 42, # The channel of the audio that the data applies to.
            &quot;sentimentData&quot;: { # The data for a sentiment annotation. # Data specifying sentiment.
              &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
              &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
            },
          },
        ],
        &quot;silence&quot;: { # Conversation-level silence data. # Overall conversation-level silence during the call.
          &quot;silenceDuration&quot;: &quot;A String&quot;, # Amount of time calculated to be in silence.
          &quot;silencePercentage&quot;: 3.14, # Percentage of the total conversation spent in silence.
        },
      },
      &quot;endTime&quot;: &quot;A String&quot;, # The time at which the analysis ended.
    },
    &quot;annotatorSelector&quot;: { # Selector of all available annotators and phrase matchers to run. # To select the annotators to run and the phrase matchers to use (if any). If not specified, all annotators will be run.
      &quot;issueModels&quot;: [ # The issue model to run. If not provided, the most recently deployed topic model will be used. The provided issue model will only be used for inference if the issue model is deployed and if run_issue_model_annotator is set to true. If more than one issue model is provided, only the first provided issue model will be used for inference.
        &quot;A String&quot;,
      ],
      &quot;phraseMatchers&quot;: [ # The list of phrase matchers to run. If not provided, all active phrase matchers will be used. If inactive phrase matchers are provided, they will not be used. Phrase matchers will be run only if run_phrase_matcher_annotator is set to true. Format: projects/{project}/locations/{location}/phraseMatchers/{phrase_matcher}
        &quot;A String&quot;,
      ],
      &quot;runEntityAnnotator&quot;: True or False, # Whether to run the entity annotator.
      &quot;runIntentAnnotator&quot;: True or False, # Whether to run the intent annotator.
      &quot;runInterruptionAnnotator&quot;: True or False, # Whether to run the interruption annotator.
      &quot;runIssueModelAnnotator&quot;: True or False, # Whether to run the issue model annotator. A model should have already been deployed for this to take effect.
      &quot;runPhraseMatcherAnnotator&quot;: True or False, # Whether to run the active phrase matcher annotator(s).
      &quot;runSentimentAnnotator&quot;: True or False, # Whether to run the sentiment annotator.
      &quot;runSilenceAnnotator&quot;: True or False, # Whether to run the silence annotator.
      &quot;runSummarizationAnnotator&quot;: True or False, # Whether to run the summarization annotator.
      &quot;summarizationConfig&quot;: { # Configuration for summarization. # Configuration for the summarization annotator.
        &quot;conversationProfile&quot;: &quot;A String&quot;, # Resource name of the Dialogflow conversation profile. Format: projects/{project}/locations/{location}/conversationProfiles/{conversation_profile}
        &quot;summarizationModel&quot;: &quot;A String&quot;, # Default summarization model to be used.
      },
    },
    &quot;createTime&quot;: &quot;A String&quot;, # Output only. The time at which the analysis was created, which occurs when the long-running operation completes.
    &quot;name&quot;: &quot;A String&quot;, # Immutable. The resource name of the analysis. Format: projects/{project}/locations/{location}/conversations/{conversation}/analyses/{analysis}
    &quot;requestTime&quot;: &quot;A String&quot;, # Output only. The time at which the analysis was requested.
  },
  &quot;latestSummary&quot;: { # Conversation summarization suggestion data. # Output only. Latest summary of the conversation.
    &quot;answerRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
    &quot;confidence&quot;: 3.14, # The confidence score of the summarization.
    &quot;conversationModel&quot;: &quot;A String&quot;, # The name of the model that generates this summary. Format: projects/{project}/locations/{location}/conversationModels/{conversation_model}
    &quot;metadata&quot;: { # A map that contains metadata about the summarization and the document from which it originates.
      &quot;a_key&quot;: &quot;A String&quot;,
    },
    &quot;text&quot;: &quot;A String&quot;, # The summarization content that is concatenated into one string.
    &quot;textSections&quot;: { # The summarization content that is divided into sections. The key is the section&#x27;s name and the value is the section&#x27;s content. There is no specific format for the key or value.
      &quot;a_key&quot;: &quot;A String&quot;,
    },
  },
  &quot;medium&quot;: &quot;A String&quot;, # Immutable. The conversation medium, if unspecified will default to PHONE_CALL.
  &quot;metadataJson&quot;: &quot;A String&quot;, # Input only. JSON Metadata encoded as a string. This field is primarily used by Insights integrations with various telphony systems and must be in one of Insights&#x27; supported formats.
  &quot;name&quot;: &quot;A String&quot;, # Immutable. The resource name of the conversation. Format: projects/{project}/locations/{location}/conversations/{conversation}
  &quot;obfuscatedUserId&quot;: &quot;A String&quot;, # Obfuscated user ID which the customer sent to us.
  &quot;qualityMetadata&quot;: { # Conversation metadata related to quality management. # Conversation metadata related to quality management.
    &quot;agentInfo&quot;: [ # Information about agents involved in the call.
      { # Information about an agent involved in the conversation.
        &quot;agentId&quot;: &quot;A String&quot;, # A user-specified string representing the agent.
        &quot;displayName&quot;: &quot;A String&quot;, # The agent&#x27;s name.
        &quot;dispositionCode&quot;: &quot;A String&quot;, # A user-provided string indicating the outcome of the agent&#x27;s segment of the call.
        &quot;team&quot;: &quot;A String&quot;, # A user-specified string representing the agent&#x27;s team.
      },
    ],
    &quot;customerSatisfactionRating&quot;: 42, # An arbitrary integer value indicating the customer&#x27;s satisfaction rating.
    &quot;menuPath&quot;: &quot;A String&quot;, # An arbitrary string value specifying the menu path the customer took.
    &quot;waitDuration&quot;: &quot;A String&quot;, # The amount of time the customer waited to connect with an agent.
  },
  &quot;runtimeAnnotations&quot;: [ # Output only. The annotations that were generated during the customer and agent interaction.
    { # An annotation that was generated during the customer and agent interaction.
      &quot;annotationId&quot;: &quot;A String&quot;, # The unique identifier of the annotation. Format: projects/{project}/locations/{location}/conversationDatasets/{dataset}/conversationDataItems/{data_item}/conversationAnnotations/{annotation}
      &quot;answerFeedback&quot;: { # The feedback that the customer has about a certain answer in the conversation. # The feedback that the customer has about the answer in `data`.
        &quot;clicked&quot;: True or False, # Indicates whether an answer or item was clicked by the human agent.
        &quot;correctnessLevel&quot;: &quot;A String&quot;, # The correctness level of an answer.
        &quot;displayed&quot;: True or False, # Indicates whether an answer or item was displayed to the human agent in the agent desktop UI.
      },
      &quot;articleSuggestion&quot;: { # Agent Assist Article Suggestion data. # Agent Assist Article Suggestion data.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this article is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the Article Suggestion and the document that it originates from.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
        &quot;source&quot;: &quot;A String&quot;, # The knowledge document that this answer was extracted from. Format: projects/{project}/knowledgeBases/{knowledge_base}/documents/{document}
        &quot;title&quot;: &quot;A String&quot;, # Article title.
        &quot;uri&quot;: &quot;A String&quot;, # Article URI.
      },
      &quot;conversationSummarizationSuggestion&quot;: { # Conversation summarization suggestion data. # Conversation summarization suggestion data.
        &quot;answerRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
        &quot;confidence&quot;: 3.14, # The confidence score of the summarization.
        &quot;conversationModel&quot;: &quot;A String&quot;, # The name of the model that generates this summary. Format: projects/{project}/locations/{location}/conversationModels/{conversation_model}
        &quot;metadata&quot;: { # A map that contains metadata about the summarization and the document from which it originates.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;text&quot;: &quot;A String&quot;, # The summarization content that is concatenated into one string.
        &quot;textSections&quot;: { # The summarization content that is divided into sections. The key is the section&#x27;s name and the value is the section&#x27;s content. There is no specific format for the key or value.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
      },
      &quot;createTime&quot;: &quot;A String&quot;, # The time at which this annotation was created.
      &quot;dialogflowInteraction&quot;: { # Dialogflow interaction data. # Dialogflow interaction data.
        &quot;confidence&quot;: 3.14, # The confidence of the match ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;dialogflowIntentId&quot;: &quot;A String&quot;, # The Dialogflow intent resource path. Format: projects/{project}/agent/{agent}/intents/{intent}
      },
      &quot;endBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation ends, inclusive.
        &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
        &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
      },
      &quot;faqAnswer&quot;: { # Agent Assist frequently-asked-question answer data. # Agent Assist FAQ answer data.
        &quot;answer&quot;: &quot;A String&quot;, # The piece of text from the `source` knowledge base document.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this answer is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the FAQ answer and the document that it originates from.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
        &quot;question&quot;: &quot;A String&quot;, # The corresponding FAQ question.
        &quot;source&quot;: &quot;A String&quot;, # The knowledge document that this answer was extracted from. Format: projects/{project}/knowledgeBases/{knowledge_base}/documents/{document}.
      },
      &quot;smartComposeSuggestion&quot;: { # Agent Assist Smart Compose suggestion data. # Agent Assist Smart Compose suggestion data.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this suggestion is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the Smart Compose suggestion and the document from which it originates.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
        &quot;suggestion&quot;: &quot;A String&quot;, # The content of the suggestion.
      },
      &quot;smartReply&quot;: { # Agent Assist Smart Reply data. # Agent Assist Smart Reply data.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this reply is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the Smart Reply and the document from which it originates.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
        &quot;reply&quot;: &quot;A String&quot;, # The content of the reply.
      },
      &quot;startBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation starts, inclusive.
        &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
        &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
      },
      &quot;userInput&quot;: { # Explicit input used for generating the answer # Explicit input used for generating the answer
        &quot;generatorName&quot;: &quot;A String&quot;, # The resource name of associated generator. Format: `projects//locations//generators/`
        &quot;query&quot;: &quot;A String&quot;, # Query text. Article Search uses this to store the input query used to generate the search results.
        &quot;querySource&quot;: &quot;A String&quot;, # Query source for the answer.
      },
    },
  ],
  &quot;startTime&quot;: &quot;A String&quot;, # The time at which the conversation started.
  &quot;transcript&quot;: { # A message representing the transcript of a conversation. # Output only. The conversation transcript.
    &quot;transcriptSegments&quot;: [ # A list of sequential transcript segments that comprise the conversation.
      { # A segment of a full transcript.
        &quot;channelTag&quot;: 42, # For conversations derived from multi-channel audio, this is the channel number corresponding to the audio from that channel. For audioChannelCount = N, its output values can range from &#x27;1&#x27; to &#x27;N&#x27;. A channel tag of 0 indicates that the audio is mono.
        &quot;confidence&quot;: 3.14, # A confidence estimate between 0.0 and 1.0 of the fidelity of this segment. A default value of 0.0 indicates that the value is unset.
        &quot;dialogflowSegmentMetadata&quot;: { # Metadata from Dialogflow relating to the current transcript segment. # CCAI metadata relating to the current transcript segment.
          &quot;smartReplyAllowlistCovered&quot;: True or False, # Whether the transcript segment was covered under the configured smart reply allowlist in Agent Assist.
        },
        &quot;languageCode&quot;: &quot;A String&quot;, # The language code of this segment as a [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag. Example: &quot;en-US&quot;.
        &quot;messageTime&quot;: &quot;A String&quot;, # The time that the message occurred, if provided.
        &quot;segmentParticipant&quot;: { # The call participant speaking for a given utterance. # The participant of this segment.
          &quot;dialogflowParticipant&quot;: &quot;A String&quot;, # Deprecated. Use `dialogflow_participant_name` instead. The name of the Dialogflow participant. Format: projects/{project}/locations/{location}/conversations/{conversation}/participants/{participant}
          &quot;dialogflowParticipantName&quot;: &quot;A String&quot;, # The name of the participant provided by Dialogflow. Format: projects/{project}/locations/{location}/conversations/{conversation}/participants/{participant}
          &quot;obfuscatedExternalUserId&quot;: &quot;A String&quot;, # Obfuscated user ID from Dialogflow.
          &quot;role&quot;: &quot;A String&quot;, # The role of the participant.
          &quot;userId&quot;: &quot;A String&quot;, # A user-specified ID representing the participant.
        },
        &quot;sentiment&quot;: { # The data for a sentiment annotation. # The sentiment for this transcript segment.
          &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
          &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
        },
        &quot;text&quot;: &quot;A String&quot;, # The text of this segment.
        &quot;words&quot;: [ # A list of the word-specific information for each word in the segment.
          { # Word-level info for words in a transcript.
            &quot;confidence&quot;: 3.14, # A confidence estimate between 0.0 and 1.0 of the fidelity of this word. A default value of 0.0 indicates that the value is unset.
            &quot;endOffset&quot;: &quot;A String&quot;, # Time offset of the end of this word relative to the beginning of the total conversation.
            &quot;startOffset&quot;: &quot;A String&quot;, # Time offset of the start of this word relative to the beginning of the total conversation.
            &quot;word&quot;: &quot;A String&quot;, # The word itself. Includes punctuation marks that surround the word.
          },
        ],
      },
    ],
  },
  &quot;ttl&quot;: &quot;A String&quot;, # Input only. The TTL for this resource. If specified, then this TTL will be used to calculate the expire time.
  &quot;turnCount&quot;: 42, # Output only. The number of turns in the conversation.
  &quot;updateTime&quot;: &quot;A String&quot;, # Output only. The most recent time at which the conversation was updated.
}</pre>
</div>

<div class="method">
    <code class="details" id="upload">upload(parent, body=None, x__xgafv=None)</code>
  <pre>Create a long-running conversation upload operation. This method differs from `CreateConversation` by allowing audio transcription and optional DLP redaction.

Args:
  parent: string, Required. The parent resource of the conversation. (required)
  body: object, The request body.
    The object takes the form of:

{ # Request to upload a conversation.
  &quot;conversation&quot;: { # The conversation resource. # Required. The conversation resource to create.
    &quot;agentId&quot;: &quot;A String&quot;, # An opaque, user-specified string representing the human agent who handled the conversation.
    &quot;callMetadata&quot;: { # Call-specific metadata. # Call-specific metadata.
      &quot;agentChannel&quot;: 42, # The audio channel that contains the agent.
      &quot;customerChannel&quot;: 42, # The audio channel that contains the customer.
    },
    &quot;createTime&quot;: &quot;A String&quot;, # Output only. The time at which the conversation was created.
    &quot;dataSource&quot;: { # The conversation source, which is a combination of transcript and audio. # The source of the audio and transcription for the conversation.
      &quot;dialogflowSource&quot;: { # A Dialogflow source of conversation data. # The source when the conversation comes from Dialogflow.
        &quot;audioUri&quot;: &quot;A String&quot;, # Cloud Storage URI that points to a file that contains the conversation audio.
        &quot;dialogflowConversation&quot;: &quot;A String&quot;, # Output only. The name of the Dialogflow conversation that this conversation resource is derived from. Format: projects/{project}/locations/{location}/conversations/{conversation}
      },
      &quot;gcsSource&quot;: { # A Cloud Storage source of conversation data. # A Cloud Storage location specification for the audio and transcript.
        &quot;audioUri&quot;: &quot;A String&quot;, # Cloud Storage URI that points to a file that contains the conversation audio.
        &quot;transcriptUri&quot;: &quot;A String&quot;, # Immutable. Cloud Storage URI that points to a file that contains the conversation transcript.
      },
    },
    &quot;dialogflowIntents&quot;: { # Output only. All the matched Dialogflow intents in the call. The key corresponds to a Dialogflow intent, format: projects/{project}/agent/{agent}/intents/{intent}
      &quot;a_key&quot;: { # The data for a Dialogflow intent. Represents a detected intent in the conversation, e.g. MAKES_PROMISE.
        &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the intent.
      },
    },
    &quot;duration&quot;: &quot;A String&quot;, # Output only. The duration of the conversation.
    &quot;expireTime&quot;: &quot;A String&quot;, # The time at which this conversation should expire. After this time, the conversation data and any associated analyses will be deleted.
    &quot;labels&quot;: { # A map for the user to specify any custom fields. A maximum of 20 labels per conversation is allowed, with a maximum of 256 characters per entry.
      &quot;a_key&quot;: &quot;A String&quot;,
    },
    &quot;languageCode&quot;: &quot;A String&quot;, # A user-specified language code for the conversation.
    &quot;latestAnalysis&quot;: { # The analysis resource. # Output only. The conversation&#x27;s latest analysis, if one exists.
      &quot;analysisResult&quot;: { # The result of an analysis. # Output only. The result of the analysis, which is populated when the analysis finishes.
        &quot;callAnalysisMetadata&quot;: { # Call-specific metadata created during analysis. # Call-specific metadata created by the analysis.
          &quot;annotations&quot;: [ # A list of call annotations that apply to this call.
            { # A piece of metadata that applies to a window of a call.
              &quot;annotationEndBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation ends, inclusive.
                &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
                &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
              },
              &quot;annotationStartBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation starts, inclusive.
                &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
                &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
              },
              &quot;channelTag&quot;: 42, # The channel of the audio where the annotation occurs. For single-channel audio, this field is not populated.
              &quot;entityMentionData&quot;: { # The data for an entity mention annotation. This represents a mention of an `Entity` in the conversation. # Data specifying an entity mention.
                &quot;entityUniqueId&quot;: &quot;A String&quot;, # The key of this entity in conversation entities. Can be used to retrieve the exact `Entity` this mention is attached to.
                &quot;sentiment&quot;: { # The data for a sentiment annotation. # Sentiment expressed for this mention of the entity.
                  &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
                  &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
                },
                &quot;type&quot;: &quot;A String&quot;, # The type of the entity mention.
              },
              &quot;holdData&quot;: { # The data for a hold annotation. # Data specifying a hold.
              },
              &quot;intentMatchData&quot;: { # The data for an intent match. Represents an intent match for a text segment in the conversation. A text segment can be part of a sentence, a complete sentence, or an utterance with multiple sentences. # Data specifying an intent match.
                &quot;intentUniqueId&quot;: &quot;A String&quot;, # The id of the matched intent. Can be used to retrieve the corresponding intent information.
              },
              &quot;interruptionData&quot;: { # The data for an interruption annotation. # Data specifying an interruption.
              },
              &quot;issueMatchData&quot;: { # The data for an issue match annotation. # Data specifying an issue match.
                &quot;issueAssignment&quot;: { # Information about the issue. # Information about the issue&#x27;s assignment.
                  &quot;displayName&quot;: &quot;A String&quot;, # Immutable. Display name of the assigned issue. This field is set at time of analyis and immutable since then.
                  &quot;issue&quot;: &quot;A String&quot;, # Resource name of the assigned issue.
                  &quot;score&quot;: 3.14, # Score indicating the likelihood of the issue assignment. currently bounded on [0,1].
                },
              },
              &quot;phraseMatchData&quot;: { # The data for a matched phrase matcher. Represents information identifying a phrase matcher for a given match. # Data specifying a phrase match.
                &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the phrase matcher.
                &quot;phraseMatcher&quot;: &quot;A String&quot;, # The unique identifier (the resource name) of the phrase matcher.
              },
              &quot;sentimentData&quot;: { # The data for a sentiment annotation. # Data specifying sentiment.
                &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
                &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
              },
              &quot;silenceData&quot;: { # The data for a silence annotation. # Data specifying silence.
              },
            },
          ],
          &quot;entities&quot;: { # All the entities in the call.
            &quot;a_key&quot;: { # The data for an entity annotation. Represents a phrase in the conversation that is a known entity, such as a person, an organization, or location.
              &quot;displayName&quot;: &quot;A String&quot;, # The representative name for the entity.
              &quot;metadata&quot;: { # Metadata associated with the entity. For most entity types, the metadata is a Wikipedia URL (`wikipedia_url`) and Knowledge Graph MID (`mid`), if they are available. For the metadata associated with other entity types, see the Type table below.
                &quot;a_key&quot;: &quot;A String&quot;,
              },
              &quot;salience&quot;: 3.14, # The salience score associated with the entity in the [0, 1.0] range. The salience score for an entity provides information about the importance or centrality of that entity to the entire document text. Scores closer to 0 are less salient, while scores closer to 1.0 are highly salient.
              &quot;sentiment&quot;: { # The data for a sentiment annotation. # The aggregate sentiment expressed for this entity in the conversation.
                &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
                &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
              },
              &quot;type&quot;: &quot;A String&quot;, # The entity type.
            },
          },
          &quot;intents&quot;: { # All the matched intents in the call.
            &quot;a_key&quot;: { # The data for an intent. Represents a detected intent in the conversation, for example MAKES_PROMISE.
              &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the intent.
              &quot;id&quot;: &quot;A String&quot;, # The unique identifier of the intent.
            },
          },
          &quot;issueModelResult&quot;: { # Issue Modeling result on a conversation. # Overall conversation-level issue modeling result.
            &quot;issueModel&quot;: &quot;A String&quot;, # Issue model that generates the result. Format: projects/{project}/locations/{location}/issueModels/{issue_model}
            &quot;issues&quot;: [ # All the matched issues.
              { # Information about the issue.
                &quot;displayName&quot;: &quot;A String&quot;, # Immutable. Display name of the assigned issue. This field is set at time of analyis and immutable since then.
                &quot;issue&quot;: &quot;A String&quot;, # Resource name of the assigned issue.
                &quot;score&quot;: 3.14, # Score indicating the likelihood of the issue assignment. currently bounded on [0,1].
              },
            ],
          },
          &quot;phraseMatchers&quot;: { # All the matched phrase matchers in the call.
            &quot;a_key&quot;: { # The data for a matched phrase matcher. Represents information identifying a phrase matcher for a given match.
              &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the phrase matcher.
              &quot;phraseMatcher&quot;: &quot;A String&quot;, # The unique identifier (the resource name) of the phrase matcher.
            },
          },
          &quot;sentiments&quot;: [ # Overall conversation-level sentiment for each channel of the call.
            { # One channel of conversation-level sentiment data.
              &quot;channelTag&quot;: 42, # The channel of the audio that the data applies to.
              &quot;sentimentData&quot;: { # The data for a sentiment annotation. # Data specifying sentiment.
                &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
                &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
              },
            },
          ],
          &quot;silence&quot;: { # Conversation-level silence data. # Overall conversation-level silence during the call.
            &quot;silenceDuration&quot;: &quot;A String&quot;, # Amount of time calculated to be in silence.
            &quot;silencePercentage&quot;: 3.14, # Percentage of the total conversation spent in silence.
          },
        },
        &quot;endTime&quot;: &quot;A String&quot;, # The time at which the analysis ended.
      },
      &quot;annotatorSelector&quot;: { # Selector of all available annotators and phrase matchers to run. # To select the annotators to run and the phrase matchers to use (if any). If not specified, all annotators will be run.
        &quot;issueModels&quot;: [ # The issue model to run. If not provided, the most recently deployed topic model will be used. The provided issue model will only be used for inference if the issue model is deployed and if run_issue_model_annotator is set to true. If more than one issue model is provided, only the first provided issue model will be used for inference.
          &quot;A String&quot;,
        ],
        &quot;phraseMatchers&quot;: [ # The list of phrase matchers to run. If not provided, all active phrase matchers will be used. If inactive phrase matchers are provided, they will not be used. Phrase matchers will be run only if run_phrase_matcher_annotator is set to true. Format: projects/{project}/locations/{location}/phraseMatchers/{phrase_matcher}
          &quot;A String&quot;,
        ],
        &quot;runEntityAnnotator&quot;: True or False, # Whether to run the entity annotator.
        &quot;runIntentAnnotator&quot;: True or False, # Whether to run the intent annotator.
        &quot;runInterruptionAnnotator&quot;: True or False, # Whether to run the interruption annotator.
        &quot;runIssueModelAnnotator&quot;: True or False, # Whether to run the issue model annotator. A model should have already been deployed for this to take effect.
        &quot;runPhraseMatcherAnnotator&quot;: True or False, # Whether to run the active phrase matcher annotator(s).
        &quot;runSentimentAnnotator&quot;: True or False, # Whether to run the sentiment annotator.
        &quot;runSilenceAnnotator&quot;: True or False, # Whether to run the silence annotator.
        &quot;runSummarizationAnnotator&quot;: True or False, # Whether to run the summarization annotator.
        &quot;summarizationConfig&quot;: { # Configuration for summarization. # Configuration for the summarization annotator.
          &quot;conversationProfile&quot;: &quot;A String&quot;, # Resource name of the Dialogflow conversation profile. Format: projects/{project}/locations/{location}/conversationProfiles/{conversation_profile}
          &quot;summarizationModel&quot;: &quot;A String&quot;, # Default summarization model to be used.
        },
      },
      &quot;createTime&quot;: &quot;A String&quot;, # Output only. The time at which the analysis was created, which occurs when the long-running operation completes.
      &quot;name&quot;: &quot;A String&quot;, # Immutable. The resource name of the analysis. Format: projects/{project}/locations/{location}/conversations/{conversation}/analyses/{analysis}
      &quot;requestTime&quot;: &quot;A String&quot;, # Output only. The time at which the analysis was requested.
    },
    &quot;latestSummary&quot;: { # Conversation summarization suggestion data. # Output only. Latest summary of the conversation.
      &quot;answerRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
      &quot;confidence&quot;: 3.14, # The confidence score of the summarization.
      &quot;conversationModel&quot;: &quot;A String&quot;, # The name of the model that generates this summary. Format: projects/{project}/locations/{location}/conversationModels/{conversation_model}
      &quot;metadata&quot;: { # A map that contains metadata about the summarization and the document from which it originates.
        &quot;a_key&quot;: &quot;A String&quot;,
      },
      &quot;text&quot;: &quot;A String&quot;, # The summarization content that is concatenated into one string.
      &quot;textSections&quot;: { # The summarization content that is divided into sections. The key is the section&#x27;s name and the value is the section&#x27;s content. There is no specific format for the key or value.
        &quot;a_key&quot;: &quot;A String&quot;,
      },
    },
    &quot;medium&quot;: &quot;A String&quot;, # Immutable. The conversation medium, if unspecified will default to PHONE_CALL.
    &quot;metadataJson&quot;: &quot;A String&quot;, # Input only. JSON Metadata encoded as a string. This field is primarily used by Insights integrations with various telphony systems and must be in one of Insights&#x27; supported formats.
    &quot;name&quot;: &quot;A String&quot;, # Immutable. The resource name of the conversation. Format: projects/{project}/locations/{location}/conversations/{conversation}
    &quot;obfuscatedUserId&quot;: &quot;A String&quot;, # Obfuscated user ID which the customer sent to us.
    &quot;qualityMetadata&quot;: { # Conversation metadata related to quality management. # Conversation metadata related to quality management.
      &quot;agentInfo&quot;: [ # Information about agents involved in the call.
        { # Information about an agent involved in the conversation.
          &quot;agentId&quot;: &quot;A String&quot;, # A user-specified string representing the agent.
          &quot;displayName&quot;: &quot;A String&quot;, # The agent&#x27;s name.
          &quot;dispositionCode&quot;: &quot;A String&quot;, # A user-provided string indicating the outcome of the agent&#x27;s segment of the call.
          &quot;team&quot;: &quot;A String&quot;, # A user-specified string representing the agent&#x27;s team.
        },
      ],
      &quot;customerSatisfactionRating&quot;: 42, # An arbitrary integer value indicating the customer&#x27;s satisfaction rating.
      &quot;menuPath&quot;: &quot;A String&quot;, # An arbitrary string value specifying the menu path the customer took.
      &quot;waitDuration&quot;: &quot;A String&quot;, # The amount of time the customer waited to connect with an agent.
    },
    &quot;runtimeAnnotations&quot;: [ # Output only. The annotations that were generated during the customer and agent interaction.
      { # An annotation that was generated during the customer and agent interaction.
        &quot;annotationId&quot;: &quot;A String&quot;, # The unique identifier of the annotation. Format: projects/{project}/locations/{location}/conversationDatasets/{dataset}/conversationDataItems/{data_item}/conversationAnnotations/{annotation}
        &quot;answerFeedback&quot;: { # The feedback that the customer has about a certain answer in the conversation. # The feedback that the customer has about the answer in `data`.
          &quot;clicked&quot;: True or False, # Indicates whether an answer or item was clicked by the human agent.
          &quot;correctnessLevel&quot;: &quot;A String&quot;, # The correctness level of an answer.
          &quot;displayed&quot;: True or False, # Indicates whether an answer or item was displayed to the human agent in the agent desktop UI.
        },
        &quot;articleSuggestion&quot;: { # Agent Assist Article Suggestion data. # Agent Assist Article Suggestion data.
          &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this article is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
          &quot;metadata&quot;: { # Map that contains metadata about the Article Suggestion and the document that it originates from.
            &quot;a_key&quot;: &quot;A String&quot;,
          },
          &quot;queryRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
          &quot;source&quot;: &quot;A String&quot;, # The knowledge document that this answer was extracted from. Format: projects/{project}/knowledgeBases/{knowledge_base}/documents/{document}
          &quot;title&quot;: &quot;A String&quot;, # Article title.
          &quot;uri&quot;: &quot;A String&quot;, # Article URI.
        },
        &quot;conversationSummarizationSuggestion&quot;: { # Conversation summarization suggestion data. # Conversation summarization suggestion data.
          &quot;answerRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
          &quot;confidence&quot;: 3.14, # The confidence score of the summarization.
          &quot;conversationModel&quot;: &quot;A String&quot;, # The name of the model that generates this summary. Format: projects/{project}/locations/{location}/conversationModels/{conversation_model}
          &quot;metadata&quot;: { # A map that contains metadata about the summarization and the document from which it originates.
            &quot;a_key&quot;: &quot;A String&quot;,
          },
          &quot;text&quot;: &quot;A String&quot;, # The summarization content that is concatenated into one string.
          &quot;textSections&quot;: { # The summarization content that is divided into sections. The key is the section&#x27;s name and the value is the section&#x27;s content. There is no specific format for the key or value.
            &quot;a_key&quot;: &quot;A String&quot;,
          },
        },
        &quot;createTime&quot;: &quot;A String&quot;, # The time at which this annotation was created.
        &quot;dialogflowInteraction&quot;: { # Dialogflow interaction data. # Dialogflow interaction data.
          &quot;confidence&quot;: 3.14, # The confidence of the match ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
          &quot;dialogflowIntentId&quot;: &quot;A String&quot;, # The Dialogflow intent resource path. Format: projects/{project}/agent/{agent}/intents/{intent}
        },
        &quot;endBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation ends, inclusive.
          &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
          &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
        },
        &quot;faqAnswer&quot;: { # Agent Assist frequently-asked-question answer data. # Agent Assist FAQ answer data.
          &quot;answer&quot;: &quot;A String&quot;, # The piece of text from the `source` knowledge base document.
          &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this answer is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
          &quot;metadata&quot;: { # Map that contains metadata about the FAQ answer and the document that it originates from.
            &quot;a_key&quot;: &quot;A String&quot;,
          },
          &quot;queryRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
          &quot;question&quot;: &quot;A String&quot;, # The corresponding FAQ question.
          &quot;source&quot;: &quot;A String&quot;, # The knowledge document that this answer was extracted from. Format: projects/{project}/knowledgeBases/{knowledge_base}/documents/{document}.
        },
        &quot;smartComposeSuggestion&quot;: { # Agent Assist Smart Compose suggestion data. # Agent Assist Smart Compose suggestion data.
          &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this suggestion is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
          &quot;metadata&quot;: { # Map that contains metadata about the Smart Compose suggestion and the document from which it originates.
            &quot;a_key&quot;: &quot;A String&quot;,
          },
          &quot;queryRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
          &quot;suggestion&quot;: &quot;A String&quot;, # The content of the suggestion.
        },
        &quot;smartReply&quot;: { # Agent Assist Smart Reply data. # Agent Assist Smart Reply data.
          &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this reply is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
          &quot;metadata&quot;: { # Map that contains metadata about the Smart Reply and the document from which it originates.
            &quot;a_key&quot;: &quot;A String&quot;,
          },
          &quot;queryRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
          &quot;reply&quot;: &quot;A String&quot;, # The content of the reply.
        },
        &quot;startBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation starts, inclusive.
          &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
          &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
        },
        &quot;userInput&quot;: { # Explicit input used for generating the answer # Explicit input used for generating the answer
          &quot;generatorName&quot;: &quot;A String&quot;, # The resource name of associated generator. Format: `projects//locations//generators/`
          &quot;query&quot;: &quot;A String&quot;, # Query text. Article Search uses this to store the input query used to generate the search results.
          &quot;querySource&quot;: &quot;A String&quot;, # Query source for the answer.
        },
      },
    ],
    &quot;startTime&quot;: &quot;A String&quot;, # The time at which the conversation started.
    &quot;transcript&quot;: { # A message representing the transcript of a conversation. # Output only. The conversation transcript.
      &quot;transcriptSegments&quot;: [ # A list of sequential transcript segments that comprise the conversation.
        { # A segment of a full transcript.
          &quot;channelTag&quot;: 42, # For conversations derived from multi-channel audio, this is the channel number corresponding to the audio from that channel. For audioChannelCount = N, its output values can range from &#x27;1&#x27; to &#x27;N&#x27;. A channel tag of 0 indicates that the audio is mono.
          &quot;confidence&quot;: 3.14, # A confidence estimate between 0.0 and 1.0 of the fidelity of this segment. A default value of 0.0 indicates that the value is unset.
          &quot;dialogflowSegmentMetadata&quot;: { # Metadata from Dialogflow relating to the current transcript segment. # CCAI metadata relating to the current transcript segment.
            &quot;smartReplyAllowlistCovered&quot;: True or False, # Whether the transcript segment was covered under the configured smart reply allowlist in Agent Assist.
          },
          &quot;languageCode&quot;: &quot;A String&quot;, # The language code of this segment as a [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag. Example: &quot;en-US&quot;.
          &quot;messageTime&quot;: &quot;A String&quot;, # The time that the message occurred, if provided.
          &quot;segmentParticipant&quot;: { # The call participant speaking for a given utterance. # The participant of this segment.
            &quot;dialogflowParticipant&quot;: &quot;A String&quot;, # Deprecated. Use `dialogflow_participant_name` instead. The name of the Dialogflow participant. Format: projects/{project}/locations/{location}/conversations/{conversation}/participants/{participant}
            &quot;dialogflowParticipantName&quot;: &quot;A String&quot;, # The name of the participant provided by Dialogflow. Format: projects/{project}/locations/{location}/conversations/{conversation}/participants/{participant}
            &quot;obfuscatedExternalUserId&quot;: &quot;A String&quot;, # Obfuscated user ID from Dialogflow.
            &quot;role&quot;: &quot;A String&quot;, # The role of the participant.
            &quot;userId&quot;: &quot;A String&quot;, # A user-specified ID representing the participant.
          },
          &quot;sentiment&quot;: { # The data for a sentiment annotation. # The sentiment for this transcript segment.
            &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
            &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
          },
          &quot;text&quot;: &quot;A String&quot;, # The text of this segment.
          &quot;words&quot;: [ # A list of the word-specific information for each word in the segment.
            { # Word-level info for words in a transcript.
              &quot;confidence&quot;: 3.14, # A confidence estimate between 0.0 and 1.0 of the fidelity of this word. A default value of 0.0 indicates that the value is unset.
              &quot;endOffset&quot;: &quot;A String&quot;, # Time offset of the end of this word relative to the beginning of the total conversation.
              &quot;startOffset&quot;: &quot;A String&quot;, # Time offset of the start of this word relative to the beginning of the total conversation.
              &quot;word&quot;: &quot;A String&quot;, # The word itself. Includes punctuation marks that surround the word.
            },
          ],
        },
      ],
    },
    &quot;ttl&quot;: &quot;A String&quot;, # Input only. The TTL for this resource. If specified, then this TTL will be used to calculate the expire time.
    &quot;turnCount&quot;: 42, # Output only. The number of turns in the conversation.
    &quot;updateTime&quot;: &quot;A String&quot;, # Output only. The most recent time at which the conversation was updated.
  },
  &quot;conversationId&quot;: &quot;A String&quot;, # Optional. A unique ID for the new conversation. This ID will become the final component of the conversation&#x27;s resource name. If no ID is specified, a server-generated ID will be used. This value should be 4-64 characters and must match the regular expression `^[a-z0-9-]{4,64}$`. Valid characters are `a-z-`
  &quot;parent&quot;: &quot;A String&quot;, # Required. The parent resource of the conversation.
  &quot;redactionConfig&quot;: { # DLP resources used for redaction while ingesting conversations. DLP settings are applied to conversations ingested from the `UploadConversation` and `IngestConversations` endpoints, including conversation coming from CCAI Platform. They are not applied to conversations ingested from the `CreateConversation` endpoint or the Dialogflow / Agent Assist runtime integrations. When using Dialogflow / Agent Assist runtime integrations, redaction should be performed in Dialogflow / Agent Assist. # Optional. DLP settings for transcript redaction. Will default to the config specified in Settings.
    &quot;deidentifyTemplate&quot;: &quot;A String&quot;, # The fully-qualified DLP deidentify template resource name. Format: `projects/{project}/deidentifyTemplates/{template}`
    &quot;inspectTemplate&quot;: &quot;A String&quot;, # The fully-qualified DLP inspect template resource name. Format: `projects/{project}/locations/{location}/inspectTemplates/{template}`
  },
  &quot;speechConfig&quot;: { # Speech-to-Text configuration. Speech-to-Text settings are applied to conversations ingested from the `UploadConversation` and `IngestConversations` endpoints, including conversation coming from CCAI Platform. They are not applied to conversations ingested from the `CreateConversation` endpoint. # Optional. Speech-to-Text configuration. Will default to the config specified in Settings.
    &quot;speechRecognizer&quot;: &quot;A String&quot;, # The fully-qualified Speech Recognizer resource name. Format: `projects/{project_id}/locations/{location}/recognizer/{recognizer}`
  },
}

  x__xgafv: string, V1 error format.
    Allowed values
      1 - v1 error format
      2 - v2 error format

Returns:
  An object of the form:

    { # This resource represents a long-running operation that is the result of a network API call.
  &quot;done&quot;: True or False, # If the value is `false`, it means the operation is still in progress. If `true`, the operation is completed, and either `error` or `response` is available.
  &quot;error&quot;: { # The `Status` type defines a logical error model that is suitable for different programming environments, including REST APIs and RPC APIs. It is used by [gRPC](https://github.com/grpc). Each `Status` message contains three pieces of data: error code, error message, and error details. You can find out more about this error model and how to work with it in the [API Design Guide](https://cloud.google.com/apis/design/errors). # The error result of the operation in case of failure or cancellation.
    &quot;code&quot;: 42, # The status code, which should be an enum value of google.rpc.Code.
    &quot;details&quot;: [ # A list of messages that carry the error details. There is a common set of message types for APIs to use.
      {
        &quot;a_key&quot;: &quot;&quot;, # Properties of the object. Contains field @type with type URL.
      },
    ],
    &quot;message&quot;: &quot;A String&quot;, # A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client.
  },
  &quot;metadata&quot;: { # Service-specific metadata associated with the operation. It typically contains progress information and common metadata such as create time. Some services might not provide such metadata. Any method that returns a long-running operation should document the metadata type, if any.
    &quot;a_key&quot;: &quot;&quot;, # Properties of the object. Contains field @type with type URL.
  },
  &quot;name&quot;: &quot;A String&quot;, # The server-assigned name, which is only unique within the same service that originally returns it. If you use the default HTTP mapping, the `name` should be a resource name ending with `operations/{unique_id}`.
  &quot;response&quot;: { # The normal, successful response of the operation. If the original method returns no data on success, such as `Delete`, the response is `google.protobuf.Empty`. If the original method is standard `Get`/`Create`/`Update`, the response should be the resource. For other methods, the response should have the type `XxxResponse`, where `Xxx` is the original method name. For example, if the original method name is `TakeSnapshot()`, the inferred response type is `TakeSnapshotResponse`.
    &quot;a_key&quot;: &quot;&quot;, # Properties of the object. Contains field @type with type URL.
  },
}</pre>
</div>

</body></html>