<html><body>
<style>

body, h1, h2, h3, div, span, p, pre, a {
  margin: 0;
  padding: 0;
  border: 0;
  font-weight: inherit;
  font-style: inherit;
  font-size: 100%;
  font-family: inherit;
  vertical-align: baseline;
}

body {
  font-size: 13px;
  padding: 1em;
}

h1 {
  font-size: 26px;
  margin-bottom: 1em;
}

h2 {
  font-size: 24px;
  margin-bottom: 1em;
}

h3 {
  font-size: 20px;
  margin-bottom: 1em;
  margin-top: 1em;
}

pre, code {
  line-height: 1.5;
  font-family: Monaco, 'DejaVu Sans Mono', 'Bitstream Vera Sans Mono', 'Lucida Console', monospace;
}

pre {
  margin-top: 0.5em;
}

h1, h2, h3, p {
  font-family: Arial, sans serif;
}

h1, h2, h3 {
  border-bottom: solid #CCC 1px;
}

.toc_element {
  margin-top: 0.5em;
}

.firstline {
  margin-left: 2 em;
}

.method  {
  margin-top: 1em;
  border: solid 1px #CCC;
  padding: 1em;
  background: #EEE;
}

.details {
  font-weight: bold;
  font-size: 14px;
}

</style>

<h1><a href="contactcenterinsights_v1.html">Contact Center AI Insights API</a> . <a href="contactcenterinsights_v1.projects.html">projects</a> . <a href="contactcenterinsights_v1.projects.locations.html">locations</a> . <a href="contactcenterinsights_v1.projects.locations.conversations.html">conversations</a></h1>
<h2>Instance Methods</h2>
<p class="toc_element">
  <code><a href="contactcenterinsights_v1.projects.locations.conversations.analyses.html">analyses()</a></code>
</p>
<p class="firstline">Returns the analyses Resource.</p>

<p class="toc_element">
  <code><a href="#bulkAnalyze">bulkAnalyze(parent, body=None, x__xgafv=None)</a></code></p>
<p class="firstline">Analyzes multiple conversations in a single request.</p>
<p class="toc_element">
  <code><a href="#calculateStats">calculateStats(location, filter=None, x__xgafv=None)</a></code></p>
<p class="firstline">Gets conversation statistics.</p>
<p class="toc_element">
  <code><a href="#close">close()</a></code></p>
<p class="firstline">Close httplib2 connections.</p>
<p class="toc_element">
  <code><a href="#create">create(parent, body=None, conversationId=None, x__xgafv=None)</a></code></p>
<p class="firstline">Creates a conversation.</p>
<p class="toc_element">
  <code><a href="#delete">delete(name, force=None, x__xgafv=None)</a></code></p>
<p class="firstline">Deletes a conversation.</p>
<p class="toc_element">
  <code><a href="#get">get(name, view=None, x__xgafv=None)</a></code></p>
<p class="firstline">Gets a conversation.</p>
<p class="toc_element">
  <code><a href="#ingest">ingest(parent, body=None, x__xgafv=None)</a></code></p>
<p class="firstline">Imports conversations and processes them according to the user's configuration.</p>
<p class="toc_element">
  <code><a href="#list">list(parent, filter=None, pageSize=None, pageToken=None, view=None, x__xgafv=None)</a></code></p>
<p class="firstline">Lists conversations.</p>
<p class="toc_element">
  <code><a href="#list_next">list_next()</a></code></p>
<p class="firstline">Retrieves the next page of results.</p>
<p class="toc_element">
  <code><a href="#patch">patch(name, body=None, updateMask=None, x__xgafv=None)</a></code></p>
<p class="firstline">Updates a conversation.</p>
<h3>Method Details</h3>
<div class="method">
    <code class="details" id="bulkAnalyze">bulkAnalyze(parent, body=None, x__xgafv=None)</code>
  <pre>Analyzes multiple conversations in a single request.

Args:
  parent: string, Required. The parent resource to create analyses in. (required)
  body: object, The request body.
    The object takes the form of:

{ # The request to analyze conversations in bulk.
  &quot;analysisPercentage&quot;: 3.14, # Required. Percentage of selected conversation to analyze, between [0, 100].
  &quot;annotatorSelector&quot;: { # Selector of all available annotators and phrase matchers to run. # To select the annotators to run and the phrase matchers to use (if any). If not specified, all annotators will be run.
    &quot;issueModels&quot;: [ # The issue model to run. If not provided, the most recently deployed topic model will be used. The provided issue model will only be used for inference if the issue model is deployed and if run_issue_model_annotator is set to true. If more than one issue model is provided, only the first provided issue model will be used for inference.
      &quot;A String&quot;,
    ],
    &quot;phraseMatchers&quot;: [ # The list of phrase matchers to run. If not provided, all active phrase matchers will be used. If inactive phrase matchers are provided, they will not be used. Phrase matchers will be run only if run_phrase_matcher_annotator is set to true. Format: projects/{project}/locations/{location}/phraseMatchers/{phrase_matcher}
      &quot;A String&quot;,
    ],
    &quot;runEntityAnnotator&quot;: True or False, # Whether to run the entity annotator.
    &quot;runIntentAnnotator&quot;: True or False, # Whether to run the intent annotator.
    &quot;runInterruptionAnnotator&quot;: True or False, # Whether to run the interruption annotator.
    &quot;runIssueModelAnnotator&quot;: True or False, # Whether to run the issue model annotator. A model should have already been deployed for this to take effect.
    &quot;runPhraseMatcherAnnotator&quot;: True or False, # Whether to run the active phrase matcher annotator(s).
    &quot;runSentimentAnnotator&quot;: True or False, # Whether to run the sentiment annotator.
    &quot;runSilenceAnnotator&quot;: True or False, # Whether to run the silence annotator.
  },
  &quot;filter&quot;: &quot;A String&quot;, # Required. Filter used to select the subset of conversations to analyze.
  &quot;parent&quot;: &quot;A String&quot;, # Required. The parent resource to create analyses in.
}

  x__xgafv: string, V1 error format.
    Allowed values
      1 - v1 error format
      2 - v2 error format

Returns:
  An object of the form:

    { # This resource represents a long-running operation that is the result of a network API call.
  &quot;done&quot;: True or False, # If the value is `false`, it means the operation is still in progress. If `true`, the operation is completed, and either `error` or `response` is available.
  &quot;error&quot;: { # The `Status` type defines a logical error model that is suitable for different programming environments, including REST APIs and RPC APIs. It is used by [gRPC](https://github.com/grpc). Each `Status` message contains three pieces of data: error code, error message, and error details. You can find out more about this error model and how to work with it in the [API Design Guide](https://cloud.google.com/apis/design/errors). # The error result of the operation in case of failure or cancellation.
    &quot;code&quot;: 42, # The status code, which should be an enum value of google.rpc.Code.
    &quot;details&quot;: [ # A list of messages that carry the error details. There is a common set of message types for APIs to use.
      {
        &quot;a_key&quot;: &quot;&quot;, # Properties of the object. Contains field @type with type URL.
      },
    ],
    &quot;message&quot;: &quot;A String&quot;, # A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client.
  },
  &quot;metadata&quot;: { # Service-specific metadata associated with the operation. It typically contains progress information and common metadata such as create time. Some services might not provide such metadata. Any method that returns a long-running operation should document the metadata type, if any.
    &quot;a_key&quot;: &quot;&quot;, # Properties of the object. Contains field @type with type URL.
  },
  &quot;name&quot;: &quot;A String&quot;, # The server-assigned name, which is only unique within the same service that originally returns it. If you use the default HTTP mapping, the `name` should be a resource name ending with `operations/{unique_id}`.
  &quot;response&quot;: { # The normal response of the operation in case of success. If the original method returns no data on success, such as `Delete`, the response is `google.protobuf.Empty`. If the original method is standard `Get`/`Create`/`Update`, the response should be the resource. For other methods, the response should have the type `XxxResponse`, where `Xxx` is the original method name. For example, if the original method name is `TakeSnapshot()`, the inferred response type is `TakeSnapshotResponse`.
    &quot;a_key&quot;: &quot;&quot;, # Properties of the object. Contains field @type with type URL.
  },
}</pre>
</div>

<div class="method">
    <code class="details" id="calculateStats">calculateStats(location, filter=None, x__xgafv=None)</code>
  <pre>Gets conversation statistics.

Args:
  location: string, Required. The location of the conversations. (required)
  filter: string, A filter to reduce results to a specific subset. This field is useful for getting statistics about conversations with specific properties.
  x__xgafv: string, V1 error format.
    Allowed values
      1 - v1 error format
      2 - v2 error format

Returns:
  An object of the form:

    { # The response for calculating conversation statistics.
  &quot;averageDuration&quot;: &quot;A String&quot;, # The average duration of all conversations. The average is calculated using only conversations that have a time duration.
  &quot;averageTurnCount&quot;: 42, # The average number of turns per conversation.
  &quot;conversationCount&quot;: 42, # The total number of conversations.
  &quot;conversationCountTimeSeries&quot;: { # A time series representing conversations over time. # A time series representing the count of conversations created over time that match that requested filter criteria.
    &quot;intervalDuration&quot;: &quot;A String&quot;, # The duration of each interval.
    &quot;points&quot;: [ # An ordered list of intervals from earliest to latest, where each interval represents the number of conversations that transpired during the time window.
      { # A single interval in a time series.
        &quot;conversationCount&quot;: 42, # The number of conversations created in this interval.
        &quot;startTime&quot;: &quot;A String&quot;, # The start time of this interval.
      },
    ],
  },
  &quot;customHighlighterMatches&quot;: { # A map associating each custom highlighter resource name with its respective number of matches in the set of conversations.
    &quot;a_key&quot;: 42,
  },
  &quot;issueMatches&quot;: { # A map associating each issue resource name with its respective number of matches in the set of conversations. Key has the format: `projects//locations//issueModels//issues/` Deprecated, use `issue_matches_stats` field instead.
    &quot;a_key&quot;: 42,
  },
  &quot;issueMatchesStats&quot;: { # A map associating each issue resource name with its respective number of matches in the set of conversations. Key has the format: `projects//locations//issueModels//issues/`
    &quot;a_key&quot;: { # Aggregated statistics about an issue.
      &quot;displayName&quot;: &quot;A String&quot;, # Display name of the issue.
      &quot;issue&quot;: &quot;A String&quot;, # Issue resource. Format: projects/{project}/locations/{location}/issueModels/{issue_model}/issues/{issue}
      &quot;labeledConversationsCount&quot;: &quot;A String&quot;, # Number of conversations attached to the issue at this point in time.
    },
  },
  &quot;smartHighlighterMatches&quot;: { # A map associating each smart highlighter display name with its respective number of matches in the set of conversations.
    &quot;a_key&quot;: 42,
  },
}</pre>
</div>

<div class="method">
    <code class="details" id="close">close()</code>
  <pre>Close httplib2 connections.</pre>
</div>

<div class="method">
    <code class="details" id="create">create(parent, body=None, conversationId=None, x__xgafv=None)</code>
  <pre>Creates a conversation.

Args:
  parent: string, Required. The parent resource of the conversation. (required)
  body: object, The request body.
    The object takes the form of:

{ # The conversation resource.
  &quot;agentId&quot;: &quot;A String&quot;, # An opaque, user-specified string representing the human agent who handled the conversation.
  &quot;callMetadata&quot;: { # Call-specific metadata. # Call-specific metadata.
    &quot;agentChannel&quot;: 42, # The audio channel that contains the agent.
    &quot;customerChannel&quot;: 42, # The audio channel that contains the customer.
  },
  &quot;createTime&quot;: &quot;A String&quot;, # Output only. The time at which the conversation was created.
  &quot;dataSource&quot;: { # The conversation source, which is a combination of transcript and audio. # The source of the audio and transcription for the conversation.
    &quot;dialogflowSource&quot;: { # A Dialogflow source of conversation data. # The source when the conversation comes from Dialogflow.
      &quot;audioUri&quot;: &quot;A String&quot;, # Cloud Storage URI that points to a file that contains the conversation audio.
      &quot;dialogflowConversation&quot;: &quot;A String&quot;, # Output only. The name of the Dialogflow conversation that this conversation resource is derived from. Format: projects/{project}/locations/{location}/conversations/{conversation}
    },
    &quot;gcsSource&quot;: { # A Cloud Storage source of conversation data. # A Cloud Storage location specification for the audio and transcript.
      &quot;audioUri&quot;: &quot;A String&quot;, # Cloud Storage URI that points to a file that contains the conversation audio.
      &quot;transcriptUri&quot;: &quot;A String&quot;, # Immutable. Cloud Storage URI that points to a file that contains the conversation transcript.
    },
  },
  &quot;dialogflowIntents&quot;: { # Output only. All the matched Dialogflow intents in the call. The key corresponds to a Dialogflow intent, format: projects/{project}/agent/{agent}/intents/{intent}
    &quot;a_key&quot;: { # The data for a Dialogflow intent. Represents a detected intent in the conversation, e.g. MAKES_PROMISE.
      &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the intent.
    },
  },
  &quot;duration&quot;: &quot;A String&quot;, # Output only. The duration of the conversation.
  &quot;expireTime&quot;: &quot;A String&quot;, # The time at which this conversation should expire. After this time, the conversation data and any associated analyses will be deleted.
  &quot;labels&quot;: { # A map for the user to specify any custom fields. A maximum of 20 labels per conversation is allowed, with a maximum of 256 characters per entry.
    &quot;a_key&quot;: &quot;A String&quot;,
  },
  &quot;languageCode&quot;: &quot;A String&quot;, # A user-specified language code for the conversation.
  &quot;latestAnalysis&quot;: { # The analysis resource. # Output only. The conversation&#x27;s latest analysis, if one exists.
    &quot;analysisResult&quot;: { # The result of an analysis. # Output only. The result of the analysis, which is populated when the analysis finishes.
      &quot;callAnalysisMetadata&quot;: { # Call-specific metadata created during analysis. # Call-specific metadata created by the analysis.
        &quot;annotations&quot;: [ # A list of call annotations that apply to this call.
          { # A piece of metadata that applies to a window of a call.
            &quot;annotationEndBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation ends, inclusive.
              &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
              &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
            },
            &quot;annotationStartBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation starts, inclusive.
              &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
              &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
            },
            &quot;channelTag&quot;: 42, # The channel of the audio where the annotation occurs. For single-channel audio, this field is not populated.
            &quot;entityMentionData&quot;: { # The data for an entity mention annotation. This represents a mention of an `Entity` in the conversation. # Data specifying an entity mention.
              &quot;entityUniqueId&quot;: &quot;A String&quot;, # The key of this entity in conversation entities. Can be used to retrieve the exact `Entity` this mention is attached to.
              &quot;sentiment&quot;: { # The data for a sentiment annotation. # Sentiment expressed for this mention of the entity.
                &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
                &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
              },
              &quot;type&quot;: &quot;A String&quot;, # The type of the entity mention.
            },
            &quot;holdData&quot;: { # The data for a hold annotation. # Data specifying a hold.
            },
            &quot;intentMatchData&quot;: { # The data for an intent match. Represents an intent match for a text segment in the conversation. A text segment can be part of a sentence, a complete sentence, or an utterance with multiple sentences. # Data specifying an intent match.
              &quot;intentUniqueId&quot;: &quot;A String&quot;, # The id of the matched intent. Can be used to retrieve the corresponding intent information.
            },
            &quot;interruptionData&quot;: { # The data for an interruption annotation. # Data specifying an interruption.
            },
            &quot;issueMatchData&quot;: { # The data for an issue match annotation. # Data specifying an issue match.
              &quot;issueAssignment&quot;: { # Information about the issue. # Information about the issue&#x27;s assignment.
                &quot;displayName&quot;: &quot;A String&quot;, # Immutable. Display name of the assigned issue. This field is set at time of analyis and immutable since then.
                &quot;issue&quot;: &quot;A String&quot;, # Resource name of the assigned issue.
                &quot;score&quot;: 3.14, # Score indicating the likelihood of the issue assignment. currently bounded on [0,1].
              },
            },
            &quot;phraseMatchData&quot;: { # The data for a matched phrase matcher. Represents information identifying a phrase matcher for a given match. # Data specifying a phrase match.
              &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the phrase matcher.
              &quot;phraseMatcher&quot;: &quot;A String&quot;, # The unique identifier (the resource name) of the phrase matcher.
            },
            &quot;sentimentData&quot;: { # The data for a sentiment annotation. # Data specifying sentiment.
              &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
              &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
            },
            &quot;silenceData&quot;: { # The data for a silence annotation. # Data specifying silence.
            },
          },
        ],
        &quot;entities&quot;: { # All the entities in the call.
          &quot;a_key&quot;: { # The data for an entity annotation. Represents a phrase in the conversation that is a known entity, such as a person, an organization, or location.
            &quot;displayName&quot;: &quot;A String&quot;, # The representative name for the entity.
            &quot;metadata&quot;: { # Metadata associated with the entity. For most entity types, the metadata is a Wikipedia URL (`wikipedia_url`) and Knowledge Graph MID (`mid`), if they are available. For the metadata associated with other entity types, see the Type table below.
              &quot;a_key&quot;: &quot;A String&quot;,
            },
            &quot;salience&quot;: 3.14, # The salience score associated with the entity in the [0, 1.0] range. The salience score for an entity provides information about the importance or centrality of that entity to the entire document text. Scores closer to 0 are less salient, while scores closer to 1.0 are highly salient.
            &quot;sentiment&quot;: { # The data for a sentiment annotation. # The aggregate sentiment expressed for this entity in the conversation.
              &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
              &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
            },
            &quot;type&quot;: &quot;A String&quot;, # The entity type.
          },
        },
        &quot;intents&quot;: { # All the matched intents in the call.
          &quot;a_key&quot;: { # The data for an intent. Represents a detected intent in the conversation, for example MAKES_PROMISE.
            &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the intent.
            &quot;id&quot;: &quot;A String&quot;, # The unique identifier of the intent.
          },
        },
        &quot;issueModelResult&quot;: { # Issue Modeling result on a conversation. # Overall conversation-level issue modeling result.
          &quot;issueModel&quot;: &quot;A String&quot;, # Issue model that generates the result. Format: projects/{project}/locations/{location}/issueModels/{issue_model}
          &quot;issues&quot;: [ # All the matched issues.
            { # Information about the issue.
              &quot;displayName&quot;: &quot;A String&quot;, # Immutable. Display name of the assigned issue. This field is set at time of analyis and immutable since then.
              &quot;issue&quot;: &quot;A String&quot;, # Resource name of the assigned issue.
              &quot;score&quot;: 3.14, # Score indicating the likelihood of the issue assignment. currently bounded on [0,1].
            },
          ],
        },
        &quot;phraseMatchers&quot;: { # All the matched phrase matchers in the call.
          &quot;a_key&quot;: { # The data for a matched phrase matcher. Represents information identifying a phrase matcher for a given match.
            &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the phrase matcher.
            &quot;phraseMatcher&quot;: &quot;A String&quot;, # The unique identifier (the resource name) of the phrase matcher.
          },
        },
        &quot;sentiments&quot;: [ # Overall conversation-level sentiment for each channel of the call.
          { # One channel of conversation-level sentiment data.
            &quot;channelTag&quot;: 42, # The channel of the audio that the data applies to.
            &quot;sentimentData&quot;: { # The data for a sentiment annotation. # Data specifying sentiment.
              &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
              &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
            },
          },
        ],
      },
      &quot;endTime&quot;: &quot;A String&quot;, # The time at which the analysis ended.
    },
    &quot;annotatorSelector&quot;: { # Selector of all available annotators and phrase matchers to run. # To select the annotators to run and the phrase matchers to use (if any). If not specified, all annotators will be run.
      &quot;issueModels&quot;: [ # The issue model to run. If not provided, the most recently deployed topic model will be used. The provided issue model will only be used for inference if the issue model is deployed and if run_issue_model_annotator is set to true. If more than one issue model is provided, only the first provided issue model will be used for inference.
        &quot;A String&quot;,
      ],
      &quot;phraseMatchers&quot;: [ # The list of phrase matchers to run. If not provided, all active phrase matchers will be used. If inactive phrase matchers are provided, they will not be used. Phrase matchers will be run only if run_phrase_matcher_annotator is set to true. Format: projects/{project}/locations/{location}/phraseMatchers/{phrase_matcher}
        &quot;A String&quot;,
      ],
      &quot;runEntityAnnotator&quot;: True or False, # Whether to run the entity annotator.
      &quot;runIntentAnnotator&quot;: True or False, # Whether to run the intent annotator.
      &quot;runInterruptionAnnotator&quot;: True or False, # Whether to run the interruption annotator.
      &quot;runIssueModelAnnotator&quot;: True or False, # Whether to run the issue model annotator. A model should have already been deployed for this to take effect.
      &quot;runPhraseMatcherAnnotator&quot;: True or False, # Whether to run the active phrase matcher annotator(s).
      &quot;runSentimentAnnotator&quot;: True or False, # Whether to run the sentiment annotator.
      &quot;runSilenceAnnotator&quot;: True or False, # Whether to run the silence annotator.
    },
    &quot;createTime&quot;: &quot;A String&quot;, # Output only. The time at which the analysis was created, which occurs when the long-running operation completes.
    &quot;name&quot;: &quot;A String&quot;, # Immutable. The resource name of the analysis. Format: projects/{project}/locations/{location}/conversations/{conversation}/analyses/{analysis}
    &quot;requestTime&quot;: &quot;A String&quot;, # Output only. The time at which the analysis was requested.
  },
  &quot;medium&quot;: &quot;A String&quot;, # Immutable. The conversation medium, if unspecified will default to PHONE_CALL.
  &quot;name&quot;: &quot;A String&quot;, # Immutable. The resource name of the conversation. Format: projects/{project}/locations/{location}/conversations/{conversation}
  &quot;obfuscatedUserId&quot;: &quot;A String&quot;, # Obfuscated user ID which the customer sent to us.
  &quot;runtimeAnnotations&quot;: [ # Output only. The annotations that were generated during the customer and agent interaction.
    { # An annotation that was generated during the customer and agent interaction.
      &quot;annotationId&quot;: &quot;A String&quot;, # The unique identifier of the annotation. Format: projects/{project}/locations/{location}/conversationDatasets/{dataset}/conversationDataItems/{data_item}/conversationAnnotations/{annotation}
      &quot;answerFeedback&quot;: { # The feedback that the customer has about a certain answer in the conversation. # The feedback that the customer has about the answer in `data`.
        &quot;clicked&quot;: True or False, # Indicates whether an answer or item was clicked by the human agent.
        &quot;correctnessLevel&quot;: &quot;A String&quot;, # The correctness level of an answer.
        &quot;displayed&quot;: True or False, # Indicates whether an answer or item was displayed to the human agent in the agent desktop UI.
      },
      &quot;articleSuggestion&quot;: { # Agent Assist Article Suggestion data. # Agent Assist Article Suggestion data.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this article is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the Article Suggestion and the document that it originates from.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
        &quot;source&quot;: &quot;A String&quot;, # The knowledge document that this answer was extracted from. Format: projects/{project}/knowledgeBases/{knowledge_base}/documents/{document}
        &quot;title&quot;: &quot;A String&quot;, # Article title.
        &quot;uri&quot;: &quot;A String&quot;, # Article URI.
      },
      &quot;createTime&quot;: &quot;A String&quot;, # The time at which this annotation was created.
      &quot;dialogflowInteraction&quot;: { # Dialogflow interaction data. # Dialogflow interaction data.
        &quot;confidence&quot;: 3.14, # The confidence of the match ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;dialogflowIntentId&quot;: &quot;A String&quot;, # The Dialogflow intent resource path. Format: projects/{project}/agent/{agent}/intents/{intent}
      },
      &quot;endBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation ends, inclusive.
        &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
        &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
      },
      &quot;faqAnswer&quot;: { # Agent Assist frequently-asked-question answer data. # Agent Assist FAQ answer data.
        &quot;answer&quot;: &quot;A String&quot;, # The piece of text from the `source` knowledge base document.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this answer is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the FAQ answer and the document that it originates from.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
        &quot;question&quot;: &quot;A String&quot;, # The corresponding FAQ question.
        &quot;source&quot;: &quot;A String&quot;, # The knowledge document that this answer was extracted from. Format: projects/{project}/knowledgeBases/{knowledge_base}/documents/{document}.
      },
      &quot;smartComposeSuggestion&quot;: { # Agent Assist Smart Compose suggestion data. # Agent Assist Smart Compose suggestion data.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this suggestion is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the Smart Compose suggestion and the document from which it originates.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
        &quot;suggestion&quot;: &quot;A String&quot;, # The content of the suggestion.
      },
      &quot;smartReply&quot;: { # Agent Assist Smart Reply data. # Agent Assist Smart Reply data.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this reply is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the Smart Reply and the document from which it originates.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
        &quot;reply&quot;: &quot;A String&quot;, # The content of the reply.
      },
      &quot;startBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation starts, inclusive.
        &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
        &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
      },
    },
  ],
  &quot;startTime&quot;: &quot;A String&quot;, # The time at which the conversation started.
  &quot;transcript&quot;: { # A message representing the transcript of a conversation. # Output only. The conversation transcript.
    &quot;transcriptSegments&quot;: [ # A list of sequential transcript segments that comprise the conversation.
      { # A segment of a full transcript.
        &quot;channelTag&quot;: 42, # For conversations derived from multi-channel audio, this is the channel number corresponding to the audio from that channel. For audioChannelCount = N, its output values can range from &#x27;1&#x27; to &#x27;N&#x27;. A channel tag of 0 indicates that the audio is mono.
        &quot;confidence&quot;: 3.14, # A confidence estimate between 0.0 and 1.0 of the fidelity of this segment. A default value of 0.0 indicates that the value is unset.
        &quot;dialogflowSegmentMetadata&quot;: { # Metadata from Dialogflow relating to the current transcript segment. # CCAI metadata relating to the current transcript segment.
          &quot;smartReplyAllowlistCovered&quot;: True or False, # Whether the transcript segment was covered under the configured smart reply allowlist in Agent Assist.
        },
        &quot;languageCode&quot;: &quot;A String&quot;, # The language code of this segment as a [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag. Example: &quot;en-US&quot;.
        &quot;messageTime&quot;: &quot;A String&quot;, # The time that the message occurred, if provided.
        &quot;segmentParticipant&quot;: { # The call participant speaking for a given utterance. # The participant of this segment.
          &quot;dialogflowParticipant&quot;: &quot;A String&quot;, # Deprecated. Use `dialogflow_participant_name` instead. The name of the Dialogflow participant. Format: projects/{project}/locations/{location}/conversations/{conversation}/participants/{participant}
          &quot;dialogflowParticipantName&quot;: &quot;A String&quot;, # The name of the participant provided by Dialogflow. Format: projects/{project}/locations/{location}/conversations/{conversation}/participants/{participant}
          &quot;obfuscatedExternalUserId&quot;: &quot;A String&quot;, # Obfuscated user ID from Dialogflow.
          &quot;role&quot;: &quot;A String&quot;, # The role of the participant.
          &quot;userId&quot;: &quot;A String&quot;, # A user-specified ID representing the participant.
        },
        &quot;sentiment&quot;: { # The data for a sentiment annotation. # The sentiment for this transcript segment.
          &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
          &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
        },
        &quot;text&quot;: &quot;A String&quot;, # The text of this segment.
        &quot;words&quot;: [ # A list of the word-specific information for each word in the segment.
          { # Word-level info for words in a transcript.
            &quot;confidence&quot;: 3.14, # A confidence estimate between 0.0 and 1.0 of the fidelity of this word. A default value of 0.0 indicates that the value is unset.
            &quot;endOffset&quot;: &quot;A String&quot;, # Time offset of the end of this word relative to the beginning of the total conversation.
            &quot;startOffset&quot;: &quot;A String&quot;, # Time offset of the start of this word relative to the beginning of the total conversation.
            &quot;word&quot;: &quot;A String&quot;, # The word itself. Includes punctuation marks that surround the word.
          },
        ],
      },
    ],
  },
  &quot;ttl&quot;: &quot;A String&quot;, # Input only. The TTL for this resource. If specified, then this TTL will be used to calculate the expire time.
  &quot;turnCount&quot;: 42, # Output only. The number of turns in the conversation.
  &quot;updateTime&quot;: &quot;A String&quot;, # Output only. The most recent time at which the conversation was updated.
}

  conversationId: string, A unique ID for the new conversation. This ID will become the final component of the conversation&#x27;s resource name. If no ID is specified, a server-generated ID will be used. This value should be 4-64 characters and must match the regular expression `^[a-z0-9-]{4,64}$`. Valid characters are `a-z-`
  x__xgafv: string, V1 error format.
    Allowed values
      1 - v1 error format
      2 - v2 error format

Returns:
  An object of the form:

    { # The conversation resource.
  &quot;agentId&quot;: &quot;A String&quot;, # An opaque, user-specified string representing the human agent who handled the conversation.
  &quot;callMetadata&quot;: { # Call-specific metadata. # Call-specific metadata.
    &quot;agentChannel&quot;: 42, # The audio channel that contains the agent.
    &quot;customerChannel&quot;: 42, # The audio channel that contains the customer.
  },
  &quot;createTime&quot;: &quot;A String&quot;, # Output only. The time at which the conversation was created.
  &quot;dataSource&quot;: { # The conversation source, which is a combination of transcript and audio. # The source of the audio and transcription for the conversation.
    &quot;dialogflowSource&quot;: { # A Dialogflow source of conversation data. # The source when the conversation comes from Dialogflow.
      &quot;audioUri&quot;: &quot;A String&quot;, # Cloud Storage URI that points to a file that contains the conversation audio.
      &quot;dialogflowConversation&quot;: &quot;A String&quot;, # Output only. The name of the Dialogflow conversation that this conversation resource is derived from. Format: projects/{project}/locations/{location}/conversations/{conversation}
    },
    &quot;gcsSource&quot;: { # A Cloud Storage source of conversation data. # A Cloud Storage location specification for the audio and transcript.
      &quot;audioUri&quot;: &quot;A String&quot;, # Cloud Storage URI that points to a file that contains the conversation audio.
      &quot;transcriptUri&quot;: &quot;A String&quot;, # Immutable. Cloud Storage URI that points to a file that contains the conversation transcript.
    },
  },
  &quot;dialogflowIntents&quot;: { # Output only. All the matched Dialogflow intents in the call. The key corresponds to a Dialogflow intent, format: projects/{project}/agent/{agent}/intents/{intent}
    &quot;a_key&quot;: { # The data for a Dialogflow intent. Represents a detected intent in the conversation, e.g. MAKES_PROMISE.
      &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the intent.
    },
  },
  &quot;duration&quot;: &quot;A String&quot;, # Output only. The duration of the conversation.
  &quot;expireTime&quot;: &quot;A String&quot;, # The time at which this conversation should expire. After this time, the conversation data and any associated analyses will be deleted.
  &quot;labels&quot;: { # A map for the user to specify any custom fields. A maximum of 20 labels per conversation is allowed, with a maximum of 256 characters per entry.
    &quot;a_key&quot;: &quot;A String&quot;,
  },
  &quot;languageCode&quot;: &quot;A String&quot;, # A user-specified language code for the conversation.
  &quot;latestAnalysis&quot;: { # The analysis resource. # Output only. The conversation&#x27;s latest analysis, if one exists.
    &quot;analysisResult&quot;: { # The result of an analysis. # Output only. The result of the analysis, which is populated when the analysis finishes.
      &quot;callAnalysisMetadata&quot;: { # Call-specific metadata created during analysis. # Call-specific metadata created by the analysis.
        &quot;annotations&quot;: [ # A list of call annotations that apply to this call.
          { # A piece of metadata that applies to a window of a call.
            &quot;annotationEndBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation ends, inclusive.
              &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
              &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
            },
            &quot;annotationStartBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation starts, inclusive.
              &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
              &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
            },
            &quot;channelTag&quot;: 42, # The channel of the audio where the annotation occurs. For single-channel audio, this field is not populated.
            &quot;entityMentionData&quot;: { # The data for an entity mention annotation. This represents a mention of an `Entity` in the conversation. # Data specifying an entity mention.
              &quot;entityUniqueId&quot;: &quot;A String&quot;, # The key of this entity in conversation entities. Can be used to retrieve the exact `Entity` this mention is attached to.
              &quot;sentiment&quot;: { # The data for a sentiment annotation. # Sentiment expressed for this mention of the entity.
                &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
                &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
              },
              &quot;type&quot;: &quot;A String&quot;, # The type of the entity mention.
            },
            &quot;holdData&quot;: { # The data for a hold annotation. # Data specifying a hold.
            },
            &quot;intentMatchData&quot;: { # The data for an intent match. Represents an intent match for a text segment in the conversation. A text segment can be part of a sentence, a complete sentence, or an utterance with multiple sentences. # Data specifying an intent match.
              &quot;intentUniqueId&quot;: &quot;A String&quot;, # The id of the matched intent. Can be used to retrieve the corresponding intent information.
            },
            &quot;interruptionData&quot;: { # The data for an interruption annotation. # Data specifying an interruption.
            },
            &quot;issueMatchData&quot;: { # The data for an issue match annotation. # Data specifying an issue match.
              &quot;issueAssignment&quot;: { # Information about the issue. # Information about the issue&#x27;s assignment.
                &quot;displayName&quot;: &quot;A String&quot;, # Immutable. Display name of the assigned issue. This field is set at time of analyis and immutable since then.
                &quot;issue&quot;: &quot;A String&quot;, # Resource name of the assigned issue.
                &quot;score&quot;: 3.14, # Score indicating the likelihood of the issue assignment. currently bounded on [0,1].
              },
            },
            &quot;phraseMatchData&quot;: { # The data for a matched phrase matcher. Represents information identifying a phrase matcher for a given match. # Data specifying a phrase match.
              &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the phrase matcher.
              &quot;phraseMatcher&quot;: &quot;A String&quot;, # The unique identifier (the resource name) of the phrase matcher.
            },
            &quot;sentimentData&quot;: { # The data for a sentiment annotation. # Data specifying sentiment.
              &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
              &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
            },
            &quot;silenceData&quot;: { # The data for a silence annotation. # Data specifying silence.
            },
          },
        ],
        &quot;entities&quot;: { # All the entities in the call.
          &quot;a_key&quot;: { # The data for an entity annotation. Represents a phrase in the conversation that is a known entity, such as a person, an organization, or location.
            &quot;displayName&quot;: &quot;A String&quot;, # The representative name for the entity.
            &quot;metadata&quot;: { # Metadata associated with the entity. For most entity types, the metadata is a Wikipedia URL (`wikipedia_url`) and Knowledge Graph MID (`mid`), if they are available. For the metadata associated with other entity types, see the Type table below.
              &quot;a_key&quot;: &quot;A String&quot;,
            },
            &quot;salience&quot;: 3.14, # The salience score associated with the entity in the [0, 1.0] range. The salience score for an entity provides information about the importance or centrality of that entity to the entire document text. Scores closer to 0 are less salient, while scores closer to 1.0 are highly salient.
            &quot;sentiment&quot;: { # The data for a sentiment annotation. # The aggregate sentiment expressed for this entity in the conversation.
              &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
              &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
            },
            &quot;type&quot;: &quot;A String&quot;, # The entity type.
          },
        },
        &quot;intents&quot;: { # All the matched intents in the call.
          &quot;a_key&quot;: { # The data for an intent. Represents a detected intent in the conversation, for example MAKES_PROMISE.
            &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the intent.
            &quot;id&quot;: &quot;A String&quot;, # The unique identifier of the intent.
          },
        },
        &quot;issueModelResult&quot;: { # Issue Modeling result on a conversation. # Overall conversation-level issue modeling result.
          &quot;issueModel&quot;: &quot;A String&quot;, # Issue model that generates the result. Format: projects/{project}/locations/{location}/issueModels/{issue_model}
          &quot;issues&quot;: [ # All the matched issues.
            { # Information about the issue.
              &quot;displayName&quot;: &quot;A String&quot;, # Immutable. Display name of the assigned issue. This field is set at time of analyis and immutable since then.
              &quot;issue&quot;: &quot;A String&quot;, # Resource name of the assigned issue.
              &quot;score&quot;: 3.14, # Score indicating the likelihood of the issue assignment. currently bounded on [0,1].
            },
          ],
        },
        &quot;phraseMatchers&quot;: { # All the matched phrase matchers in the call.
          &quot;a_key&quot;: { # The data for a matched phrase matcher. Represents information identifying a phrase matcher for a given match.
            &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the phrase matcher.
            &quot;phraseMatcher&quot;: &quot;A String&quot;, # The unique identifier (the resource name) of the phrase matcher.
          },
        },
        &quot;sentiments&quot;: [ # Overall conversation-level sentiment for each channel of the call.
          { # One channel of conversation-level sentiment data.
            &quot;channelTag&quot;: 42, # The channel of the audio that the data applies to.
            &quot;sentimentData&quot;: { # The data for a sentiment annotation. # Data specifying sentiment.
              &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
              &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
            },
          },
        ],
      },
      &quot;endTime&quot;: &quot;A String&quot;, # The time at which the analysis ended.
    },
    &quot;annotatorSelector&quot;: { # Selector of all available annotators and phrase matchers to run. # To select the annotators to run and the phrase matchers to use (if any). If not specified, all annotators will be run.
      &quot;issueModels&quot;: [ # The issue model to run. If not provided, the most recently deployed topic model will be used. The provided issue model will only be used for inference if the issue model is deployed and if run_issue_model_annotator is set to true. If more than one issue model is provided, only the first provided issue model will be used for inference.
        &quot;A String&quot;,
      ],
      &quot;phraseMatchers&quot;: [ # The list of phrase matchers to run. If not provided, all active phrase matchers will be used. If inactive phrase matchers are provided, they will not be used. Phrase matchers will be run only if run_phrase_matcher_annotator is set to true. Format: projects/{project}/locations/{location}/phraseMatchers/{phrase_matcher}
        &quot;A String&quot;,
      ],
      &quot;runEntityAnnotator&quot;: True or False, # Whether to run the entity annotator.
      &quot;runIntentAnnotator&quot;: True or False, # Whether to run the intent annotator.
      &quot;runInterruptionAnnotator&quot;: True or False, # Whether to run the interruption annotator.
      &quot;runIssueModelAnnotator&quot;: True or False, # Whether to run the issue model annotator. A model should have already been deployed for this to take effect.
      &quot;runPhraseMatcherAnnotator&quot;: True or False, # Whether to run the active phrase matcher annotator(s).
      &quot;runSentimentAnnotator&quot;: True or False, # Whether to run the sentiment annotator.
      &quot;runSilenceAnnotator&quot;: True or False, # Whether to run the silence annotator.
    },
    &quot;createTime&quot;: &quot;A String&quot;, # Output only. The time at which the analysis was created, which occurs when the long-running operation completes.
    &quot;name&quot;: &quot;A String&quot;, # Immutable. The resource name of the analysis. Format: projects/{project}/locations/{location}/conversations/{conversation}/analyses/{analysis}
    &quot;requestTime&quot;: &quot;A String&quot;, # Output only. The time at which the analysis was requested.
  },
  &quot;medium&quot;: &quot;A String&quot;, # Immutable. The conversation medium, if unspecified will default to PHONE_CALL.
  &quot;name&quot;: &quot;A String&quot;, # Immutable. The resource name of the conversation. Format: projects/{project}/locations/{location}/conversations/{conversation}
  &quot;obfuscatedUserId&quot;: &quot;A String&quot;, # Obfuscated user ID which the customer sent to us.
  &quot;runtimeAnnotations&quot;: [ # Output only. The annotations that were generated during the customer and agent interaction.
    { # An annotation that was generated during the customer and agent interaction.
      &quot;annotationId&quot;: &quot;A String&quot;, # The unique identifier of the annotation. Format: projects/{project}/locations/{location}/conversationDatasets/{dataset}/conversationDataItems/{data_item}/conversationAnnotations/{annotation}
      &quot;answerFeedback&quot;: { # The feedback that the customer has about a certain answer in the conversation. # The feedback that the customer has about the answer in `data`.
        &quot;clicked&quot;: True or False, # Indicates whether an answer or item was clicked by the human agent.
        &quot;correctnessLevel&quot;: &quot;A String&quot;, # The correctness level of an answer.
        &quot;displayed&quot;: True or False, # Indicates whether an answer or item was displayed to the human agent in the agent desktop UI.
      },
      &quot;articleSuggestion&quot;: { # Agent Assist Article Suggestion data. # Agent Assist Article Suggestion data.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this article is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the Article Suggestion and the document that it originates from.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
        &quot;source&quot;: &quot;A String&quot;, # The knowledge document that this answer was extracted from. Format: projects/{project}/knowledgeBases/{knowledge_base}/documents/{document}
        &quot;title&quot;: &quot;A String&quot;, # Article title.
        &quot;uri&quot;: &quot;A String&quot;, # Article URI.
      },
      &quot;createTime&quot;: &quot;A String&quot;, # The time at which this annotation was created.
      &quot;dialogflowInteraction&quot;: { # Dialogflow interaction data. # Dialogflow interaction data.
        &quot;confidence&quot;: 3.14, # The confidence of the match ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;dialogflowIntentId&quot;: &quot;A String&quot;, # The Dialogflow intent resource path. Format: projects/{project}/agent/{agent}/intents/{intent}
      },
      &quot;endBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation ends, inclusive.
        &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
        &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
      },
      &quot;faqAnswer&quot;: { # Agent Assist frequently-asked-question answer data. # Agent Assist FAQ answer data.
        &quot;answer&quot;: &quot;A String&quot;, # The piece of text from the `source` knowledge base document.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this answer is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the FAQ answer and the document that it originates from.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
        &quot;question&quot;: &quot;A String&quot;, # The corresponding FAQ question.
        &quot;source&quot;: &quot;A String&quot;, # The knowledge document that this answer was extracted from. Format: projects/{project}/knowledgeBases/{knowledge_base}/documents/{document}.
      },
      &quot;smartComposeSuggestion&quot;: { # Agent Assist Smart Compose suggestion data. # Agent Assist Smart Compose suggestion data.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this suggestion is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the Smart Compose suggestion and the document from which it originates.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
        &quot;suggestion&quot;: &quot;A String&quot;, # The content of the suggestion.
      },
      &quot;smartReply&quot;: { # Agent Assist Smart Reply data. # Agent Assist Smart Reply data.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this reply is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the Smart Reply and the document from which it originates.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
        &quot;reply&quot;: &quot;A String&quot;, # The content of the reply.
      },
      &quot;startBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation starts, inclusive.
        &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
        &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
      },
    },
  ],
  &quot;startTime&quot;: &quot;A String&quot;, # The time at which the conversation started.
  &quot;transcript&quot;: { # A message representing the transcript of a conversation. # Output only. The conversation transcript.
    &quot;transcriptSegments&quot;: [ # A list of sequential transcript segments that comprise the conversation.
      { # A segment of a full transcript.
        &quot;channelTag&quot;: 42, # For conversations derived from multi-channel audio, this is the channel number corresponding to the audio from that channel. For audioChannelCount = N, its output values can range from &#x27;1&#x27; to &#x27;N&#x27;. A channel tag of 0 indicates that the audio is mono.
        &quot;confidence&quot;: 3.14, # A confidence estimate between 0.0 and 1.0 of the fidelity of this segment. A default value of 0.0 indicates that the value is unset.
        &quot;dialogflowSegmentMetadata&quot;: { # Metadata from Dialogflow relating to the current transcript segment. # CCAI metadata relating to the current transcript segment.
          &quot;smartReplyAllowlistCovered&quot;: True or False, # Whether the transcript segment was covered under the configured smart reply allowlist in Agent Assist.
        },
        &quot;languageCode&quot;: &quot;A String&quot;, # The language code of this segment as a [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag. Example: &quot;en-US&quot;.
        &quot;messageTime&quot;: &quot;A String&quot;, # The time that the message occurred, if provided.
        &quot;segmentParticipant&quot;: { # The call participant speaking for a given utterance. # The participant of this segment.
          &quot;dialogflowParticipant&quot;: &quot;A String&quot;, # Deprecated. Use `dialogflow_participant_name` instead. The name of the Dialogflow participant. Format: projects/{project}/locations/{location}/conversations/{conversation}/participants/{participant}
          &quot;dialogflowParticipantName&quot;: &quot;A String&quot;, # The name of the participant provided by Dialogflow. Format: projects/{project}/locations/{location}/conversations/{conversation}/participants/{participant}
          &quot;obfuscatedExternalUserId&quot;: &quot;A String&quot;, # Obfuscated user ID from Dialogflow.
          &quot;role&quot;: &quot;A String&quot;, # The role of the participant.
          &quot;userId&quot;: &quot;A String&quot;, # A user-specified ID representing the participant.
        },
        &quot;sentiment&quot;: { # The data for a sentiment annotation. # The sentiment for this transcript segment.
          &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
          &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
        },
        &quot;text&quot;: &quot;A String&quot;, # The text of this segment.
        &quot;words&quot;: [ # A list of the word-specific information for each word in the segment.
          { # Word-level info for words in a transcript.
            &quot;confidence&quot;: 3.14, # A confidence estimate between 0.0 and 1.0 of the fidelity of this word. A default value of 0.0 indicates that the value is unset.
            &quot;endOffset&quot;: &quot;A String&quot;, # Time offset of the end of this word relative to the beginning of the total conversation.
            &quot;startOffset&quot;: &quot;A String&quot;, # Time offset of the start of this word relative to the beginning of the total conversation.
            &quot;word&quot;: &quot;A String&quot;, # The word itself. Includes punctuation marks that surround the word.
          },
        ],
      },
    ],
  },
  &quot;ttl&quot;: &quot;A String&quot;, # Input only. The TTL for this resource. If specified, then this TTL will be used to calculate the expire time.
  &quot;turnCount&quot;: 42, # Output only. The number of turns in the conversation.
  &quot;updateTime&quot;: &quot;A String&quot;, # Output only. The most recent time at which the conversation was updated.
}</pre>
</div>

<div class="method">
    <code class="details" id="delete">delete(name, force=None, x__xgafv=None)</code>
  <pre>Deletes a conversation.

Args:
  name: string, Required. The name of the conversation to delete. (required)
  force: boolean, If set to true, all of this conversation&#x27;s analyses will also be deleted. Otherwise, the request will only succeed if the conversation has no analyses.
  x__xgafv: string, V1 error format.
    Allowed values
      1 - v1 error format
      2 - v2 error format

Returns:
  An object of the form:

    { # A generic empty message that you can re-use to avoid defining duplicated empty messages in your APIs. A typical example is to use it as the request or the response type of an API method. For instance: service Foo { rpc Bar(google.protobuf.Empty) returns (google.protobuf.Empty); }
}</pre>
</div>

<div class="method">
    <code class="details" id="get">get(name, view=None, x__xgafv=None)</code>
  <pre>Gets a conversation.

Args:
  name: string, Required. The name of the conversation to get. (required)
  view: string, The level of details of the conversation. Default is `FULL`.
    Allowed values
      CONVERSATION_VIEW_UNSPECIFIED - The conversation view is not specified. * Defaults to `FULL` in `GetConversationRequest`. * Defaults to `BASIC` in `ListConversationsRequest`.
      FULL - Populates all fields in the conversation.
      BASIC - Populates all fields in the conversation except the transcript.
  x__xgafv: string, V1 error format.
    Allowed values
      1 - v1 error format
      2 - v2 error format

Returns:
  An object of the form:

    { # The conversation resource.
  &quot;agentId&quot;: &quot;A String&quot;, # An opaque, user-specified string representing the human agent who handled the conversation.
  &quot;callMetadata&quot;: { # Call-specific metadata. # Call-specific metadata.
    &quot;agentChannel&quot;: 42, # The audio channel that contains the agent.
    &quot;customerChannel&quot;: 42, # The audio channel that contains the customer.
  },
  &quot;createTime&quot;: &quot;A String&quot;, # Output only. The time at which the conversation was created.
  &quot;dataSource&quot;: { # The conversation source, which is a combination of transcript and audio. # The source of the audio and transcription for the conversation.
    &quot;dialogflowSource&quot;: { # A Dialogflow source of conversation data. # The source when the conversation comes from Dialogflow.
      &quot;audioUri&quot;: &quot;A String&quot;, # Cloud Storage URI that points to a file that contains the conversation audio.
      &quot;dialogflowConversation&quot;: &quot;A String&quot;, # Output only. The name of the Dialogflow conversation that this conversation resource is derived from. Format: projects/{project}/locations/{location}/conversations/{conversation}
    },
    &quot;gcsSource&quot;: { # A Cloud Storage source of conversation data. # A Cloud Storage location specification for the audio and transcript.
      &quot;audioUri&quot;: &quot;A String&quot;, # Cloud Storage URI that points to a file that contains the conversation audio.
      &quot;transcriptUri&quot;: &quot;A String&quot;, # Immutable. Cloud Storage URI that points to a file that contains the conversation transcript.
    },
  },
  &quot;dialogflowIntents&quot;: { # Output only. All the matched Dialogflow intents in the call. The key corresponds to a Dialogflow intent, format: projects/{project}/agent/{agent}/intents/{intent}
    &quot;a_key&quot;: { # The data for a Dialogflow intent. Represents a detected intent in the conversation, e.g. MAKES_PROMISE.
      &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the intent.
    },
  },
  &quot;duration&quot;: &quot;A String&quot;, # Output only. The duration of the conversation.
  &quot;expireTime&quot;: &quot;A String&quot;, # The time at which this conversation should expire. After this time, the conversation data and any associated analyses will be deleted.
  &quot;labels&quot;: { # A map for the user to specify any custom fields. A maximum of 20 labels per conversation is allowed, with a maximum of 256 characters per entry.
    &quot;a_key&quot;: &quot;A String&quot;,
  },
  &quot;languageCode&quot;: &quot;A String&quot;, # A user-specified language code for the conversation.
  &quot;latestAnalysis&quot;: { # The analysis resource. # Output only. The conversation&#x27;s latest analysis, if one exists.
    &quot;analysisResult&quot;: { # The result of an analysis. # Output only. The result of the analysis, which is populated when the analysis finishes.
      &quot;callAnalysisMetadata&quot;: { # Call-specific metadata created during analysis. # Call-specific metadata created by the analysis.
        &quot;annotations&quot;: [ # A list of call annotations that apply to this call.
          { # A piece of metadata that applies to a window of a call.
            &quot;annotationEndBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation ends, inclusive.
              &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
              &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
            },
            &quot;annotationStartBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation starts, inclusive.
              &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
              &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
            },
            &quot;channelTag&quot;: 42, # The channel of the audio where the annotation occurs. For single-channel audio, this field is not populated.
            &quot;entityMentionData&quot;: { # The data for an entity mention annotation. This represents a mention of an `Entity` in the conversation. # Data specifying an entity mention.
              &quot;entityUniqueId&quot;: &quot;A String&quot;, # The key of this entity in conversation entities. Can be used to retrieve the exact `Entity` this mention is attached to.
              &quot;sentiment&quot;: { # The data for a sentiment annotation. # Sentiment expressed for this mention of the entity.
                &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
                &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
              },
              &quot;type&quot;: &quot;A String&quot;, # The type of the entity mention.
            },
            &quot;holdData&quot;: { # The data for a hold annotation. # Data specifying a hold.
            },
            &quot;intentMatchData&quot;: { # The data for an intent match. Represents an intent match for a text segment in the conversation. A text segment can be part of a sentence, a complete sentence, or an utterance with multiple sentences. # Data specifying an intent match.
              &quot;intentUniqueId&quot;: &quot;A String&quot;, # The id of the matched intent. Can be used to retrieve the corresponding intent information.
            },
            &quot;interruptionData&quot;: { # The data for an interruption annotation. # Data specifying an interruption.
            },
            &quot;issueMatchData&quot;: { # The data for an issue match annotation. # Data specifying an issue match.
              &quot;issueAssignment&quot;: { # Information about the issue. # Information about the issue&#x27;s assignment.
                &quot;displayName&quot;: &quot;A String&quot;, # Immutable. Display name of the assigned issue. This field is set at time of analyis and immutable since then.
                &quot;issue&quot;: &quot;A String&quot;, # Resource name of the assigned issue.
                &quot;score&quot;: 3.14, # Score indicating the likelihood of the issue assignment. currently bounded on [0,1].
              },
            },
            &quot;phraseMatchData&quot;: { # The data for a matched phrase matcher. Represents information identifying a phrase matcher for a given match. # Data specifying a phrase match.
              &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the phrase matcher.
              &quot;phraseMatcher&quot;: &quot;A String&quot;, # The unique identifier (the resource name) of the phrase matcher.
            },
            &quot;sentimentData&quot;: { # The data for a sentiment annotation. # Data specifying sentiment.
              &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
              &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
            },
            &quot;silenceData&quot;: { # The data for a silence annotation. # Data specifying silence.
            },
          },
        ],
        &quot;entities&quot;: { # All the entities in the call.
          &quot;a_key&quot;: { # The data for an entity annotation. Represents a phrase in the conversation that is a known entity, such as a person, an organization, or location.
            &quot;displayName&quot;: &quot;A String&quot;, # The representative name for the entity.
            &quot;metadata&quot;: { # Metadata associated with the entity. For most entity types, the metadata is a Wikipedia URL (`wikipedia_url`) and Knowledge Graph MID (`mid`), if they are available. For the metadata associated with other entity types, see the Type table below.
              &quot;a_key&quot;: &quot;A String&quot;,
            },
            &quot;salience&quot;: 3.14, # The salience score associated with the entity in the [0, 1.0] range. The salience score for an entity provides information about the importance or centrality of that entity to the entire document text. Scores closer to 0 are less salient, while scores closer to 1.0 are highly salient.
            &quot;sentiment&quot;: { # The data for a sentiment annotation. # The aggregate sentiment expressed for this entity in the conversation.
              &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
              &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
            },
            &quot;type&quot;: &quot;A String&quot;, # The entity type.
          },
        },
        &quot;intents&quot;: { # All the matched intents in the call.
          &quot;a_key&quot;: { # The data for an intent. Represents a detected intent in the conversation, for example MAKES_PROMISE.
            &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the intent.
            &quot;id&quot;: &quot;A String&quot;, # The unique identifier of the intent.
          },
        },
        &quot;issueModelResult&quot;: { # Issue Modeling result on a conversation. # Overall conversation-level issue modeling result.
          &quot;issueModel&quot;: &quot;A String&quot;, # Issue model that generates the result. Format: projects/{project}/locations/{location}/issueModels/{issue_model}
          &quot;issues&quot;: [ # All the matched issues.
            { # Information about the issue.
              &quot;displayName&quot;: &quot;A String&quot;, # Immutable. Display name of the assigned issue. This field is set at time of analyis and immutable since then.
              &quot;issue&quot;: &quot;A String&quot;, # Resource name of the assigned issue.
              &quot;score&quot;: 3.14, # Score indicating the likelihood of the issue assignment. currently bounded on [0,1].
            },
          ],
        },
        &quot;phraseMatchers&quot;: { # All the matched phrase matchers in the call.
          &quot;a_key&quot;: { # The data for a matched phrase matcher. Represents information identifying a phrase matcher for a given match.
            &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the phrase matcher.
            &quot;phraseMatcher&quot;: &quot;A String&quot;, # The unique identifier (the resource name) of the phrase matcher.
          },
        },
        &quot;sentiments&quot;: [ # Overall conversation-level sentiment for each channel of the call.
          { # One channel of conversation-level sentiment data.
            &quot;channelTag&quot;: 42, # The channel of the audio that the data applies to.
            &quot;sentimentData&quot;: { # The data for a sentiment annotation. # Data specifying sentiment.
              &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
              &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
            },
          },
        ],
      },
      &quot;endTime&quot;: &quot;A String&quot;, # The time at which the analysis ended.
    },
    &quot;annotatorSelector&quot;: { # Selector of all available annotators and phrase matchers to run. # To select the annotators to run and the phrase matchers to use (if any). If not specified, all annotators will be run.
      &quot;issueModels&quot;: [ # The issue model to run. If not provided, the most recently deployed topic model will be used. The provided issue model will only be used for inference if the issue model is deployed and if run_issue_model_annotator is set to true. If more than one issue model is provided, only the first provided issue model will be used for inference.
        &quot;A String&quot;,
      ],
      &quot;phraseMatchers&quot;: [ # The list of phrase matchers to run. If not provided, all active phrase matchers will be used. If inactive phrase matchers are provided, they will not be used. Phrase matchers will be run only if run_phrase_matcher_annotator is set to true. Format: projects/{project}/locations/{location}/phraseMatchers/{phrase_matcher}
        &quot;A String&quot;,
      ],
      &quot;runEntityAnnotator&quot;: True or False, # Whether to run the entity annotator.
      &quot;runIntentAnnotator&quot;: True or False, # Whether to run the intent annotator.
      &quot;runInterruptionAnnotator&quot;: True or False, # Whether to run the interruption annotator.
      &quot;runIssueModelAnnotator&quot;: True or False, # Whether to run the issue model annotator. A model should have already been deployed for this to take effect.
      &quot;runPhraseMatcherAnnotator&quot;: True or False, # Whether to run the active phrase matcher annotator(s).
      &quot;runSentimentAnnotator&quot;: True or False, # Whether to run the sentiment annotator.
      &quot;runSilenceAnnotator&quot;: True or False, # Whether to run the silence annotator.
    },
    &quot;createTime&quot;: &quot;A String&quot;, # Output only. The time at which the analysis was created, which occurs when the long-running operation completes.
    &quot;name&quot;: &quot;A String&quot;, # Immutable. The resource name of the analysis. Format: projects/{project}/locations/{location}/conversations/{conversation}/analyses/{analysis}
    &quot;requestTime&quot;: &quot;A String&quot;, # Output only. The time at which the analysis was requested.
  },
  &quot;medium&quot;: &quot;A String&quot;, # Immutable. The conversation medium, if unspecified will default to PHONE_CALL.
  &quot;name&quot;: &quot;A String&quot;, # Immutable. The resource name of the conversation. Format: projects/{project}/locations/{location}/conversations/{conversation}
  &quot;obfuscatedUserId&quot;: &quot;A String&quot;, # Obfuscated user ID which the customer sent to us.
  &quot;runtimeAnnotations&quot;: [ # Output only. The annotations that were generated during the customer and agent interaction.
    { # An annotation that was generated during the customer and agent interaction.
      &quot;annotationId&quot;: &quot;A String&quot;, # The unique identifier of the annotation. Format: projects/{project}/locations/{location}/conversationDatasets/{dataset}/conversationDataItems/{data_item}/conversationAnnotations/{annotation}
      &quot;answerFeedback&quot;: { # The feedback that the customer has about a certain answer in the conversation. # The feedback that the customer has about the answer in `data`.
        &quot;clicked&quot;: True or False, # Indicates whether an answer or item was clicked by the human agent.
        &quot;correctnessLevel&quot;: &quot;A String&quot;, # The correctness level of an answer.
        &quot;displayed&quot;: True or False, # Indicates whether an answer or item was displayed to the human agent in the agent desktop UI.
      },
      &quot;articleSuggestion&quot;: { # Agent Assist Article Suggestion data. # Agent Assist Article Suggestion data.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this article is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the Article Suggestion and the document that it originates from.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
        &quot;source&quot;: &quot;A String&quot;, # The knowledge document that this answer was extracted from. Format: projects/{project}/knowledgeBases/{knowledge_base}/documents/{document}
        &quot;title&quot;: &quot;A String&quot;, # Article title.
        &quot;uri&quot;: &quot;A String&quot;, # Article URI.
      },
      &quot;createTime&quot;: &quot;A String&quot;, # The time at which this annotation was created.
      &quot;dialogflowInteraction&quot;: { # Dialogflow interaction data. # Dialogflow interaction data.
        &quot;confidence&quot;: 3.14, # The confidence of the match ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;dialogflowIntentId&quot;: &quot;A String&quot;, # The Dialogflow intent resource path. Format: projects/{project}/agent/{agent}/intents/{intent}
      },
      &quot;endBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation ends, inclusive.
        &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
        &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
      },
      &quot;faqAnswer&quot;: { # Agent Assist frequently-asked-question answer data. # Agent Assist FAQ answer data.
        &quot;answer&quot;: &quot;A String&quot;, # The piece of text from the `source` knowledge base document.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this answer is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the FAQ answer and the document that it originates from.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
        &quot;question&quot;: &quot;A String&quot;, # The corresponding FAQ question.
        &quot;source&quot;: &quot;A String&quot;, # The knowledge document that this answer was extracted from. Format: projects/{project}/knowledgeBases/{knowledge_base}/documents/{document}.
      },
      &quot;smartComposeSuggestion&quot;: { # Agent Assist Smart Compose suggestion data. # Agent Assist Smart Compose suggestion data.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this suggestion is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the Smart Compose suggestion and the document from which it originates.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
        &quot;suggestion&quot;: &quot;A String&quot;, # The content of the suggestion.
      },
      &quot;smartReply&quot;: { # Agent Assist Smart Reply data. # Agent Assist Smart Reply data.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this reply is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the Smart Reply and the document from which it originates.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
        &quot;reply&quot;: &quot;A String&quot;, # The content of the reply.
      },
      &quot;startBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation starts, inclusive.
        &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
        &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
      },
    },
  ],
  &quot;startTime&quot;: &quot;A String&quot;, # The time at which the conversation started.
  &quot;transcript&quot;: { # A message representing the transcript of a conversation. # Output only. The conversation transcript.
    &quot;transcriptSegments&quot;: [ # A list of sequential transcript segments that comprise the conversation.
      { # A segment of a full transcript.
        &quot;channelTag&quot;: 42, # For conversations derived from multi-channel audio, this is the channel number corresponding to the audio from that channel. For audioChannelCount = N, its output values can range from &#x27;1&#x27; to &#x27;N&#x27;. A channel tag of 0 indicates that the audio is mono.
        &quot;confidence&quot;: 3.14, # A confidence estimate between 0.0 and 1.0 of the fidelity of this segment. A default value of 0.0 indicates that the value is unset.
        &quot;dialogflowSegmentMetadata&quot;: { # Metadata from Dialogflow relating to the current transcript segment. # CCAI metadata relating to the current transcript segment.
          &quot;smartReplyAllowlistCovered&quot;: True or False, # Whether the transcript segment was covered under the configured smart reply allowlist in Agent Assist.
        },
        &quot;languageCode&quot;: &quot;A String&quot;, # The language code of this segment as a [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag. Example: &quot;en-US&quot;.
        &quot;messageTime&quot;: &quot;A String&quot;, # The time that the message occurred, if provided.
        &quot;segmentParticipant&quot;: { # The call participant speaking for a given utterance. # The participant of this segment.
          &quot;dialogflowParticipant&quot;: &quot;A String&quot;, # Deprecated. Use `dialogflow_participant_name` instead. The name of the Dialogflow participant. Format: projects/{project}/locations/{location}/conversations/{conversation}/participants/{participant}
          &quot;dialogflowParticipantName&quot;: &quot;A String&quot;, # The name of the participant provided by Dialogflow. Format: projects/{project}/locations/{location}/conversations/{conversation}/participants/{participant}
          &quot;obfuscatedExternalUserId&quot;: &quot;A String&quot;, # Obfuscated user ID from Dialogflow.
          &quot;role&quot;: &quot;A String&quot;, # The role of the participant.
          &quot;userId&quot;: &quot;A String&quot;, # A user-specified ID representing the participant.
        },
        &quot;sentiment&quot;: { # The data for a sentiment annotation. # The sentiment for this transcript segment.
          &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
          &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
        },
        &quot;text&quot;: &quot;A String&quot;, # The text of this segment.
        &quot;words&quot;: [ # A list of the word-specific information for each word in the segment.
          { # Word-level info for words in a transcript.
            &quot;confidence&quot;: 3.14, # A confidence estimate between 0.0 and 1.0 of the fidelity of this word. A default value of 0.0 indicates that the value is unset.
            &quot;endOffset&quot;: &quot;A String&quot;, # Time offset of the end of this word relative to the beginning of the total conversation.
            &quot;startOffset&quot;: &quot;A String&quot;, # Time offset of the start of this word relative to the beginning of the total conversation.
            &quot;word&quot;: &quot;A String&quot;, # The word itself. Includes punctuation marks that surround the word.
          },
        ],
      },
    ],
  },
  &quot;ttl&quot;: &quot;A String&quot;, # Input only. The TTL for this resource. If specified, then this TTL will be used to calculate the expire time.
  &quot;turnCount&quot;: 42, # Output only. The number of turns in the conversation.
  &quot;updateTime&quot;: &quot;A String&quot;, # Output only. The most recent time at which the conversation was updated.
}</pre>
</div>

<div class="method">
    <code class="details" id="ingest">ingest(parent, body=None, x__xgafv=None)</code>
  <pre>Imports conversations and processes them according to the user&#x27;s configuration.

Args:
  parent: string, Required. The parent resource for new conversations. (required)
  body: object, The request body.
    The object takes the form of:

{ # The request to ingest conversations.
  &quot;conversationConfig&quot;: { # Configuration that applies to all conversations. # Configuration that applies to all conversations.
    &quot;agentId&quot;: &quot;A String&quot;, # An opaque, user-specified string representing the human agent who handled the conversations.
  },
  &quot;gcsSource&quot;: { # Configuration for Cloud Storage bucket sources. # A cloud storage bucket source.
    &quot;bucketUri&quot;: &quot;A String&quot;, # Required. The Cloud Storage bucket containing source objects.
  },
  &quot;parent&quot;: &quot;A String&quot;, # Required. The parent resource for new conversations.
  &quot;transcriptObjectConfig&quot;: { # Configuration for processing transcript objects. # Configuration for when `source` contains conversation transcripts.
    &quot;medium&quot;: &quot;A String&quot;, # Required. The medium transcript objects represent.
  },
}

  x__xgafv: string, V1 error format.
    Allowed values
      1 - v1 error format
      2 - v2 error format

Returns:
  An object of the form:

    { # This resource represents a long-running operation that is the result of a network API call.
  &quot;done&quot;: True or False, # If the value is `false`, it means the operation is still in progress. If `true`, the operation is completed, and either `error` or `response` is available.
  &quot;error&quot;: { # The `Status` type defines a logical error model that is suitable for different programming environments, including REST APIs and RPC APIs. It is used by [gRPC](https://github.com/grpc). Each `Status` message contains three pieces of data: error code, error message, and error details. You can find out more about this error model and how to work with it in the [API Design Guide](https://cloud.google.com/apis/design/errors). # The error result of the operation in case of failure or cancellation.
    &quot;code&quot;: 42, # The status code, which should be an enum value of google.rpc.Code.
    &quot;details&quot;: [ # A list of messages that carry the error details. There is a common set of message types for APIs to use.
      {
        &quot;a_key&quot;: &quot;&quot;, # Properties of the object. Contains field @type with type URL.
      },
    ],
    &quot;message&quot;: &quot;A String&quot;, # A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client.
  },
  &quot;metadata&quot;: { # Service-specific metadata associated with the operation. It typically contains progress information and common metadata such as create time. Some services might not provide such metadata. Any method that returns a long-running operation should document the metadata type, if any.
    &quot;a_key&quot;: &quot;&quot;, # Properties of the object. Contains field @type with type URL.
  },
  &quot;name&quot;: &quot;A String&quot;, # The server-assigned name, which is only unique within the same service that originally returns it. If you use the default HTTP mapping, the `name` should be a resource name ending with `operations/{unique_id}`.
  &quot;response&quot;: { # The normal response of the operation in case of success. If the original method returns no data on success, such as `Delete`, the response is `google.protobuf.Empty`. If the original method is standard `Get`/`Create`/`Update`, the response should be the resource. For other methods, the response should have the type `XxxResponse`, where `Xxx` is the original method name. For example, if the original method name is `TakeSnapshot()`, the inferred response type is `TakeSnapshotResponse`.
    &quot;a_key&quot;: &quot;&quot;, # Properties of the object. Contains field @type with type URL.
  },
}</pre>
</div>

<div class="method">
    <code class="details" id="list">list(parent, filter=None, pageSize=None, pageToken=None, view=None, x__xgafv=None)</code>
  <pre>Lists conversations.

Args:
  parent: string, Required. The parent resource of the conversation. (required)
  filter: string, A filter to reduce results to a specific subset. Useful for querying conversations with specific properties.
  pageSize: integer, The maximum number of conversations to return in the response. A valid page size ranges from 0 to 1,000 inclusive. If the page size is zero or unspecified, a default page size of 100 will be chosen. Note that a call might return fewer results than the requested page size.
  pageToken: string, The value returned by the last `ListConversationsResponse`. This value indicates that this is a continuation of a prior `ListConversations` call and that the system should return the next page of data.
  view: string, The level of details of the conversation. Default is `BASIC`.
    Allowed values
      CONVERSATION_VIEW_UNSPECIFIED - The conversation view is not specified. * Defaults to `FULL` in `GetConversationRequest`. * Defaults to `BASIC` in `ListConversationsRequest`.
      FULL - Populates all fields in the conversation.
      BASIC - Populates all fields in the conversation except the transcript.
  x__xgafv: string, V1 error format.
    Allowed values
      1 - v1 error format
      2 - v2 error format

Returns:
  An object of the form:

    { # The response of listing conversations.
  &quot;conversations&quot;: [ # The conversations that match the request.
    { # The conversation resource.
      &quot;agentId&quot;: &quot;A String&quot;, # An opaque, user-specified string representing the human agent who handled the conversation.
      &quot;callMetadata&quot;: { # Call-specific metadata. # Call-specific metadata.
        &quot;agentChannel&quot;: 42, # The audio channel that contains the agent.
        &quot;customerChannel&quot;: 42, # The audio channel that contains the customer.
      },
      &quot;createTime&quot;: &quot;A String&quot;, # Output only. The time at which the conversation was created.
      &quot;dataSource&quot;: { # The conversation source, which is a combination of transcript and audio. # The source of the audio and transcription for the conversation.
        &quot;dialogflowSource&quot;: { # A Dialogflow source of conversation data. # The source when the conversation comes from Dialogflow.
          &quot;audioUri&quot;: &quot;A String&quot;, # Cloud Storage URI that points to a file that contains the conversation audio.
          &quot;dialogflowConversation&quot;: &quot;A String&quot;, # Output only. The name of the Dialogflow conversation that this conversation resource is derived from. Format: projects/{project}/locations/{location}/conversations/{conversation}
        },
        &quot;gcsSource&quot;: { # A Cloud Storage source of conversation data. # A Cloud Storage location specification for the audio and transcript.
          &quot;audioUri&quot;: &quot;A String&quot;, # Cloud Storage URI that points to a file that contains the conversation audio.
          &quot;transcriptUri&quot;: &quot;A String&quot;, # Immutable. Cloud Storage URI that points to a file that contains the conversation transcript.
        },
      },
      &quot;dialogflowIntents&quot;: { # Output only. All the matched Dialogflow intents in the call. The key corresponds to a Dialogflow intent, format: projects/{project}/agent/{agent}/intents/{intent}
        &quot;a_key&quot;: { # The data for a Dialogflow intent. Represents a detected intent in the conversation, e.g. MAKES_PROMISE.
          &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the intent.
        },
      },
      &quot;duration&quot;: &quot;A String&quot;, # Output only. The duration of the conversation.
      &quot;expireTime&quot;: &quot;A String&quot;, # The time at which this conversation should expire. After this time, the conversation data and any associated analyses will be deleted.
      &quot;labels&quot;: { # A map for the user to specify any custom fields. A maximum of 20 labels per conversation is allowed, with a maximum of 256 characters per entry.
        &quot;a_key&quot;: &quot;A String&quot;,
      },
      &quot;languageCode&quot;: &quot;A String&quot;, # A user-specified language code for the conversation.
      &quot;latestAnalysis&quot;: { # The analysis resource. # Output only. The conversation&#x27;s latest analysis, if one exists.
        &quot;analysisResult&quot;: { # The result of an analysis. # Output only. The result of the analysis, which is populated when the analysis finishes.
          &quot;callAnalysisMetadata&quot;: { # Call-specific metadata created during analysis. # Call-specific metadata created by the analysis.
            &quot;annotations&quot;: [ # A list of call annotations that apply to this call.
              { # A piece of metadata that applies to a window of a call.
                &quot;annotationEndBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation ends, inclusive.
                  &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
                  &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
                },
                &quot;annotationStartBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation starts, inclusive.
                  &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
                  &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
                },
                &quot;channelTag&quot;: 42, # The channel of the audio where the annotation occurs. For single-channel audio, this field is not populated.
                &quot;entityMentionData&quot;: { # The data for an entity mention annotation. This represents a mention of an `Entity` in the conversation. # Data specifying an entity mention.
                  &quot;entityUniqueId&quot;: &quot;A String&quot;, # The key of this entity in conversation entities. Can be used to retrieve the exact `Entity` this mention is attached to.
                  &quot;sentiment&quot;: { # The data for a sentiment annotation. # Sentiment expressed for this mention of the entity.
                    &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
                    &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
                  },
                  &quot;type&quot;: &quot;A String&quot;, # The type of the entity mention.
                },
                &quot;holdData&quot;: { # The data for a hold annotation. # Data specifying a hold.
                },
                &quot;intentMatchData&quot;: { # The data for an intent match. Represents an intent match for a text segment in the conversation. A text segment can be part of a sentence, a complete sentence, or an utterance with multiple sentences. # Data specifying an intent match.
                  &quot;intentUniqueId&quot;: &quot;A String&quot;, # The id of the matched intent. Can be used to retrieve the corresponding intent information.
                },
                &quot;interruptionData&quot;: { # The data for an interruption annotation. # Data specifying an interruption.
                },
                &quot;issueMatchData&quot;: { # The data for an issue match annotation. # Data specifying an issue match.
                  &quot;issueAssignment&quot;: { # Information about the issue. # Information about the issue&#x27;s assignment.
                    &quot;displayName&quot;: &quot;A String&quot;, # Immutable. Display name of the assigned issue. This field is set at time of analyis and immutable since then.
                    &quot;issue&quot;: &quot;A String&quot;, # Resource name of the assigned issue.
                    &quot;score&quot;: 3.14, # Score indicating the likelihood of the issue assignment. currently bounded on [0,1].
                  },
                },
                &quot;phraseMatchData&quot;: { # The data for a matched phrase matcher. Represents information identifying a phrase matcher for a given match. # Data specifying a phrase match.
                  &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the phrase matcher.
                  &quot;phraseMatcher&quot;: &quot;A String&quot;, # The unique identifier (the resource name) of the phrase matcher.
                },
                &quot;sentimentData&quot;: { # The data for a sentiment annotation. # Data specifying sentiment.
                  &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
                  &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
                },
                &quot;silenceData&quot;: { # The data for a silence annotation. # Data specifying silence.
                },
              },
            ],
            &quot;entities&quot;: { # All the entities in the call.
              &quot;a_key&quot;: { # The data for an entity annotation. Represents a phrase in the conversation that is a known entity, such as a person, an organization, or location.
                &quot;displayName&quot;: &quot;A String&quot;, # The representative name for the entity.
                &quot;metadata&quot;: { # Metadata associated with the entity. For most entity types, the metadata is a Wikipedia URL (`wikipedia_url`) and Knowledge Graph MID (`mid`), if they are available. For the metadata associated with other entity types, see the Type table below.
                  &quot;a_key&quot;: &quot;A String&quot;,
                },
                &quot;salience&quot;: 3.14, # The salience score associated with the entity in the [0, 1.0] range. The salience score for an entity provides information about the importance or centrality of that entity to the entire document text. Scores closer to 0 are less salient, while scores closer to 1.0 are highly salient.
                &quot;sentiment&quot;: { # The data for a sentiment annotation. # The aggregate sentiment expressed for this entity in the conversation.
                  &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
                  &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
                },
                &quot;type&quot;: &quot;A String&quot;, # The entity type.
              },
            },
            &quot;intents&quot;: { # All the matched intents in the call.
              &quot;a_key&quot;: { # The data for an intent. Represents a detected intent in the conversation, for example MAKES_PROMISE.
                &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the intent.
                &quot;id&quot;: &quot;A String&quot;, # The unique identifier of the intent.
              },
            },
            &quot;issueModelResult&quot;: { # Issue Modeling result on a conversation. # Overall conversation-level issue modeling result.
              &quot;issueModel&quot;: &quot;A String&quot;, # Issue model that generates the result. Format: projects/{project}/locations/{location}/issueModels/{issue_model}
              &quot;issues&quot;: [ # All the matched issues.
                { # Information about the issue.
                  &quot;displayName&quot;: &quot;A String&quot;, # Immutable. Display name of the assigned issue. This field is set at time of analyis and immutable since then.
                  &quot;issue&quot;: &quot;A String&quot;, # Resource name of the assigned issue.
                  &quot;score&quot;: 3.14, # Score indicating the likelihood of the issue assignment. currently bounded on [0,1].
                },
              ],
            },
            &quot;phraseMatchers&quot;: { # All the matched phrase matchers in the call.
              &quot;a_key&quot;: { # The data for a matched phrase matcher. Represents information identifying a phrase matcher for a given match.
                &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the phrase matcher.
                &quot;phraseMatcher&quot;: &quot;A String&quot;, # The unique identifier (the resource name) of the phrase matcher.
              },
            },
            &quot;sentiments&quot;: [ # Overall conversation-level sentiment for each channel of the call.
              { # One channel of conversation-level sentiment data.
                &quot;channelTag&quot;: 42, # The channel of the audio that the data applies to.
                &quot;sentimentData&quot;: { # The data for a sentiment annotation. # Data specifying sentiment.
                  &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
                  &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
                },
              },
            ],
          },
          &quot;endTime&quot;: &quot;A String&quot;, # The time at which the analysis ended.
        },
        &quot;annotatorSelector&quot;: { # Selector of all available annotators and phrase matchers to run. # To select the annotators to run and the phrase matchers to use (if any). If not specified, all annotators will be run.
          &quot;issueModels&quot;: [ # The issue model to run. If not provided, the most recently deployed topic model will be used. The provided issue model will only be used for inference if the issue model is deployed and if run_issue_model_annotator is set to true. If more than one issue model is provided, only the first provided issue model will be used for inference.
            &quot;A String&quot;,
          ],
          &quot;phraseMatchers&quot;: [ # The list of phrase matchers to run. If not provided, all active phrase matchers will be used. If inactive phrase matchers are provided, they will not be used. Phrase matchers will be run only if run_phrase_matcher_annotator is set to true. Format: projects/{project}/locations/{location}/phraseMatchers/{phrase_matcher}
            &quot;A String&quot;,
          ],
          &quot;runEntityAnnotator&quot;: True or False, # Whether to run the entity annotator.
          &quot;runIntentAnnotator&quot;: True or False, # Whether to run the intent annotator.
          &quot;runInterruptionAnnotator&quot;: True or False, # Whether to run the interruption annotator.
          &quot;runIssueModelAnnotator&quot;: True or False, # Whether to run the issue model annotator. A model should have already been deployed for this to take effect.
          &quot;runPhraseMatcherAnnotator&quot;: True or False, # Whether to run the active phrase matcher annotator(s).
          &quot;runSentimentAnnotator&quot;: True or False, # Whether to run the sentiment annotator.
          &quot;runSilenceAnnotator&quot;: True or False, # Whether to run the silence annotator.
        },
        &quot;createTime&quot;: &quot;A String&quot;, # Output only. The time at which the analysis was created, which occurs when the long-running operation completes.
        &quot;name&quot;: &quot;A String&quot;, # Immutable. The resource name of the analysis. Format: projects/{project}/locations/{location}/conversations/{conversation}/analyses/{analysis}
        &quot;requestTime&quot;: &quot;A String&quot;, # Output only. The time at which the analysis was requested.
      },
      &quot;medium&quot;: &quot;A String&quot;, # Immutable. The conversation medium, if unspecified will default to PHONE_CALL.
      &quot;name&quot;: &quot;A String&quot;, # Immutable. The resource name of the conversation. Format: projects/{project}/locations/{location}/conversations/{conversation}
      &quot;obfuscatedUserId&quot;: &quot;A String&quot;, # Obfuscated user ID which the customer sent to us.
      &quot;runtimeAnnotations&quot;: [ # Output only. The annotations that were generated during the customer and agent interaction.
        { # An annotation that was generated during the customer and agent interaction.
          &quot;annotationId&quot;: &quot;A String&quot;, # The unique identifier of the annotation. Format: projects/{project}/locations/{location}/conversationDatasets/{dataset}/conversationDataItems/{data_item}/conversationAnnotations/{annotation}
          &quot;answerFeedback&quot;: { # The feedback that the customer has about a certain answer in the conversation. # The feedback that the customer has about the answer in `data`.
            &quot;clicked&quot;: True or False, # Indicates whether an answer or item was clicked by the human agent.
            &quot;correctnessLevel&quot;: &quot;A String&quot;, # The correctness level of an answer.
            &quot;displayed&quot;: True or False, # Indicates whether an answer or item was displayed to the human agent in the agent desktop UI.
          },
          &quot;articleSuggestion&quot;: { # Agent Assist Article Suggestion data. # Agent Assist Article Suggestion data.
            &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this article is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
            &quot;metadata&quot;: { # Map that contains metadata about the Article Suggestion and the document that it originates from.
              &quot;a_key&quot;: &quot;A String&quot;,
            },
            &quot;queryRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
            &quot;source&quot;: &quot;A String&quot;, # The knowledge document that this answer was extracted from. Format: projects/{project}/knowledgeBases/{knowledge_base}/documents/{document}
            &quot;title&quot;: &quot;A String&quot;, # Article title.
            &quot;uri&quot;: &quot;A String&quot;, # Article URI.
          },
          &quot;createTime&quot;: &quot;A String&quot;, # The time at which this annotation was created.
          &quot;dialogflowInteraction&quot;: { # Dialogflow interaction data. # Dialogflow interaction data.
            &quot;confidence&quot;: 3.14, # The confidence of the match ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
            &quot;dialogflowIntentId&quot;: &quot;A String&quot;, # The Dialogflow intent resource path. Format: projects/{project}/agent/{agent}/intents/{intent}
          },
          &quot;endBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation ends, inclusive.
            &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
            &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
          },
          &quot;faqAnswer&quot;: { # Agent Assist frequently-asked-question answer data. # Agent Assist FAQ answer data.
            &quot;answer&quot;: &quot;A String&quot;, # The piece of text from the `source` knowledge base document.
            &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this answer is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
            &quot;metadata&quot;: { # Map that contains metadata about the FAQ answer and the document that it originates from.
              &quot;a_key&quot;: &quot;A String&quot;,
            },
            &quot;queryRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
            &quot;question&quot;: &quot;A String&quot;, # The corresponding FAQ question.
            &quot;source&quot;: &quot;A String&quot;, # The knowledge document that this answer was extracted from. Format: projects/{project}/knowledgeBases/{knowledge_base}/documents/{document}.
          },
          &quot;smartComposeSuggestion&quot;: { # Agent Assist Smart Compose suggestion data. # Agent Assist Smart Compose suggestion data.
            &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this suggestion is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
            &quot;metadata&quot;: { # Map that contains metadata about the Smart Compose suggestion and the document from which it originates.
              &quot;a_key&quot;: &quot;A String&quot;,
            },
            &quot;queryRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
            &quot;suggestion&quot;: &quot;A String&quot;, # The content of the suggestion.
          },
          &quot;smartReply&quot;: { # Agent Assist Smart Reply data. # Agent Assist Smart Reply data.
            &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this reply is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
            &quot;metadata&quot;: { # Map that contains metadata about the Smart Reply and the document from which it originates.
              &quot;a_key&quot;: &quot;A String&quot;,
            },
            &quot;queryRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
            &quot;reply&quot;: &quot;A String&quot;, # The content of the reply.
          },
          &quot;startBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation starts, inclusive.
            &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
            &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
          },
        },
      ],
      &quot;startTime&quot;: &quot;A String&quot;, # The time at which the conversation started.
      &quot;transcript&quot;: { # A message representing the transcript of a conversation. # Output only. The conversation transcript.
        &quot;transcriptSegments&quot;: [ # A list of sequential transcript segments that comprise the conversation.
          { # A segment of a full transcript.
            &quot;channelTag&quot;: 42, # For conversations derived from multi-channel audio, this is the channel number corresponding to the audio from that channel. For audioChannelCount = N, its output values can range from &#x27;1&#x27; to &#x27;N&#x27;. A channel tag of 0 indicates that the audio is mono.
            &quot;confidence&quot;: 3.14, # A confidence estimate between 0.0 and 1.0 of the fidelity of this segment. A default value of 0.0 indicates that the value is unset.
            &quot;dialogflowSegmentMetadata&quot;: { # Metadata from Dialogflow relating to the current transcript segment. # CCAI metadata relating to the current transcript segment.
              &quot;smartReplyAllowlistCovered&quot;: True or False, # Whether the transcript segment was covered under the configured smart reply allowlist in Agent Assist.
            },
            &quot;languageCode&quot;: &quot;A String&quot;, # The language code of this segment as a [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag. Example: &quot;en-US&quot;.
            &quot;messageTime&quot;: &quot;A String&quot;, # The time that the message occurred, if provided.
            &quot;segmentParticipant&quot;: { # The call participant speaking for a given utterance. # The participant of this segment.
              &quot;dialogflowParticipant&quot;: &quot;A String&quot;, # Deprecated. Use `dialogflow_participant_name` instead. The name of the Dialogflow participant. Format: projects/{project}/locations/{location}/conversations/{conversation}/participants/{participant}
              &quot;dialogflowParticipantName&quot;: &quot;A String&quot;, # The name of the participant provided by Dialogflow. Format: projects/{project}/locations/{location}/conversations/{conversation}/participants/{participant}
              &quot;obfuscatedExternalUserId&quot;: &quot;A String&quot;, # Obfuscated user ID from Dialogflow.
              &quot;role&quot;: &quot;A String&quot;, # The role of the participant.
              &quot;userId&quot;: &quot;A String&quot;, # A user-specified ID representing the participant.
            },
            &quot;sentiment&quot;: { # The data for a sentiment annotation. # The sentiment for this transcript segment.
              &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
              &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
            },
            &quot;text&quot;: &quot;A String&quot;, # The text of this segment.
            &quot;words&quot;: [ # A list of the word-specific information for each word in the segment.
              { # Word-level info for words in a transcript.
                &quot;confidence&quot;: 3.14, # A confidence estimate between 0.0 and 1.0 of the fidelity of this word. A default value of 0.0 indicates that the value is unset.
                &quot;endOffset&quot;: &quot;A String&quot;, # Time offset of the end of this word relative to the beginning of the total conversation.
                &quot;startOffset&quot;: &quot;A String&quot;, # Time offset of the start of this word relative to the beginning of the total conversation.
                &quot;word&quot;: &quot;A String&quot;, # The word itself. Includes punctuation marks that surround the word.
              },
            ],
          },
        ],
      },
      &quot;ttl&quot;: &quot;A String&quot;, # Input only. The TTL for this resource. If specified, then this TTL will be used to calculate the expire time.
      &quot;turnCount&quot;: 42, # Output only. The number of turns in the conversation.
      &quot;updateTime&quot;: &quot;A String&quot;, # Output only. The most recent time at which the conversation was updated.
    },
  ],
  &quot;nextPageToken&quot;: &quot;A String&quot;, # A token which can be sent as `page_token` to retrieve the next page. If this field is set, it means there is another page available. If it is not set, it means no other pages are available.
}</pre>
</div>

<div class="method">
    <code class="details" id="list_next">list_next()</code>
  <pre>Retrieves the next page of results.

        Args:
          previous_request: The request for the previous page. (required)
          previous_response: The response from the request for the previous page. (required)

        Returns:
          A request object that you can call &#x27;execute()&#x27; on to request the next
          page. Returns None if there are no more items in the collection.
        </pre>
</div>

<div class="method">
    <code class="details" id="patch">patch(name, body=None, updateMask=None, x__xgafv=None)</code>
  <pre>Updates a conversation.

Args:
  name: string, Immutable. The resource name of the conversation. Format: projects/{project}/locations/{location}/conversations/{conversation} (required)
  body: object, The request body.
    The object takes the form of:

{ # The conversation resource.
  &quot;agentId&quot;: &quot;A String&quot;, # An opaque, user-specified string representing the human agent who handled the conversation.
  &quot;callMetadata&quot;: { # Call-specific metadata. # Call-specific metadata.
    &quot;agentChannel&quot;: 42, # The audio channel that contains the agent.
    &quot;customerChannel&quot;: 42, # The audio channel that contains the customer.
  },
  &quot;createTime&quot;: &quot;A String&quot;, # Output only. The time at which the conversation was created.
  &quot;dataSource&quot;: { # The conversation source, which is a combination of transcript and audio. # The source of the audio and transcription for the conversation.
    &quot;dialogflowSource&quot;: { # A Dialogflow source of conversation data. # The source when the conversation comes from Dialogflow.
      &quot;audioUri&quot;: &quot;A String&quot;, # Cloud Storage URI that points to a file that contains the conversation audio.
      &quot;dialogflowConversation&quot;: &quot;A String&quot;, # Output only. The name of the Dialogflow conversation that this conversation resource is derived from. Format: projects/{project}/locations/{location}/conversations/{conversation}
    },
    &quot;gcsSource&quot;: { # A Cloud Storage source of conversation data. # A Cloud Storage location specification for the audio and transcript.
      &quot;audioUri&quot;: &quot;A String&quot;, # Cloud Storage URI that points to a file that contains the conversation audio.
      &quot;transcriptUri&quot;: &quot;A String&quot;, # Immutable. Cloud Storage URI that points to a file that contains the conversation transcript.
    },
  },
  &quot;dialogflowIntents&quot;: { # Output only. All the matched Dialogflow intents in the call. The key corresponds to a Dialogflow intent, format: projects/{project}/agent/{agent}/intents/{intent}
    &quot;a_key&quot;: { # The data for a Dialogflow intent. Represents a detected intent in the conversation, e.g. MAKES_PROMISE.
      &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the intent.
    },
  },
  &quot;duration&quot;: &quot;A String&quot;, # Output only. The duration of the conversation.
  &quot;expireTime&quot;: &quot;A String&quot;, # The time at which this conversation should expire. After this time, the conversation data and any associated analyses will be deleted.
  &quot;labels&quot;: { # A map for the user to specify any custom fields. A maximum of 20 labels per conversation is allowed, with a maximum of 256 characters per entry.
    &quot;a_key&quot;: &quot;A String&quot;,
  },
  &quot;languageCode&quot;: &quot;A String&quot;, # A user-specified language code for the conversation.
  &quot;latestAnalysis&quot;: { # The analysis resource. # Output only. The conversation&#x27;s latest analysis, if one exists.
    &quot;analysisResult&quot;: { # The result of an analysis. # Output only. The result of the analysis, which is populated when the analysis finishes.
      &quot;callAnalysisMetadata&quot;: { # Call-specific metadata created during analysis. # Call-specific metadata created by the analysis.
        &quot;annotations&quot;: [ # A list of call annotations that apply to this call.
          { # A piece of metadata that applies to a window of a call.
            &quot;annotationEndBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation ends, inclusive.
              &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
              &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
            },
            &quot;annotationStartBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation starts, inclusive.
              &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
              &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
            },
            &quot;channelTag&quot;: 42, # The channel of the audio where the annotation occurs. For single-channel audio, this field is not populated.
            &quot;entityMentionData&quot;: { # The data for an entity mention annotation. This represents a mention of an `Entity` in the conversation. # Data specifying an entity mention.
              &quot;entityUniqueId&quot;: &quot;A String&quot;, # The key of this entity in conversation entities. Can be used to retrieve the exact `Entity` this mention is attached to.
              &quot;sentiment&quot;: { # The data for a sentiment annotation. # Sentiment expressed for this mention of the entity.
                &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
                &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
              },
              &quot;type&quot;: &quot;A String&quot;, # The type of the entity mention.
            },
            &quot;holdData&quot;: { # The data for a hold annotation. # Data specifying a hold.
            },
            &quot;intentMatchData&quot;: { # The data for an intent match. Represents an intent match for a text segment in the conversation. A text segment can be part of a sentence, a complete sentence, or an utterance with multiple sentences. # Data specifying an intent match.
              &quot;intentUniqueId&quot;: &quot;A String&quot;, # The id of the matched intent. Can be used to retrieve the corresponding intent information.
            },
            &quot;interruptionData&quot;: { # The data for an interruption annotation. # Data specifying an interruption.
            },
            &quot;issueMatchData&quot;: { # The data for an issue match annotation. # Data specifying an issue match.
              &quot;issueAssignment&quot;: { # Information about the issue. # Information about the issue&#x27;s assignment.
                &quot;displayName&quot;: &quot;A String&quot;, # Immutable. Display name of the assigned issue. This field is set at time of analyis and immutable since then.
                &quot;issue&quot;: &quot;A String&quot;, # Resource name of the assigned issue.
                &quot;score&quot;: 3.14, # Score indicating the likelihood of the issue assignment. currently bounded on [0,1].
              },
            },
            &quot;phraseMatchData&quot;: { # The data for a matched phrase matcher. Represents information identifying a phrase matcher for a given match. # Data specifying a phrase match.
              &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the phrase matcher.
              &quot;phraseMatcher&quot;: &quot;A String&quot;, # The unique identifier (the resource name) of the phrase matcher.
            },
            &quot;sentimentData&quot;: { # The data for a sentiment annotation. # Data specifying sentiment.
              &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
              &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
            },
            &quot;silenceData&quot;: { # The data for a silence annotation. # Data specifying silence.
            },
          },
        ],
        &quot;entities&quot;: { # All the entities in the call.
          &quot;a_key&quot;: { # The data for an entity annotation. Represents a phrase in the conversation that is a known entity, such as a person, an organization, or location.
            &quot;displayName&quot;: &quot;A String&quot;, # The representative name for the entity.
            &quot;metadata&quot;: { # Metadata associated with the entity. For most entity types, the metadata is a Wikipedia URL (`wikipedia_url`) and Knowledge Graph MID (`mid`), if they are available. For the metadata associated with other entity types, see the Type table below.
              &quot;a_key&quot;: &quot;A String&quot;,
            },
            &quot;salience&quot;: 3.14, # The salience score associated with the entity in the [0, 1.0] range. The salience score for an entity provides information about the importance or centrality of that entity to the entire document text. Scores closer to 0 are less salient, while scores closer to 1.0 are highly salient.
            &quot;sentiment&quot;: { # The data for a sentiment annotation. # The aggregate sentiment expressed for this entity in the conversation.
              &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
              &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
            },
            &quot;type&quot;: &quot;A String&quot;, # The entity type.
          },
        },
        &quot;intents&quot;: { # All the matched intents in the call.
          &quot;a_key&quot;: { # The data for an intent. Represents a detected intent in the conversation, for example MAKES_PROMISE.
            &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the intent.
            &quot;id&quot;: &quot;A String&quot;, # The unique identifier of the intent.
          },
        },
        &quot;issueModelResult&quot;: { # Issue Modeling result on a conversation. # Overall conversation-level issue modeling result.
          &quot;issueModel&quot;: &quot;A String&quot;, # Issue model that generates the result. Format: projects/{project}/locations/{location}/issueModels/{issue_model}
          &quot;issues&quot;: [ # All the matched issues.
            { # Information about the issue.
              &quot;displayName&quot;: &quot;A String&quot;, # Immutable. Display name of the assigned issue. This field is set at time of analyis and immutable since then.
              &quot;issue&quot;: &quot;A String&quot;, # Resource name of the assigned issue.
              &quot;score&quot;: 3.14, # Score indicating the likelihood of the issue assignment. currently bounded on [0,1].
            },
          ],
        },
        &quot;phraseMatchers&quot;: { # All the matched phrase matchers in the call.
          &quot;a_key&quot;: { # The data for a matched phrase matcher. Represents information identifying a phrase matcher for a given match.
            &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the phrase matcher.
            &quot;phraseMatcher&quot;: &quot;A String&quot;, # The unique identifier (the resource name) of the phrase matcher.
          },
        },
        &quot;sentiments&quot;: [ # Overall conversation-level sentiment for each channel of the call.
          { # One channel of conversation-level sentiment data.
            &quot;channelTag&quot;: 42, # The channel of the audio that the data applies to.
            &quot;sentimentData&quot;: { # The data for a sentiment annotation. # Data specifying sentiment.
              &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
              &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
            },
          },
        ],
      },
      &quot;endTime&quot;: &quot;A String&quot;, # The time at which the analysis ended.
    },
    &quot;annotatorSelector&quot;: { # Selector of all available annotators and phrase matchers to run. # To select the annotators to run and the phrase matchers to use (if any). If not specified, all annotators will be run.
      &quot;issueModels&quot;: [ # The issue model to run. If not provided, the most recently deployed topic model will be used. The provided issue model will only be used for inference if the issue model is deployed and if run_issue_model_annotator is set to true. If more than one issue model is provided, only the first provided issue model will be used for inference.
        &quot;A String&quot;,
      ],
      &quot;phraseMatchers&quot;: [ # The list of phrase matchers to run. If not provided, all active phrase matchers will be used. If inactive phrase matchers are provided, they will not be used. Phrase matchers will be run only if run_phrase_matcher_annotator is set to true. Format: projects/{project}/locations/{location}/phraseMatchers/{phrase_matcher}
        &quot;A String&quot;,
      ],
      &quot;runEntityAnnotator&quot;: True or False, # Whether to run the entity annotator.
      &quot;runIntentAnnotator&quot;: True or False, # Whether to run the intent annotator.
      &quot;runInterruptionAnnotator&quot;: True or False, # Whether to run the interruption annotator.
      &quot;runIssueModelAnnotator&quot;: True or False, # Whether to run the issue model annotator. A model should have already been deployed for this to take effect.
      &quot;runPhraseMatcherAnnotator&quot;: True or False, # Whether to run the active phrase matcher annotator(s).
      &quot;runSentimentAnnotator&quot;: True or False, # Whether to run the sentiment annotator.
      &quot;runSilenceAnnotator&quot;: True or False, # Whether to run the silence annotator.
    },
    &quot;createTime&quot;: &quot;A String&quot;, # Output only. The time at which the analysis was created, which occurs when the long-running operation completes.
    &quot;name&quot;: &quot;A String&quot;, # Immutable. The resource name of the analysis. Format: projects/{project}/locations/{location}/conversations/{conversation}/analyses/{analysis}
    &quot;requestTime&quot;: &quot;A String&quot;, # Output only. The time at which the analysis was requested.
  },
  &quot;medium&quot;: &quot;A String&quot;, # Immutable. The conversation medium, if unspecified will default to PHONE_CALL.
  &quot;name&quot;: &quot;A String&quot;, # Immutable. The resource name of the conversation. Format: projects/{project}/locations/{location}/conversations/{conversation}
  &quot;obfuscatedUserId&quot;: &quot;A String&quot;, # Obfuscated user ID which the customer sent to us.
  &quot;runtimeAnnotations&quot;: [ # Output only. The annotations that were generated during the customer and agent interaction.
    { # An annotation that was generated during the customer and agent interaction.
      &quot;annotationId&quot;: &quot;A String&quot;, # The unique identifier of the annotation. Format: projects/{project}/locations/{location}/conversationDatasets/{dataset}/conversationDataItems/{data_item}/conversationAnnotations/{annotation}
      &quot;answerFeedback&quot;: { # The feedback that the customer has about a certain answer in the conversation. # The feedback that the customer has about the answer in `data`.
        &quot;clicked&quot;: True or False, # Indicates whether an answer or item was clicked by the human agent.
        &quot;correctnessLevel&quot;: &quot;A String&quot;, # The correctness level of an answer.
        &quot;displayed&quot;: True or False, # Indicates whether an answer or item was displayed to the human agent in the agent desktop UI.
      },
      &quot;articleSuggestion&quot;: { # Agent Assist Article Suggestion data. # Agent Assist Article Suggestion data.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this article is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the Article Suggestion and the document that it originates from.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
        &quot;source&quot;: &quot;A String&quot;, # The knowledge document that this answer was extracted from. Format: projects/{project}/knowledgeBases/{knowledge_base}/documents/{document}
        &quot;title&quot;: &quot;A String&quot;, # Article title.
        &quot;uri&quot;: &quot;A String&quot;, # Article URI.
      },
      &quot;createTime&quot;: &quot;A String&quot;, # The time at which this annotation was created.
      &quot;dialogflowInteraction&quot;: { # Dialogflow interaction data. # Dialogflow interaction data.
        &quot;confidence&quot;: 3.14, # The confidence of the match ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;dialogflowIntentId&quot;: &quot;A String&quot;, # The Dialogflow intent resource path. Format: projects/{project}/agent/{agent}/intents/{intent}
      },
      &quot;endBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation ends, inclusive.
        &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
        &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
      },
      &quot;faqAnswer&quot;: { # Agent Assist frequently-asked-question answer data. # Agent Assist FAQ answer data.
        &quot;answer&quot;: &quot;A String&quot;, # The piece of text from the `source` knowledge base document.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this answer is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the FAQ answer and the document that it originates from.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
        &quot;question&quot;: &quot;A String&quot;, # The corresponding FAQ question.
        &quot;source&quot;: &quot;A String&quot;, # The knowledge document that this answer was extracted from. Format: projects/{project}/knowledgeBases/{knowledge_base}/documents/{document}.
      },
      &quot;smartComposeSuggestion&quot;: { # Agent Assist Smart Compose suggestion data. # Agent Assist Smart Compose suggestion data.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this suggestion is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the Smart Compose suggestion and the document from which it originates.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
        &quot;suggestion&quot;: &quot;A String&quot;, # The content of the suggestion.
      },
      &quot;smartReply&quot;: { # Agent Assist Smart Reply data. # Agent Assist Smart Reply data.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this reply is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the Smart Reply and the document from which it originates.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
        &quot;reply&quot;: &quot;A String&quot;, # The content of the reply.
      },
      &quot;startBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation starts, inclusive.
        &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
        &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
      },
    },
  ],
  &quot;startTime&quot;: &quot;A String&quot;, # The time at which the conversation started.
  &quot;transcript&quot;: { # A message representing the transcript of a conversation. # Output only. The conversation transcript.
    &quot;transcriptSegments&quot;: [ # A list of sequential transcript segments that comprise the conversation.
      { # A segment of a full transcript.
        &quot;channelTag&quot;: 42, # For conversations derived from multi-channel audio, this is the channel number corresponding to the audio from that channel. For audioChannelCount = N, its output values can range from &#x27;1&#x27; to &#x27;N&#x27;. A channel tag of 0 indicates that the audio is mono.
        &quot;confidence&quot;: 3.14, # A confidence estimate between 0.0 and 1.0 of the fidelity of this segment. A default value of 0.0 indicates that the value is unset.
        &quot;dialogflowSegmentMetadata&quot;: { # Metadata from Dialogflow relating to the current transcript segment. # CCAI metadata relating to the current transcript segment.
          &quot;smartReplyAllowlistCovered&quot;: True or False, # Whether the transcript segment was covered under the configured smart reply allowlist in Agent Assist.
        },
        &quot;languageCode&quot;: &quot;A String&quot;, # The language code of this segment as a [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag. Example: &quot;en-US&quot;.
        &quot;messageTime&quot;: &quot;A String&quot;, # The time that the message occurred, if provided.
        &quot;segmentParticipant&quot;: { # The call participant speaking for a given utterance. # The participant of this segment.
          &quot;dialogflowParticipant&quot;: &quot;A String&quot;, # Deprecated. Use `dialogflow_participant_name` instead. The name of the Dialogflow participant. Format: projects/{project}/locations/{location}/conversations/{conversation}/participants/{participant}
          &quot;dialogflowParticipantName&quot;: &quot;A String&quot;, # The name of the participant provided by Dialogflow. Format: projects/{project}/locations/{location}/conversations/{conversation}/participants/{participant}
          &quot;obfuscatedExternalUserId&quot;: &quot;A String&quot;, # Obfuscated user ID from Dialogflow.
          &quot;role&quot;: &quot;A String&quot;, # The role of the participant.
          &quot;userId&quot;: &quot;A String&quot;, # A user-specified ID representing the participant.
        },
        &quot;sentiment&quot;: { # The data for a sentiment annotation. # The sentiment for this transcript segment.
          &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
          &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
        },
        &quot;text&quot;: &quot;A String&quot;, # The text of this segment.
        &quot;words&quot;: [ # A list of the word-specific information for each word in the segment.
          { # Word-level info for words in a transcript.
            &quot;confidence&quot;: 3.14, # A confidence estimate between 0.0 and 1.0 of the fidelity of this word. A default value of 0.0 indicates that the value is unset.
            &quot;endOffset&quot;: &quot;A String&quot;, # Time offset of the end of this word relative to the beginning of the total conversation.
            &quot;startOffset&quot;: &quot;A String&quot;, # Time offset of the start of this word relative to the beginning of the total conversation.
            &quot;word&quot;: &quot;A String&quot;, # The word itself. Includes punctuation marks that surround the word.
          },
        ],
      },
    ],
  },
  &quot;ttl&quot;: &quot;A String&quot;, # Input only. The TTL for this resource. If specified, then this TTL will be used to calculate the expire time.
  &quot;turnCount&quot;: 42, # Output only. The number of turns in the conversation.
  &quot;updateTime&quot;: &quot;A String&quot;, # Output only. The most recent time at which the conversation was updated.
}

  updateMask: string, The list of fields to be updated.
  x__xgafv: string, V1 error format.
    Allowed values
      1 - v1 error format
      2 - v2 error format

Returns:
  An object of the form:

    { # The conversation resource.
  &quot;agentId&quot;: &quot;A String&quot;, # An opaque, user-specified string representing the human agent who handled the conversation.
  &quot;callMetadata&quot;: { # Call-specific metadata. # Call-specific metadata.
    &quot;agentChannel&quot;: 42, # The audio channel that contains the agent.
    &quot;customerChannel&quot;: 42, # The audio channel that contains the customer.
  },
  &quot;createTime&quot;: &quot;A String&quot;, # Output only. The time at which the conversation was created.
  &quot;dataSource&quot;: { # The conversation source, which is a combination of transcript and audio. # The source of the audio and transcription for the conversation.
    &quot;dialogflowSource&quot;: { # A Dialogflow source of conversation data. # The source when the conversation comes from Dialogflow.
      &quot;audioUri&quot;: &quot;A String&quot;, # Cloud Storage URI that points to a file that contains the conversation audio.
      &quot;dialogflowConversation&quot;: &quot;A String&quot;, # Output only. The name of the Dialogflow conversation that this conversation resource is derived from. Format: projects/{project}/locations/{location}/conversations/{conversation}
    },
    &quot;gcsSource&quot;: { # A Cloud Storage source of conversation data. # A Cloud Storage location specification for the audio and transcript.
      &quot;audioUri&quot;: &quot;A String&quot;, # Cloud Storage URI that points to a file that contains the conversation audio.
      &quot;transcriptUri&quot;: &quot;A String&quot;, # Immutable. Cloud Storage URI that points to a file that contains the conversation transcript.
    },
  },
  &quot;dialogflowIntents&quot;: { # Output only. All the matched Dialogflow intents in the call. The key corresponds to a Dialogflow intent, format: projects/{project}/agent/{agent}/intents/{intent}
    &quot;a_key&quot;: { # The data for a Dialogflow intent. Represents a detected intent in the conversation, e.g. MAKES_PROMISE.
      &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the intent.
    },
  },
  &quot;duration&quot;: &quot;A String&quot;, # Output only. The duration of the conversation.
  &quot;expireTime&quot;: &quot;A String&quot;, # The time at which this conversation should expire. After this time, the conversation data and any associated analyses will be deleted.
  &quot;labels&quot;: { # A map for the user to specify any custom fields. A maximum of 20 labels per conversation is allowed, with a maximum of 256 characters per entry.
    &quot;a_key&quot;: &quot;A String&quot;,
  },
  &quot;languageCode&quot;: &quot;A String&quot;, # A user-specified language code for the conversation.
  &quot;latestAnalysis&quot;: { # The analysis resource. # Output only. The conversation&#x27;s latest analysis, if one exists.
    &quot;analysisResult&quot;: { # The result of an analysis. # Output only. The result of the analysis, which is populated when the analysis finishes.
      &quot;callAnalysisMetadata&quot;: { # Call-specific metadata created during analysis. # Call-specific metadata created by the analysis.
        &quot;annotations&quot;: [ # A list of call annotations that apply to this call.
          { # A piece of metadata that applies to a window of a call.
            &quot;annotationEndBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation ends, inclusive.
              &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
              &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
            },
            &quot;annotationStartBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation starts, inclusive.
              &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
              &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
            },
            &quot;channelTag&quot;: 42, # The channel of the audio where the annotation occurs. For single-channel audio, this field is not populated.
            &quot;entityMentionData&quot;: { # The data for an entity mention annotation. This represents a mention of an `Entity` in the conversation. # Data specifying an entity mention.
              &quot;entityUniqueId&quot;: &quot;A String&quot;, # The key of this entity in conversation entities. Can be used to retrieve the exact `Entity` this mention is attached to.
              &quot;sentiment&quot;: { # The data for a sentiment annotation. # Sentiment expressed for this mention of the entity.
                &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
                &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
              },
              &quot;type&quot;: &quot;A String&quot;, # The type of the entity mention.
            },
            &quot;holdData&quot;: { # The data for a hold annotation. # Data specifying a hold.
            },
            &quot;intentMatchData&quot;: { # The data for an intent match. Represents an intent match for a text segment in the conversation. A text segment can be part of a sentence, a complete sentence, or an utterance with multiple sentences. # Data specifying an intent match.
              &quot;intentUniqueId&quot;: &quot;A String&quot;, # The id of the matched intent. Can be used to retrieve the corresponding intent information.
            },
            &quot;interruptionData&quot;: { # The data for an interruption annotation. # Data specifying an interruption.
            },
            &quot;issueMatchData&quot;: { # The data for an issue match annotation. # Data specifying an issue match.
              &quot;issueAssignment&quot;: { # Information about the issue. # Information about the issue&#x27;s assignment.
                &quot;displayName&quot;: &quot;A String&quot;, # Immutable. Display name of the assigned issue. This field is set at time of analyis and immutable since then.
                &quot;issue&quot;: &quot;A String&quot;, # Resource name of the assigned issue.
                &quot;score&quot;: 3.14, # Score indicating the likelihood of the issue assignment. currently bounded on [0,1].
              },
            },
            &quot;phraseMatchData&quot;: { # The data for a matched phrase matcher. Represents information identifying a phrase matcher for a given match. # Data specifying a phrase match.
              &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the phrase matcher.
              &quot;phraseMatcher&quot;: &quot;A String&quot;, # The unique identifier (the resource name) of the phrase matcher.
            },
            &quot;sentimentData&quot;: { # The data for a sentiment annotation. # Data specifying sentiment.
              &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
              &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
            },
            &quot;silenceData&quot;: { # The data for a silence annotation. # Data specifying silence.
            },
          },
        ],
        &quot;entities&quot;: { # All the entities in the call.
          &quot;a_key&quot;: { # The data for an entity annotation. Represents a phrase in the conversation that is a known entity, such as a person, an organization, or location.
            &quot;displayName&quot;: &quot;A String&quot;, # The representative name for the entity.
            &quot;metadata&quot;: { # Metadata associated with the entity. For most entity types, the metadata is a Wikipedia URL (`wikipedia_url`) and Knowledge Graph MID (`mid`), if they are available. For the metadata associated with other entity types, see the Type table below.
              &quot;a_key&quot;: &quot;A String&quot;,
            },
            &quot;salience&quot;: 3.14, # The salience score associated with the entity in the [0, 1.0] range. The salience score for an entity provides information about the importance or centrality of that entity to the entire document text. Scores closer to 0 are less salient, while scores closer to 1.0 are highly salient.
            &quot;sentiment&quot;: { # The data for a sentiment annotation. # The aggregate sentiment expressed for this entity in the conversation.
              &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
              &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
            },
            &quot;type&quot;: &quot;A String&quot;, # The entity type.
          },
        },
        &quot;intents&quot;: { # All the matched intents in the call.
          &quot;a_key&quot;: { # The data for an intent. Represents a detected intent in the conversation, for example MAKES_PROMISE.
            &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the intent.
            &quot;id&quot;: &quot;A String&quot;, # The unique identifier of the intent.
          },
        },
        &quot;issueModelResult&quot;: { # Issue Modeling result on a conversation. # Overall conversation-level issue modeling result.
          &quot;issueModel&quot;: &quot;A String&quot;, # Issue model that generates the result. Format: projects/{project}/locations/{location}/issueModels/{issue_model}
          &quot;issues&quot;: [ # All the matched issues.
            { # Information about the issue.
              &quot;displayName&quot;: &quot;A String&quot;, # Immutable. Display name of the assigned issue. This field is set at time of analyis and immutable since then.
              &quot;issue&quot;: &quot;A String&quot;, # Resource name of the assigned issue.
              &quot;score&quot;: 3.14, # Score indicating the likelihood of the issue assignment. currently bounded on [0,1].
            },
          ],
        },
        &quot;phraseMatchers&quot;: { # All the matched phrase matchers in the call.
          &quot;a_key&quot;: { # The data for a matched phrase matcher. Represents information identifying a phrase matcher for a given match.
            &quot;displayName&quot;: &quot;A String&quot;, # The human-readable name of the phrase matcher.
            &quot;phraseMatcher&quot;: &quot;A String&quot;, # The unique identifier (the resource name) of the phrase matcher.
          },
        },
        &quot;sentiments&quot;: [ # Overall conversation-level sentiment for each channel of the call.
          { # One channel of conversation-level sentiment data.
            &quot;channelTag&quot;: 42, # The channel of the audio that the data applies to.
            &quot;sentimentData&quot;: { # The data for a sentiment annotation. # Data specifying sentiment.
              &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
              &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
            },
          },
        ],
      },
      &quot;endTime&quot;: &quot;A String&quot;, # The time at which the analysis ended.
    },
    &quot;annotatorSelector&quot;: { # Selector of all available annotators and phrase matchers to run. # To select the annotators to run and the phrase matchers to use (if any). If not specified, all annotators will be run.
      &quot;issueModels&quot;: [ # The issue model to run. If not provided, the most recently deployed topic model will be used. The provided issue model will only be used for inference if the issue model is deployed and if run_issue_model_annotator is set to true. If more than one issue model is provided, only the first provided issue model will be used for inference.
        &quot;A String&quot;,
      ],
      &quot;phraseMatchers&quot;: [ # The list of phrase matchers to run. If not provided, all active phrase matchers will be used. If inactive phrase matchers are provided, they will not be used. Phrase matchers will be run only if run_phrase_matcher_annotator is set to true. Format: projects/{project}/locations/{location}/phraseMatchers/{phrase_matcher}
        &quot;A String&quot;,
      ],
      &quot;runEntityAnnotator&quot;: True or False, # Whether to run the entity annotator.
      &quot;runIntentAnnotator&quot;: True or False, # Whether to run the intent annotator.
      &quot;runInterruptionAnnotator&quot;: True or False, # Whether to run the interruption annotator.
      &quot;runIssueModelAnnotator&quot;: True or False, # Whether to run the issue model annotator. A model should have already been deployed for this to take effect.
      &quot;runPhraseMatcherAnnotator&quot;: True or False, # Whether to run the active phrase matcher annotator(s).
      &quot;runSentimentAnnotator&quot;: True or False, # Whether to run the sentiment annotator.
      &quot;runSilenceAnnotator&quot;: True or False, # Whether to run the silence annotator.
    },
    &quot;createTime&quot;: &quot;A String&quot;, # Output only. The time at which the analysis was created, which occurs when the long-running operation completes.
    &quot;name&quot;: &quot;A String&quot;, # Immutable. The resource name of the analysis. Format: projects/{project}/locations/{location}/conversations/{conversation}/analyses/{analysis}
    &quot;requestTime&quot;: &quot;A String&quot;, # Output only. The time at which the analysis was requested.
  },
  &quot;medium&quot;: &quot;A String&quot;, # Immutable. The conversation medium, if unspecified will default to PHONE_CALL.
  &quot;name&quot;: &quot;A String&quot;, # Immutable. The resource name of the conversation. Format: projects/{project}/locations/{location}/conversations/{conversation}
  &quot;obfuscatedUserId&quot;: &quot;A String&quot;, # Obfuscated user ID which the customer sent to us.
  &quot;runtimeAnnotations&quot;: [ # Output only. The annotations that were generated during the customer and agent interaction.
    { # An annotation that was generated during the customer and agent interaction.
      &quot;annotationId&quot;: &quot;A String&quot;, # The unique identifier of the annotation. Format: projects/{project}/locations/{location}/conversationDatasets/{dataset}/conversationDataItems/{data_item}/conversationAnnotations/{annotation}
      &quot;answerFeedback&quot;: { # The feedback that the customer has about a certain answer in the conversation. # The feedback that the customer has about the answer in `data`.
        &quot;clicked&quot;: True or False, # Indicates whether an answer or item was clicked by the human agent.
        &quot;correctnessLevel&quot;: &quot;A String&quot;, # The correctness level of an answer.
        &quot;displayed&quot;: True or False, # Indicates whether an answer or item was displayed to the human agent in the agent desktop UI.
      },
      &quot;articleSuggestion&quot;: { # Agent Assist Article Suggestion data. # Agent Assist Article Suggestion data.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this article is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the Article Suggestion and the document that it originates from.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
        &quot;source&quot;: &quot;A String&quot;, # The knowledge document that this answer was extracted from. Format: projects/{project}/knowledgeBases/{knowledge_base}/documents/{document}
        &quot;title&quot;: &quot;A String&quot;, # Article title.
        &quot;uri&quot;: &quot;A String&quot;, # Article URI.
      },
      &quot;createTime&quot;: &quot;A String&quot;, # The time at which this annotation was created.
      &quot;dialogflowInteraction&quot;: { # Dialogflow interaction data. # Dialogflow interaction data.
        &quot;confidence&quot;: 3.14, # The confidence of the match ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;dialogflowIntentId&quot;: &quot;A String&quot;, # The Dialogflow intent resource path. Format: projects/{project}/agent/{agent}/intents/{intent}
      },
      &quot;endBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation ends, inclusive.
        &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
        &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
      },
      &quot;faqAnswer&quot;: { # Agent Assist frequently-asked-question answer data. # Agent Assist FAQ answer data.
        &quot;answer&quot;: &quot;A String&quot;, # The piece of text from the `source` knowledge base document.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this answer is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the FAQ answer and the document that it originates from.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
        &quot;question&quot;: &quot;A String&quot;, # The corresponding FAQ question.
        &quot;source&quot;: &quot;A String&quot;, # The knowledge document that this answer was extracted from. Format: projects/{project}/knowledgeBases/{knowledge_base}/documents/{document}.
      },
      &quot;smartComposeSuggestion&quot;: { # Agent Assist Smart Compose suggestion data. # Agent Assist Smart Compose suggestion data.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this suggestion is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the Smart Compose suggestion and the document from which it originates.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
        &quot;suggestion&quot;: &quot;A String&quot;, # The content of the suggestion.
      },
      &quot;smartReply&quot;: { # Agent Assist Smart Reply data. # Agent Assist Smart Reply data.
        &quot;confidenceScore&quot;: 3.14, # The system&#x27;s confidence score that this reply is a good match for this conversation, ranging from 0.0 (completely uncertain) to 1.0 (completely certain).
        &quot;metadata&quot;: { # Map that contains metadata about the Smart Reply and the document from which it originates.
          &quot;a_key&quot;: &quot;A String&quot;,
        },
        &quot;queryRecord&quot;: &quot;A String&quot;, # The name of the answer record. Format: projects/{project}/locations/{location}/answerRecords/{answer_record}
        &quot;reply&quot;: &quot;A String&quot;, # The content of the reply.
      },
      &quot;startBoundary&quot;: { # A point in a conversation that marks the start or the end of an annotation. # The boundary in the conversation where the annotation starts, inclusive.
        &quot;transcriptIndex&quot;: 42, # The index in the sequence of transcribed pieces of the conversation where the boundary is located. This index starts at zero.
        &quot;wordIndex&quot;: 42, # The word index of this boundary with respect to the first word in the transcript piece. This index starts at zero.
      },
    },
  ],
  &quot;startTime&quot;: &quot;A String&quot;, # The time at which the conversation started.
  &quot;transcript&quot;: { # A message representing the transcript of a conversation. # Output only. The conversation transcript.
    &quot;transcriptSegments&quot;: [ # A list of sequential transcript segments that comprise the conversation.
      { # A segment of a full transcript.
        &quot;channelTag&quot;: 42, # For conversations derived from multi-channel audio, this is the channel number corresponding to the audio from that channel. For audioChannelCount = N, its output values can range from &#x27;1&#x27; to &#x27;N&#x27;. A channel tag of 0 indicates that the audio is mono.
        &quot;confidence&quot;: 3.14, # A confidence estimate between 0.0 and 1.0 of the fidelity of this segment. A default value of 0.0 indicates that the value is unset.
        &quot;dialogflowSegmentMetadata&quot;: { # Metadata from Dialogflow relating to the current transcript segment. # CCAI metadata relating to the current transcript segment.
          &quot;smartReplyAllowlistCovered&quot;: True or False, # Whether the transcript segment was covered under the configured smart reply allowlist in Agent Assist.
        },
        &quot;languageCode&quot;: &quot;A String&quot;, # The language code of this segment as a [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag. Example: &quot;en-US&quot;.
        &quot;messageTime&quot;: &quot;A String&quot;, # The time that the message occurred, if provided.
        &quot;segmentParticipant&quot;: { # The call participant speaking for a given utterance. # The participant of this segment.
          &quot;dialogflowParticipant&quot;: &quot;A String&quot;, # Deprecated. Use `dialogflow_participant_name` instead. The name of the Dialogflow participant. Format: projects/{project}/locations/{location}/conversations/{conversation}/participants/{participant}
          &quot;dialogflowParticipantName&quot;: &quot;A String&quot;, # The name of the participant provided by Dialogflow. Format: projects/{project}/locations/{location}/conversations/{conversation}/participants/{participant}
          &quot;obfuscatedExternalUserId&quot;: &quot;A String&quot;, # Obfuscated user ID from Dialogflow.
          &quot;role&quot;: &quot;A String&quot;, # The role of the participant.
          &quot;userId&quot;: &quot;A String&quot;, # A user-specified ID representing the participant.
        },
        &quot;sentiment&quot;: { # The data for a sentiment annotation. # The sentiment for this transcript segment.
          &quot;magnitude&quot;: 3.14, # A non-negative number from 0 to infinity which represents the abolute magnitude of sentiment regardless of score.
          &quot;score&quot;: 3.14, # The sentiment score between -1.0 (negative) and 1.0 (positive).
        },
        &quot;text&quot;: &quot;A String&quot;, # The text of this segment.
        &quot;words&quot;: [ # A list of the word-specific information for each word in the segment.
          { # Word-level info for words in a transcript.
            &quot;confidence&quot;: 3.14, # A confidence estimate between 0.0 and 1.0 of the fidelity of this word. A default value of 0.0 indicates that the value is unset.
            &quot;endOffset&quot;: &quot;A String&quot;, # Time offset of the end of this word relative to the beginning of the total conversation.
            &quot;startOffset&quot;: &quot;A String&quot;, # Time offset of the start of this word relative to the beginning of the total conversation.
            &quot;word&quot;: &quot;A String&quot;, # The word itself. Includes punctuation marks that surround the word.
          },
        ],
      },
    ],
  },
  &quot;ttl&quot;: &quot;A String&quot;, # Input only. The TTL for this resource. If specified, then this TTL will be used to calculate the expire time.
  &quot;turnCount&quot;: 42, # Output only. The number of turns in the conversation.
  &quot;updateTime&quot;: &quot;A String&quot;, # Output only. The most recent time at which the conversation was updated.
}</pre>
</div>

</body></html>