<html><body>
<style>

body, h1, h2, h3, div, span, p, pre, a {
  margin: 0;
  padding: 0;
  border: 0;
  font-weight: inherit;
  font-style: inherit;
  font-size: 100%;
  font-family: inherit;
  vertical-align: baseline;
}

body {
  font-size: 13px;
  padding: 1em;
}

h1 {
  font-size: 26px;
  margin-bottom: 1em;
}

h2 {
  font-size: 24px;
  margin-bottom: 1em;
}

h3 {
  font-size: 20px;
  margin-bottom: 1em;
  margin-top: 1em;
}

pre, code {
  line-height: 1.5;
  font-family: Monaco, 'DejaVu Sans Mono', 'Bitstream Vera Sans Mono', 'Lucida Console', monospace;
}

pre {
  margin-top: 0.5em;
}

h1, h2, h3, p {
  font-family: Arial, sans serif;
}

h1, h2, h3 {
  border-bottom: solid #CCC 1px;
}

.toc_element {
  margin-top: 0.5em;
}

.firstline {
  margin-left: 2 em;
}

.method  {
  margin-top: 1em;
  border: solid 1px #CCC;
  padding: 1em;
  background: #EEE;
}

.details {
  font-weight: bold;
  font-size: 14px;
}

</style>

<h1><a href="bigquerydatatransfer_v1.html">BigQuery Data Transfer API</a> . <a href="bigquerydatatransfer_v1.projects.html">projects</a> . <a href="bigquerydatatransfer_v1.projects.transferConfigs.html">transferConfigs</a></h1>
<h2>Instance Methods</h2>
<p class="toc_element">
  <code><a href="bigquerydatatransfer_v1.projects.transferConfigs.runs.html">runs()</a></code>
</p>
<p class="firstline">Returns the runs Resource.</p>

<p class="toc_element">
  <code><a href="#close">close()</a></code></p>
<p class="firstline">Close httplib2 connections.</p>
<p class="toc_element">
  <code><a href="#create">create(parent, authorizationCode=None, body=None, serviceAccountName=None, versionInfo=None, x__xgafv=None)</a></code></p>
<p class="firstline">Creates a new data transfer configuration.</p>
<p class="toc_element">
  <code><a href="#delete">delete(name, x__xgafv=None)</a></code></p>
<p class="firstline">Deletes a data transfer configuration, including any associated transfer runs and logs.</p>
<p class="toc_element">
  <code><a href="#get">get(name, x__xgafv=None)</a></code></p>
<p class="firstline">Returns information about a data transfer config.</p>
<p class="toc_element">
  <code><a href="#list">list(parent, dataSourceIds=None, pageSize=None, pageToken=None, x__xgafv=None)</a></code></p>
<p class="firstline">Returns information about all transfer configs owned by a project in the specified location.</p>
<p class="toc_element">
  <code><a href="#list_next">list_next()</a></code></p>
<p class="firstline">Retrieves the next page of results.</p>
<p class="toc_element">
  <code><a href="#patch">patch(name, authorizationCode=None, body=None, serviceAccountName=None, updateMask=None, versionInfo=None, x__xgafv=None)</a></code></p>
<p class="firstline">Updates a data transfer configuration. All fields must be set, even if they are not updated.</p>
<p class="toc_element">
  <code><a href="#scheduleRuns">scheduleRuns(parent, body=None, x__xgafv=None)</a></code></p>
<p class="firstline">Creates transfer runs for a time range [start_time, end_time]. For each date - or whatever granularity the data source supports - in the range, one transfer run is created. Note that runs are created per UTC time in the time range. DEPRECATED: use StartManualTransferRuns instead.</p>
<p class="toc_element">
  <code><a href="#startManualRuns">startManualRuns(parent, body=None, x__xgafv=None)</a></code></p>
<p class="firstline">Start manual transfer runs to be executed now with schedule_time equal to current time. The transfer runs can be created for a time range where the run_time is between start_time (inclusive) and end_time (exclusive), or for a specific run_time.</p>
<h3>Method Details</h3>
<div class="method">
    <code class="details" id="close">close()</code>
  <pre>Close httplib2 connections.</pre>
</div>

<div class="method">
    <code class="details" id="create">create(parent, authorizationCode=None, body=None, serviceAccountName=None, versionInfo=None, x__xgafv=None)</code>
  <pre>Creates a new data transfer configuration.

Args:
  parent: string, Required. The BigQuery project id where the transfer configuration should be created. Must be in the format projects/{project_id}/locations/{location_id} or projects/{project_id}. If specified location and location of the destination bigquery dataset do not match - the request will fail. (required)
  body: object, The request body.
    The object takes the form of:

{ # Represents a data transfer configuration. A transfer configuration contains all metadata needed to perform a data transfer. For example, `destination_dataset_id` specifies where data should be stored. When a new transfer configuration is created, the specified `destination_dataset_id` is created when needed and shared with the appropriate data source service account.
  &quot;dataRefreshWindowDays&quot;: 42, # The number of days to look back to automatically refresh the data. For example, if `data_refresh_window_days = 10`, then every day BigQuery reingests data for [today-10, today-1], rather than ingesting data for just [today-1]. Only valid if the data source supports the feature. Set the value to 0 to use the default value.
  &quot;dataSourceId&quot;: &quot;A String&quot;, # Data source ID. This cannot be changed once data transfer is created. The full list of available data source IDs can be returned through an API call: https://cloud.google.com/bigquery-transfer/docs/reference/datatransfer/rest/v1/projects.locations.dataSources/list
  &quot;datasetRegion&quot;: &quot;A String&quot;, # Output only. Region in which BigQuery dataset is located.
  &quot;destinationDatasetId&quot;: &quot;A String&quot;, # The BigQuery target dataset id.
  &quot;disabled&quot;: True or False, # Is this config disabled. When set to true, no runs are scheduled for a given transfer.
  &quot;displayName&quot;: &quot;A String&quot;, # User specified display name for the data transfer.
  &quot;emailPreferences&quot;: { # Represents preferences for sending email notifications for transfer run events. # Email notifications will be sent according to these preferences to the email address of the user who owns this transfer config.
    &quot;enableFailureEmail&quot;: True or False, # If true, email notifications will be sent on transfer run failures.
  },
  &quot;name&quot;: &quot;A String&quot;, # The resource name of the transfer config. Transfer config names have the form `projects/{project_id}/locations/{region}/transferConfigs/{config_id}`. Where `config_id` is usually a uuid, even though it is not guaranteed or required. The name is ignored when creating a transfer config.
  &quot;nextRunTime&quot;: &quot;A String&quot;, # Output only. Next time when data transfer will run.
  &quot;notificationPubsubTopic&quot;: &quot;A String&quot;, # Pub/Sub topic where notifications will be sent after transfer runs associated with this transfer config finish. The format for specifying a pubsub topic is: `projects/{project}/topics/{topic}`
  &quot;ownerInfo&quot;: { # Information about a user. # Output only. Information about the user whose credentials are used to transfer data. Populated only for `transferConfigs.get` requests. In case the user information is not available, this field will not be populated.
    &quot;email&quot;: &quot;A String&quot;, # E-mail address of the user.
  },
  &quot;params&quot;: { # Parameters specific to each data source. For more information see the bq tab in the &#x27;Setting up a data transfer&#x27; section for each data source. For example the parameters for Cloud Storage transfers are listed here: https://cloud.google.com/bigquery-transfer/docs/cloud-storage-transfer#bq
    &quot;a_key&quot;: &quot;&quot;, # Properties of the object.
  },
  &quot;schedule&quot;: &quot;A String&quot;, # Data transfer schedule. If the data source does not support a custom schedule, this should be empty. If it is empty, the default value for the data source will be used. The specified times are in UTC. Examples of valid format: `1st,3rd monday of month 15:30`, `every wed,fri of jan,jun 13:15`, and `first sunday of quarter 00:00`. See more explanation about the format here: https://cloud.google.com/appengine/docs/flexible/python/scheduling-jobs-with-cron-yaml#the_schedule_format NOTE: The minimum interval time between recurring transfers depends on the data source; refer to the documentation for your data source.
  &quot;scheduleOptions&quot;: { # Options customizing the data transfer schedule. # Options customizing the data transfer schedule.
    &quot;disableAutoScheduling&quot;: True or False, # If true, automatic scheduling of data transfer runs for this configuration will be disabled. The runs can be started on ad-hoc basis using StartManualTransferRuns API. When automatic scheduling is disabled, the TransferConfig.schedule field will be ignored.
    &quot;endTime&quot;: &quot;A String&quot;, # Defines time to stop scheduling transfer runs. A transfer run cannot be scheduled at or after the end time. The end time can be changed at any moment. The time when a data transfer can be trigerred manually is not limited by this option.
    &quot;startTime&quot;: &quot;A String&quot;, # Specifies time to start scheduling transfer runs. The first run will be scheduled at or after the start time according to a recurrence pattern defined in the schedule string. The start time can be changed at any moment. The time when a data transfer can be trigerred manually is not limited by this option.
  },
  &quot;state&quot;: &quot;A String&quot;, # Output only. State of the most recently updated transfer run.
  &quot;updateTime&quot;: &quot;A String&quot;, # Output only. Data transfer modification time. Ignored by server on input.
  &quot;userId&quot;: &quot;A String&quot;, # Deprecated. Unique ID of the user on whose behalf transfer is done.
}

  authorizationCode: string, Optional OAuth2 authorization code to use with this transfer configuration. This is required only if `transferConfig.dataSourceId` is &#x27;youtube_channel&#x27; and new credentials are needed, as indicated by `CheckValidCreds`. In order to obtain authorization_code, make a request to the following URL: https://www.gstatic.com/bigquerydatatransfer/oauthz/auth?redirect_uri=urn:ietf:wg:oauth:2.0:oob&amp;response_type=authorization_code&amp;client_id=client_id&amp;scope=data_source_scopes * The client_id is the OAuth client_id of the a data source as returned by ListDataSources method. * data_source_scopes are the scopes returned by ListDataSources method. Note that this should not be set when `service_account_name` is used to create the transfer config.
  serviceAccountName: string, Optional service account email. If this field is set, the transfer config will be created with this service account&#x27;s credentials. It requires that the requesting user calling this API has permissions to act as this service account. Note that not all data sources support service account credentials when creating a transfer config. For the latest list of data sources, read about [using service accounts](https://cloud.google.com/bigquery-transfer/docs/use-service-accounts).
  versionInfo: string, Optional version info. This is required only if `transferConfig.dataSourceId` is not &#x27;youtube_channel&#x27; and new credentials are needed, as indicated by `CheckValidCreds`. In order to obtain version info, make a request to the following URL: https://www.gstatic.com/bigquerydatatransfer/oauthz/auth?redirect_uri=urn:ietf:wg:oauth:2.0:oob&amp;response_type=version_info&amp;client_id=client_id&amp;scope=data_source_scopes * The client_id is the OAuth client_id of the a data source as returned by ListDataSources method. * data_source_scopes are the scopes returned by ListDataSources method. Note that this should not be set when `service_account_name` is used to create the transfer config.
  x__xgafv: string, V1 error format.
    Allowed values
      1 - v1 error format
      2 - v2 error format

Returns:
  An object of the form:

    { # Represents a data transfer configuration. A transfer configuration contains all metadata needed to perform a data transfer. For example, `destination_dataset_id` specifies where data should be stored. When a new transfer configuration is created, the specified `destination_dataset_id` is created when needed and shared with the appropriate data source service account.
  &quot;dataRefreshWindowDays&quot;: 42, # The number of days to look back to automatically refresh the data. For example, if `data_refresh_window_days = 10`, then every day BigQuery reingests data for [today-10, today-1], rather than ingesting data for just [today-1]. Only valid if the data source supports the feature. Set the value to 0 to use the default value.
  &quot;dataSourceId&quot;: &quot;A String&quot;, # Data source ID. This cannot be changed once data transfer is created. The full list of available data source IDs can be returned through an API call: https://cloud.google.com/bigquery-transfer/docs/reference/datatransfer/rest/v1/projects.locations.dataSources/list
  &quot;datasetRegion&quot;: &quot;A String&quot;, # Output only. Region in which BigQuery dataset is located.
  &quot;destinationDatasetId&quot;: &quot;A String&quot;, # The BigQuery target dataset id.
  &quot;disabled&quot;: True or False, # Is this config disabled. When set to true, no runs are scheduled for a given transfer.
  &quot;displayName&quot;: &quot;A String&quot;, # User specified display name for the data transfer.
  &quot;emailPreferences&quot;: { # Represents preferences for sending email notifications for transfer run events. # Email notifications will be sent according to these preferences to the email address of the user who owns this transfer config.
    &quot;enableFailureEmail&quot;: True or False, # If true, email notifications will be sent on transfer run failures.
  },
  &quot;name&quot;: &quot;A String&quot;, # The resource name of the transfer config. Transfer config names have the form `projects/{project_id}/locations/{region}/transferConfigs/{config_id}`. Where `config_id` is usually a uuid, even though it is not guaranteed or required. The name is ignored when creating a transfer config.
  &quot;nextRunTime&quot;: &quot;A String&quot;, # Output only. Next time when data transfer will run.
  &quot;notificationPubsubTopic&quot;: &quot;A String&quot;, # Pub/Sub topic where notifications will be sent after transfer runs associated with this transfer config finish. The format for specifying a pubsub topic is: `projects/{project}/topics/{topic}`
  &quot;ownerInfo&quot;: { # Information about a user. # Output only. Information about the user whose credentials are used to transfer data. Populated only for `transferConfigs.get` requests. In case the user information is not available, this field will not be populated.
    &quot;email&quot;: &quot;A String&quot;, # E-mail address of the user.
  },
  &quot;params&quot;: { # Parameters specific to each data source. For more information see the bq tab in the &#x27;Setting up a data transfer&#x27; section for each data source. For example the parameters for Cloud Storage transfers are listed here: https://cloud.google.com/bigquery-transfer/docs/cloud-storage-transfer#bq
    &quot;a_key&quot;: &quot;&quot;, # Properties of the object.
  },
  &quot;schedule&quot;: &quot;A String&quot;, # Data transfer schedule. If the data source does not support a custom schedule, this should be empty. If it is empty, the default value for the data source will be used. The specified times are in UTC. Examples of valid format: `1st,3rd monday of month 15:30`, `every wed,fri of jan,jun 13:15`, and `first sunday of quarter 00:00`. See more explanation about the format here: https://cloud.google.com/appengine/docs/flexible/python/scheduling-jobs-with-cron-yaml#the_schedule_format NOTE: The minimum interval time between recurring transfers depends on the data source; refer to the documentation for your data source.
  &quot;scheduleOptions&quot;: { # Options customizing the data transfer schedule. # Options customizing the data transfer schedule.
    &quot;disableAutoScheduling&quot;: True or False, # If true, automatic scheduling of data transfer runs for this configuration will be disabled. The runs can be started on ad-hoc basis using StartManualTransferRuns API. When automatic scheduling is disabled, the TransferConfig.schedule field will be ignored.
    &quot;endTime&quot;: &quot;A String&quot;, # Defines time to stop scheduling transfer runs. A transfer run cannot be scheduled at or after the end time. The end time can be changed at any moment. The time when a data transfer can be trigerred manually is not limited by this option.
    &quot;startTime&quot;: &quot;A String&quot;, # Specifies time to start scheduling transfer runs. The first run will be scheduled at or after the start time according to a recurrence pattern defined in the schedule string. The start time can be changed at any moment. The time when a data transfer can be trigerred manually is not limited by this option.
  },
  &quot;state&quot;: &quot;A String&quot;, # Output only. State of the most recently updated transfer run.
  &quot;updateTime&quot;: &quot;A String&quot;, # Output only. Data transfer modification time. Ignored by server on input.
  &quot;userId&quot;: &quot;A String&quot;, # Deprecated. Unique ID of the user on whose behalf transfer is done.
}</pre>
</div>

<div class="method">
    <code class="details" id="delete">delete(name, x__xgafv=None)</code>
  <pre>Deletes a data transfer configuration, including any associated transfer runs and logs.

Args:
  name: string, Required. The field will contain name of the resource requested, for example: `projects/{project_id}/transferConfigs/{config_id}` or `projects/{project_id}/locations/{location_id}/transferConfigs/{config_id}` (required)
  x__xgafv: string, V1 error format.
    Allowed values
      1 - v1 error format
      2 - v2 error format

Returns:
  An object of the form:

    { # A generic empty message that you can re-use to avoid defining duplicated empty messages in your APIs. A typical example is to use it as the request or the response type of an API method. For instance: service Foo { rpc Bar(google.protobuf.Empty) returns (google.protobuf.Empty); }
}</pre>
</div>

<div class="method">
    <code class="details" id="get">get(name, x__xgafv=None)</code>
  <pre>Returns information about a data transfer config.

Args:
  name: string, Required. The field will contain name of the resource requested, for example: `projects/{project_id}/transferConfigs/{config_id}` or `projects/{project_id}/locations/{location_id}/transferConfigs/{config_id}` (required)
  x__xgafv: string, V1 error format.
    Allowed values
      1 - v1 error format
      2 - v2 error format

Returns:
  An object of the form:

    { # Represents a data transfer configuration. A transfer configuration contains all metadata needed to perform a data transfer. For example, `destination_dataset_id` specifies where data should be stored. When a new transfer configuration is created, the specified `destination_dataset_id` is created when needed and shared with the appropriate data source service account.
  &quot;dataRefreshWindowDays&quot;: 42, # The number of days to look back to automatically refresh the data. For example, if `data_refresh_window_days = 10`, then every day BigQuery reingests data for [today-10, today-1], rather than ingesting data for just [today-1]. Only valid if the data source supports the feature. Set the value to 0 to use the default value.
  &quot;dataSourceId&quot;: &quot;A String&quot;, # Data source ID. This cannot be changed once data transfer is created. The full list of available data source IDs can be returned through an API call: https://cloud.google.com/bigquery-transfer/docs/reference/datatransfer/rest/v1/projects.locations.dataSources/list
  &quot;datasetRegion&quot;: &quot;A String&quot;, # Output only. Region in which BigQuery dataset is located.
  &quot;destinationDatasetId&quot;: &quot;A String&quot;, # The BigQuery target dataset id.
  &quot;disabled&quot;: True or False, # Is this config disabled. When set to true, no runs are scheduled for a given transfer.
  &quot;displayName&quot;: &quot;A String&quot;, # User specified display name for the data transfer.
  &quot;emailPreferences&quot;: { # Represents preferences for sending email notifications for transfer run events. # Email notifications will be sent according to these preferences to the email address of the user who owns this transfer config.
    &quot;enableFailureEmail&quot;: True or False, # If true, email notifications will be sent on transfer run failures.
  },
  &quot;name&quot;: &quot;A String&quot;, # The resource name of the transfer config. Transfer config names have the form `projects/{project_id}/locations/{region}/transferConfigs/{config_id}`. Where `config_id` is usually a uuid, even though it is not guaranteed or required. The name is ignored when creating a transfer config.
  &quot;nextRunTime&quot;: &quot;A String&quot;, # Output only. Next time when data transfer will run.
  &quot;notificationPubsubTopic&quot;: &quot;A String&quot;, # Pub/Sub topic where notifications will be sent after transfer runs associated with this transfer config finish. The format for specifying a pubsub topic is: `projects/{project}/topics/{topic}`
  &quot;ownerInfo&quot;: { # Information about a user. # Output only. Information about the user whose credentials are used to transfer data. Populated only for `transferConfigs.get` requests. In case the user information is not available, this field will not be populated.
    &quot;email&quot;: &quot;A String&quot;, # E-mail address of the user.
  },
  &quot;params&quot;: { # Parameters specific to each data source. For more information see the bq tab in the &#x27;Setting up a data transfer&#x27; section for each data source. For example the parameters for Cloud Storage transfers are listed here: https://cloud.google.com/bigquery-transfer/docs/cloud-storage-transfer#bq
    &quot;a_key&quot;: &quot;&quot;, # Properties of the object.
  },
  &quot;schedule&quot;: &quot;A String&quot;, # Data transfer schedule. If the data source does not support a custom schedule, this should be empty. If it is empty, the default value for the data source will be used. The specified times are in UTC. Examples of valid format: `1st,3rd monday of month 15:30`, `every wed,fri of jan,jun 13:15`, and `first sunday of quarter 00:00`. See more explanation about the format here: https://cloud.google.com/appengine/docs/flexible/python/scheduling-jobs-with-cron-yaml#the_schedule_format NOTE: The minimum interval time between recurring transfers depends on the data source; refer to the documentation for your data source.
  &quot;scheduleOptions&quot;: { # Options customizing the data transfer schedule. # Options customizing the data transfer schedule.
    &quot;disableAutoScheduling&quot;: True or False, # If true, automatic scheduling of data transfer runs for this configuration will be disabled. The runs can be started on ad-hoc basis using StartManualTransferRuns API. When automatic scheduling is disabled, the TransferConfig.schedule field will be ignored.
    &quot;endTime&quot;: &quot;A String&quot;, # Defines time to stop scheduling transfer runs. A transfer run cannot be scheduled at or after the end time. The end time can be changed at any moment. The time when a data transfer can be trigerred manually is not limited by this option.
    &quot;startTime&quot;: &quot;A String&quot;, # Specifies time to start scheduling transfer runs. The first run will be scheduled at or after the start time according to a recurrence pattern defined in the schedule string. The start time can be changed at any moment. The time when a data transfer can be trigerred manually is not limited by this option.
  },
  &quot;state&quot;: &quot;A String&quot;, # Output only. State of the most recently updated transfer run.
  &quot;updateTime&quot;: &quot;A String&quot;, # Output only. Data transfer modification time. Ignored by server on input.
  &quot;userId&quot;: &quot;A String&quot;, # Deprecated. Unique ID of the user on whose behalf transfer is done.
}</pre>
</div>

<div class="method">
    <code class="details" id="list">list(parent, dataSourceIds=None, pageSize=None, pageToken=None, x__xgafv=None)</code>
  <pre>Returns information about all transfer configs owned by a project in the specified location.

Args:
  parent: string, Required. The BigQuery project id for which transfer configs should be returned: `projects/{project_id}` or `projects/{project_id}/locations/{location_id}` (required)
  dataSourceIds: string, When specified, only configurations of requested data sources are returned. (repeated)
  pageSize: integer, Page size. The default page size is the maximum value of 1000 results.
  pageToken: string, Pagination token, which can be used to request a specific page of `ListTransfersRequest` list results. For multiple-page results, `ListTransfersResponse` outputs a `next_page` token, which can be used as the `page_token` value to request the next page of list results.
  x__xgafv: string, V1 error format.
    Allowed values
      1 - v1 error format
      2 - v2 error format

Returns:
  An object of the form:

    { # The returned list of pipelines in the project.
  &quot;nextPageToken&quot;: &quot;A String&quot;, # Output only. The next-pagination token. For multiple-page list results, this token can be used as the `ListTransferConfigsRequest.page_token` to request the next page of list results.
  &quot;transferConfigs&quot;: [ # Output only. The stored pipeline transfer configurations.
    { # Represents a data transfer configuration. A transfer configuration contains all metadata needed to perform a data transfer. For example, `destination_dataset_id` specifies where data should be stored. When a new transfer configuration is created, the specified `destination_dataset_id` is created when needed and shared with the appropriate data source service account.
      &quot;dataRefreshWindowDays&quot;: 42, # The number of days to look back to automatically refresh the data. For example, if `data_refresh_window_days = 10`, then every day BigQuery reingests data for [today-10, today-1], rather than ingesting data for just [today-1]. Only valid if the data source supports the feature. Set the value to 0 to use the default value.
      &quot;dataSourceId&quot;: &quot;A String&quot;, # Data source ID. This cannot be changed once data transfer is created. The full list of available data source IDs can be returned through an API call: https://cloud.google.com/bigquery-transfer/docs/reference/datatransfer/rest/v1/projects.locations.dataSources/list
      &quot;datasetRegion&quot;: &quot;A String&quot;, # Output only. Region in which BigQuery dataset is located.
      &quot;destinationDatasetId&quot;: &quot;A String&quot;, # The BigQuery target dataset id.
      &quot;disabled&quot;: True or False, # Is this config disabled. When set to true, no runs are scheduled for a given transfer.
      &quot;displayName&quot;: &quot;A String&quot;, # User specified display name for the data transfer.
      &quot;emailPreferences&quot;: { # Represents preferences for sending email notifications for transfer run events. # Email notifications will be sent according to these preferences to the email address of the user who owns this transfer config.
        &quot;enableFailureEmail&quot;: True or False, # If true, email notifications will be sent on transfer run failures.
      },
      &quot;name&quot;: &quot;A String&quot;, # The resource name of the transfer config. Transfer config names have the form `projects/{project_id}/locations/{region}/transferConfigs/{config_id}`. Where `config_id` is usually a uuid, even though it is not guaranteed or required. The name is ignored when creating a transfer config.
      &quot;nextRunTime&quot;: &quot;A String&quot;, # Output only. Next time when data transfer will run.
      &quot;notificationPubsubTopic&quot;: &quot;A String&quot;, # Pub/Sub topic where notifications will be sent after transfer runs associated with this transfer config finish. The format for specifying a pubsub topic is: `projects/{project}/topics/{topic}`
      &quot;ownerInfo&quot;: { # Information about a user. # Output only. Information about the user whose credentials are used to transfer data. Populated only for `transferConfigs.get` requests. In case the user information is not available, this field will not be populated.
        &quot;email&quot;: &quot;A String&quot;, # E-mail address of the user.
      },
      &quot;params&quot;: { # Parameters specific to each data source. For more information see the bq tab in the &#x27;Setting up a data transfer&#x27; section for each data source. For example the parameters for Cloud Storage transfers are listed here: https://cloud.google.com/bigquery-transfer/docs/cloud-storage-transfer#bq
        &quot;a_key&quot;: &quot;&quot;, # Properties of the object.
      },
      &quot;schedule&quot;: &quot;A String&quot;, # Data transfer schedule. If the data source does not support a custom schedule, this should be empty. If it is empty, the default value for the data source will be used. The specified times are in UTC. Examples of valid format: `1st,3rd monday of month 15:30`, `every wed,fri of jan,jun 13:15`, and `first sunday of quarter 00:00`. See more explanation about the format here: https://cloud.google.com/appengine/docs/flexible/python/scheduling-jobs-with-cron-yaml#the_schedule_format NOTE: The minimum interval time between recurring transfers depends on the data source; refer to the documentation for your data source.
      &quot;scheduleOptions&quot;: { # Options customizing the data transfer schedule. # Options customizing the data transfer schedule.
        &quot;disableAutoScheduling&quot;: True or False, # If true, automatic scheduling of data transfer runs for this configuration will be disabled. The runs can be started on ad-hoc basis using StartManualTransferRuns API. When automatic scheduling is disabled, the TransferConfig.schedule field will be ignored.
        &quot;endTime&quot;: &quot;A String&quot;, # Defines time to stop scheduling transfer runs. A transfer run cannot be scheduled at or after the end time. The end time can be changed at any moment. The time when a data transfer can be trigerred manually is not limited by this option.
        &quot;startTime&quot;: &quot;A String&quot;, # Specifies time to start scheduling transfer runs. The first run will be scheduled at or after the start time according to a recurrence pattern defined in the schedule string. The start time can be changed at any moment. The time when a data transfer can be trigerred manually is not limited by this option.
      },
      &quot;state&quot;: &quot;A String&quot;, # Output only. State of the most recently updated transfer run.
      &quot;updateTime&quot;: &quot;A String&quot;, # Output only. Data transfer modification time. Ignored by server on input.
      &quot;userId&quot;: &quot;A String&quot;, # Deprecated. Unique ID of the user on whose behalf transfer is done.
    },
  ],
}</pre>
</div>

<div class="method">
    <code class="details" id="list_next">list_next()</code>
  <pre>Retrieves the next page of results.

        Args:
          previous_request: The request for the previous page. (required)
          previous_response: The response from the request for the previous page. (required)

        Returns:
          A request object that you can call &#x27;execute()&#x27; on to request the next
          page. Returns None if there are no more items in the collection.
        </pre>
</div>

<div class="method">
    <code class="details" id="patch">patch(name, authorizationCode=None, body=None, serviceAccountName=None, updateMask=None, versionInfo=None, x__xgafv=None)</code>
  <pre>Updates a data transfer configuration. All fields must be set, even if they are not updated.

Args:
  name: string, The resource name of the transfer config. Transfer config names have the form `projects/{project_id}/locations/{region}/transferConfigs/{config_id}`. Where `config_id` is usually a uuid, even though it is not guaranteed or required. The name is ignored when creating a transfer config. (required)
  body: object, The request body.
    The object takes the form of:

{ # Represents a data transfer configuration. A transfer configuration contains all metadata needed to perform a data transfer. For example, `destination_dataset_id` specifies where data should be stored. When a new transfer configuration is created, the specified `destination_dataset_id` is created when needed and shared with the appropriate data source service account.
  &quot;dataRefreshWindowDays&quot;: 42, # The number of days to look back to automatically refresh the data. For example, if `data_refresh_window_days = 10`, then every day BigQuery reingests data for [today-10, today-1], rather than ingesting data for just [today-1]. Only valid if the data source supports the feature. Set the value to 0 to use the default value.
  &quot;dataSourceId&quot;: &quot;A String&quot;, # Data source ID. This cannot be changed once data transfer is created. The full list of available data source IDs can be returned through an API call: https://cloud.google.com/bigquery-transfer/docs/reference/datatransfer/rest/v1/projects.locations.dataSources/list
  &quot;datasetRegion&quot;: &quot;A String&quot;, # Output only. Region in which BigQuery dataset is located.
  &quot;destinationDatasetId&quot;: &quot;A String&quot;, # The BigQuery target dataset id.
  &quot;disabled&quot;: True or False, # Is this config disabled. When set to true, no runs are scheduled for a given transfer.
  &quot;displayName&quot;: &quot;A String&quot;, # User specified display name for the data transfer.
  &quot;emailPreferences&quot;: { # Represents preferences for sending email notifications for transfer run events. # Email notifications will be sent according to these preferences to the email address of the user who owns this transfer config.
    &quot;enableFailureEmail&quot;: True or False, # If true, email notifications will be sent on transfer run failures.
  },
  &quot;name&quot;: &quot;A String&quot;, # The resource name of the transfer config. Transfer config names have the form `projects/{project_id}/locations/{region}/transferConfigs/{config_id}`. Where `config_id` is usually a uuid, even though it is not guaranteed or required. The name is ignored when creating a transfer config.
  &quot;nextRunTime&quot;: &quot;A String&quot;, # Output only. Next time when data transfer will run.
  &quot;notificationPubsubTopic&quot;: &quot;A String&quot;, # Pub/Sub topic where notifications will be sent after transfer runs associated with this transfer config finish. The format for specifying a pubsub topic is: `projects/{project}/topics/{topic}`
  &quot;ownerInfo&quot;: { # Information about a user. # Output only. Information about the user whose credentials are used to transfer data. Populated only for `transferConfigs.get` requests. In case the user information is not available, this field will not be populated.
    &quot;email&quot;: &quot;A String&quot;, # E-mail address of the user.
  },
  &quot;params&quot;: { # Parameters specific to each data source. For more information see the bq tab in the &#x27;Setting up a data transfer&#x27; section for each data source. For example the parameters for Cloud Storage transfers are listed here: https://cloud.google.com/bigquery-transfer/docs/cloud-storage-transfer#bq
    &quot;a_key&quot;: &quot;&quot;, # Properties of the object.
  },
  &quot;schedule&quot;: &quot;A String&quot;, # Data transfer schedule. If the data source does not support a custom schedule, this should be empty. If it is empty, the default value for the data source will be used. The specified times are in UTC. Examples of valid format: `1st,3rd monday of month 15:30`, `every wed,fri of jan,jun 13:15`, and `first sunday of quarter 00:00`. See more explanation about the format here: https://cloud.google.com/appengine/docs/flexible/python/scheduling-jobs-with-cron-yaml#the_schedule_format NOTE: The minimum interval time between recurring transfers depends on the data source; refer to the documentation for your data source.
  &quot;scheduleOptions&quot;: { # Options customizing the data transfer schedule. # Options customizing the data transfer schedule.
    &quot;disableAutoScheduling&quot;: True or False, # If true, automatic scheduling of data transfer runs for this configuration will be disabled. The runs can be started on ad-hoc basis using StartManualTransferRuns API. When automatic scheduling is disabled, the TransferConfig.schedule field will be ignored.
    &quot;endTime&quot;: &quot;A String&quot;, # Defines time to stop scheduling transfer runs. A transfer run cannot be scheduled at or after the end time. The end time can be changed at any moment. The time when a data transfer can be trigerred manually is not limited by this option.
    &quot;startTime&quot;: &quot;A String&quot;, # Specifies time to start scheduling transfer runs. The first run will be scheduled at or after the start time according to a recurrence pattern defined in the schedule string. The start time can be changed at any moment. The time when a data transfer can be trigerred manually is not limited by this option.
  },
  &quot;state&quot;: &quot;A String&quot;, # Output only. State of the most recently updated transfer run.
  &quot;updateTime&quot;: &quot;A String&quot;, # Output only. Data transfer modification time. Ignored by server on input.
  &quot;userId&quot;: &quot;A String&quot;, # Deprecated. Unique ID of the user on whose behalf transfer is done.
}

  authorizationCode: string, Optional OAuth2 authorization code to use with this transfer configuration. This is required only if `transferConfig.dataSourceId` is &#x27;youtube_channel&#x27; and new credentials are needed, as indicated by `CheckValidCreds`. In order to obtain authorization_code, make a request to the following URL: https://www.gstatic.com/bigquerydatatransfer/oauthz/auth?redirect_uri=urn:ietf:wg:oauth:2.0:oob&amp;response_type=authorization_code&amp;client_id=client_id&amp;scope=data_source_scopes * The client_id is the OAuth client_id of the a data source as returned by ListDataSources method. * data_source_scopes are the scopes returned by ListDataSources method. Note that this should not be set when `service_account_name` is used to update the transfer config.
  serviceAccountName: string, Optional service account email. If this field is set, the transfer config will be created with this service account&#x27;s credentials. It requires that the requesting user calling this API has permissions to act as this service account. Note that not all data sources support service account credentials when creating a transfer config. For the latest list of data sources, read about [using service accounts](https://cloud.google.com/bigquery-transfer/docs/use-service-accounts).
  updateMask: string, Required. Required list of fields to be updated in this request.
  versionInfo: string, Optional version info. This is required only if `transferConfig.dataSourceId` is not &#x27;youtube_channel&#x27; and new credentials are needed, as indicated by `CheckValidCreds`. In order to obtain version info, make a request to the following URL: https://www.gstatic.com/bigquerydatatransfer/oauthz/auth?redirect_uri=urn:ietf:wg:oauth:2.0:oob&amp;response_type=version_info&amp;client_id=client_id&amp;scope=data_source_scopes * The client_id is the OAuth client_id of the a data source as returned by ListDataSources method. * data_source_scopes are the scopes returned by ListDataSources method. Note that this should not be set when `service_account_name` is used to update the transfer config.
  x__xgafv: string, V1 error format.
    Allowed values
      1 - v1 error format
      2 - v2 error format

Returns:
  An object of the form:

    { # Represents a data transfer configuration. A transfer configuration contains all metadata needed to perform a data transfer. For example, `destination_dataset_id` specifies where data should be stored. When a new transfer configuration is created, the specified `destination_dataset_id` is created when needed and shared with the appropriate data source service account.
  &quot;dataRefreshWindowDays&quot;: 42, # The number of days to look back to automatically refresh the data. For example, if `data_refresh_window_days = 10`, then every day BigQuery reingests data for [today-10, today-1], rather than ingesting data for just [today-1]. Only valid if the data source supports the feature. Set the value to 0 to use the default value.
  &quot;dataSourceId&quot;: &quot;A String&quot;, # Data source ID. This cannot be changed once data transfer is created. The full list of available data source IDs can be returned through an API call: https://cloud.google.com/bigquery-transfer/docs/reference/datatransfer/rest/v1/projects.locations.dataSources/list
  &quot;datasetRegion&quot;: &quot;A String&quot;, # Output only. Region in which BigQuery dataset is located.
  &quot;destinationDatasetId&quot;: &quot;A String&quot;, # The BigQuery target dataset id.
  &quot;disabled&quot;: True or False, # Is this config disabled. When set to true, no runs are scheduled for a given transfer.
  &quot;displayName&quot;: &quot;A String&quot;, # User specified display name for the data transfer.
  &quot;emailPreferences&quot;: { # Represents preferences for sending email notifications for transfer run events. # Email notifications will be sent according to these preferences to the email address of the user who owns this transfer config.
    &quot;enableFailureEmail&quot;: True or False, # If true, email notifications will be sent on transfer run failures.
  },
  &quot;name&quot;: &quot;A String&quot;, # The resource name of the transfer config. Transfer config names have the form `projects/{project_id}/locations/{region}/transferConfigs/{config_id}`. Where `config_id` is usually a uuid, even though it is not guaranteed or required. The name is ignored when creating a transfer config.
  &quot;nextRunTime&quot;: &quot;A String&quot;, # Output only. Next time when data transfer will run.
  &quot;notificationPubsubTopic&quot;: &quot;A String&quot;, # Pub/Sub topic where notifications will be sent after transfer runs associated with this transfer config finish. The format for specifying a pubsub topic is: `projects/{project}/topics/{topic}`
  &quot;ownerInfo&quot;: { # Information about a user. # Output only. Information about the user whose credentials are used to transfer data. Populated only for `transferConfigs.get` requests. In case the user information is not available, this field will not be populated.
    &quot;email&quot;: &quot;A String&quot;, # E-mail address of the user.
  },
  &quot;params&quot;: { # Parameters specific to each data source. For more information see the bq tab in the &#x27;Setting up a data transfer&#x27; section for each data source. For example the parameters for Cloud Storage transfers are listed here: https://cloud.google.com/bigquery-transfer/docs/cloud-storage-transfer#bq
    &quot;a_key&quot;: &quot;&quot;, # Properties of the object.
  },
  &quot;schedule&quot;: &quot;A String&quot;, # Data transfer schedule. If the data source does not support a custom schedule, this should be empty. If it is empty, the default value for the data source will be used. The specified times are in UTC. Examples of valid format: `1st,3rd monday of month 15:30`, `every wed,fri of jan,jun 13:15`, and `first sunday of quarter 00:00`. See more explanation about the format here: https://cloud.google.com/appengine/docs/flexible/python/scheduling-jobs-with-cron-yaml#the_schedule_format NOTE: The minimum interval time between recurring transfers depends on the data source; refer to the documentation for your data source.
  &quot;scheduleOptions&quot;: { # Options customizing the data transfer schedule. # Options customizing the data transfer schedule.
    &quot;disableAutoScheduling&quot;: True or False, # If true, automatic scheduling of data transfer runs for this configuration will be disabled. The runs can be started on ad-hoc basis using StartManualTransferRuns API. When automatic scheduling is disabled, the TransferConfig.schedule field will be ignored.
    &quot;endTime&quot;: &quot;A String&quot;, # Defines time to stop scheduling transfer runs. A transfer run cannot be scheduled at or after the end time. The end time can be changed at any moment. The time when a data transfer can be trigerred manually is not limited by this option.
    &quot;startTime&quot;: &quot;A String&quot;, # Specifies time to start scheduling transfer runs. The first run will be scheduled at or after the start time according to a recurrence pattern defined in the schedule string. The start time can be changed at any moment. The time when a data transfer can be trigerred manually is not limited by this option.
  },
  &quot;state&quot;: &quot;A String&quot;, # Output only. State of the most recently updated transfer run.
  &quot;updateTime&quot;: &quot;A String&quot;, # Output only. Data transfer modification time. Ignored by server on input.
  &quot;userId&quot;: &quot;A String&quot;, # Deprecated. Unique ID of the user on whose behalf transfer is done.
}</pre>
</div>

<div class="method">
    <code class="details" id="scheduleRuns">scheduleRuns(parent, body=None, x__xgafv=None)</code>
  <pre>Creates transfer runs for a time range [start_time, end_time]. For each date - or whatever granularity the data source supports - in the range, one transfer run is created. Note that runs are created per UTC time in the time range. DEPRECATED: use StartManualTransferRuns instead.

Args:
  parent: string, Required. Transfer configuration name in the form: `projects/{project_id}/transferConfigs/{config_id}` or `projects/{project_id}/locations/{location_id}/transferConfigs/{config_id}`. (required)
  body: object, The request body.
    The object takes the form of:

{ # A request to schedule transfer runs for a time range.
  &quot;endTime&quot;: &quot;A String&quot;, # Required. End time of the range of transfer runs. For example, `&quot;2017-05-30T00:00:00+00:00&quot;`.
  &quot;startTime&quot;: &quot;A String&quot;, # Required. Start time of the range of transfer runs. For example, `&quot;2017-05-25T00:00:00+00:00&quot;`.
}

  x__xgafv: string, V1 error format.
    Allowed values
      1 - v1 error format
      2 - v2 error format

Returns:
  An object of the form:

    { # A response to schedule transfer runs for a time range.
  &quot;runs&quot;: [ # The transfer runs that were scheduled.
    { # Represents a data transfer run.
      &quot;dataSourceId&quot;: &quot;A String&quot;, # Output only. Data source id.
      &quot;destinationDatasetId&quot;: &quot;A String&quot;, # Output only. The BigQuery target dataset id.
      &quot;emailPreferences&quot;: { # Represents preferences for sending email notifications for transfer run events. # Output only. Email notifications will be sent according to these preferences to the email address of the user who owns the transfer config this run was derived from.
        &quot;enableFailureEmail&quot;: True or False, # If true, email notifications will be sent on transfer run failures.
      },
      &quot;endTime&quot;: &quot;A String&quot;, # Output only. Time when transfer run ended. Parameter ignored by server for input requests.
      &quot;errorStatus&quot;: { # The `Status` type defines a logical error model that is suitable for different programming environments, including REST APIs and RPC APIs. It is used by [gRPC](https://github.com/grpc). Each `Status` message contains three pieces of data: error code, error message, and error details. You can find out more about this error model and how to work with it in the [API Design Guide](https://cloud.google.com/apis/design/errors). # Status of the transfer run.
        &quot;code&quot;: 42, # The status code, which should be an enum value of google.rpc.Code.
        &quot;details&quot;: [ # A list of messages that carry the error details. There is a common set of message types for APIs to use.
          {
            &quot;a_key&quot;: &quot;&quot;, # Properties of the object. Contains field @type with type URL.
          },
        ],
        &quot;message&quot;: &quot;A String&quot;, # A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client.
      },
      &quot;name&quot;: &quot;A String&quot;, # The resource name of the transfer run. Transfer run names have the form `projects/{project_id}/locations/{location}/transferConfigs/{config_id}/runs/{run_id}`. The name is ignored when creating a transfer run.
      &quot;notificationPubsubTopic&quot;: &quot;A String&quot;, # Output only. Pub/Sub topic where a notification will be sent after this transfer run finishes. The format for specifying a pubsub topic is: `projects/{project}/topics/{topic}`
      &quot;params&quot;: { # Output only. Parameters specific to each data source. For more information see the bq tab in the &#x27;Setting up a data transfer&#x27; section for each data source. For example the parameters for Cloud Storage transfers are listed here: https://cloud.google.com/bigquery-transfer/docs/cloud-storage-transfer#bq
        &quot;a_key&quot;: &quot;&quot;, # Properties of the object.
      },
      &quot;runTime&quot;: &quot;A String&quot;, # For batch transfer runs, specifies the date and time of the data should be ingested.
      &quot;schedule&quot;: &quot;A String&quot;, # Output only. Describes the schedule of this transfer run if it was created as part of a regular schedule. For batch transfer runs that are scheduled manually, this is empty. NOTE: the system might choose to delay the schedule depending on the current load, so `schedule_time` doesn&#x27;t always match this.
      &quot;scheduleTime&quot;: &quot;A String&quot;, # Minimum time after which a transfer run can be started.
      &quot;startTime&quot;: &quot;A String&quot;, # Output only. Time when transfer run was started. Parameter ignored by server for input requests.
      &quot;state&quot;: &quot;A String&quot;, # Data transfer run state. Ignored for input requests.
      &quot;updateTime&quot;: &quot;A String&quot;, # Output only. Last time the data transfer run state was updated.
      &quot;userId&quot;: &quot;A String&quot;, # Deprecated. Unique ID of the user on whose behalf transfer is done.
    },
  ],
}</pre>
</div>

<div class="method">
    <code class="details" id="startManualRuns">startManualRuns(parent, body=None, x__xgafv=None)</code>
  <pre>Start manual transfer runs to be executed now with schedule_time equal to current time. The transfer runs can be created for a time range where the run_time is between start_time (inclusive) and end_time (exclusive), or for a specific run_time.

Args:
  parent: string, Transfer configuration name in the form: `projects/{project_id}/transferConfigs/{config_id}` or `projects/{project_id}/locations/{location_id}/transferConfigs/{config_id}`. (required)
  body: object, The request body.
    The object takes the form of:

{ # A request to start manual transfer runs.
  &quot;requestedRunTime&quot;: &quot;A String&quot;, # Specific run_time for a transfer run to be started. The requested_run_time must not be in the future.
  &quot;requestedTimeRange&quot;: { # A specification for a time range, this will request transfer runs with run_time between start_time (inclusive) and end_time (exclusive). # Time range for the transfer runs that should be started.
    &quot;endTime&quot;: &quot;A String&quot;, # End time of the range of transfer runs. For example, `&quot;2017-05-30T00:00:00+00:00&quot;`. The end_time must not be in the future. Creates transfer runs where run_time is in the range between start_time (inclusive) and end_time (exclusive).
    &quot;startTime&quot;: &quot;A String&quot;, # Start time of the range of transfer runs. For example, `&quot;2017-05-25T00:00:00+00:00&quot;`. The start_time must be strictly less than the end_time. Creates transfer runs where run_time is in the range between start_time (inclusive) and end_time (exclusive).
  },
}

  x__xgafv: string, V1 error format.
    Allowed values
      1 - v1 error format
      2 - v2 error format

Returns:
  An object of the form:

    { # A response to start manual transfer runs.
  &quot;runs&quot;: [ # The transfer runs that were created.
    { # Represents a data transfer run.
      &quot;dataSourceId&quot;: &quot;A String&quot;, # Output only. Data source id.
      &quot;destinationDatasetId&quot;: &quot;A String&quot;, # Output only. The BigQuery target dataset id.
      &quot;emailPreferences&quot;: { # Represents preferences for sending email notifications for transfer run events. # Output only. Email notifications will be sent according to these preferences to the email address of the user who owns the transfer config this run was derived from.
        &quot;enableFailureEmail&quot;: True or False, # If true, email notifications will be sent on transfer run failures.
      },
      &quot;endTime&quot;: &quot;A String&quot;, # Output only. Time when transfer run ended. Parameter ignored by server for input requests.
      &quot;errorStatus&quot;: { # The `Status` type defines a logical error model that is suitable for different programming environments, including REST APIs and RPC APIs. It is used by [gRPC](https://github.com/grpc). Each `Status` message contains three pieces of data: error code, error message, and error details. You can find out more about this error model and how to work with it in the [API Design Guide](https://cloud.google.com/apis/design/errors). # Status of the transfer run.
        &quot;code&quot;: 42, # The status code, which should be an enum value of google.rpc.Code.
        &quot;details&quot;: [ # A list of messages that carry the error details. There is a common set of message types for APIs to use.
          {
            &quot;a_key&quot;: &quot;&quot;, # Properties of the object. Contains field @type with type URL.
          },
        ],
        &quot;message&quot;: &quot;A String&quot;, # A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client.
      },
      &quot;name&quot;: &quot;A String&quot;, # The resource name of the transfer run. Transfer run names have the form `projects/{project_id}/locations/{location}/transferConfigs/{config_id}/runs/{run_id}`. The name is ignored when creating a transfer run.
      &quot;notificationPubsubTopic&quot;: &quot;A String&quot;, # Output only. Pub/Sub topic where a notification will be sent after this transfer run finishes. The format for specifying a pubsub topic is: `projects/{project}/topics/{topic}`
      &quot;params&quot;: { # Output only. Parameters specific to each data source. For more information see the bq tab in the &#x27;Setting up a data transfer&#x27; section for each data source. For example the parameters for Cloud Storage transfers are listed here: https://cloud.google.com/bigquery-transfer/docs/cloud-storage-transfer#bq
        &quot;a_key&quot;: &quot;&quot;, # Properties of the object.
      },
      &quot;runTime&quot;: &quot;A String&quot;, # For batch transfer runs, specifies the date and time of the data should be ingested.
      &quot;schedule&quot;: &quot;A String&quot;, # Output only. Describes the schedule of this transfer run if it was created as part of a regular schedule. For batch transfer runs that are scheduled manually, this is empty. NOTE: the system might choose to delay the schedule depending on the current load, so `schedule_time` doesn&#x27;t always match this.
      &quot;scheduleTime&quot;: &quot;A String&quot;, # Minimum time after which a transfer run can be started.
      &quot;startTime&quot;: &quot;A String&quot;, # Output only. Time when transfer run was started. Parameter ignored by server for input requests.
      &quot;state&quot;: &quot;A String&quot;, # Data transfer run state. Ignored for input requests.
      &quot;updateTime&quot;: &quot;A String&quot;, # Output only. Last time the data transfer run state was updated.
      &quot;userId&quot;: &quot;A String&quot;, # Deprecated. Unique ID of the user on whose behalf transfer is done.
    },
  ],
}</pre>
</div>

</body></html>