<html><body>
<style>

body, h1, h2, h3, div, span, p, pre, a {
  margin: 0;
  padding: 0;
  border: 0;
  font-weight: inherit;
  font-style: inherit;
  font-size: 100%;
  font-family: inherit;
  vertical-align: baseline;
}

body {
  font-size: 13px;
  padding: 1em;
}

h1 {
  font-size: 26px;
  margin-bottom: 1em;
}

h2 {
  font-size: 24px;
  margin-bottom: 1em;
}

h3 {
  font-size: 20px;
  margin-bottom: 1em;
  margin-top: 1em;
}

pre, code {
  line-height: 1.5;
  font-family: Monaco, 'DejaVu Sans Mono', 'Bitstream Vera Sans Mono', 'Lucida Console', monospace;
}

pre {
  margin-top: 0.5em;
}

h1, h2, h3, p {
  font-family: Arial, sans serif;
}

h1, h2, h3 {
  border-bottom: solid #CCC 1px;
}

.toc_element {
  margin-top: 0.5em;
}

.firstline {
  margin-left: 2 em;
}

.method  {
  margin-top: 1em;
  border: solid 1px #CCC;
  padding: 1em;
  background: #EEE;
}

.details {
  font-weight: bold;
  font-size: 14px;
}

</style>

<h1><a href="discoveryengine_v1beta.html">Discovery Engine API</a> . <a href="discoveryengine_v1beta.projects.html">projects</a> . <a href="discoveryengine_v1beta.projects.locations.html">locations</a> . <a href="discoveryengine_v1beta.projects.locations.collections.html">collections</a> . <a href="discoveryengine_v1beta.projects.locations.collections.engines.html">engines</a> . <a href="discoveryengine_v1beta.projects.locations.collections.engines.assistants.html">assistants</a></h1>
<h2>Instance Methods</h2>
<p class="toc_element">
  <code><a href="#close">close()</a></code></p>
<p class="firstline">Close httplib2 connections.</p>
<p class="toc_element">
  <code><a href="#get">get(name, x__xgafv=None)</a></code></p>
<p class="firstline">Gets an Assistant.</p>
<p class="toc_element">
  <code><a href="#patch">patch(name, body=None, updateMask=None, x__xgafv=None)</a></code></p>
<p class="firstline">Updates an Assistant</p>
<p class="toc_element">
  <code><a href="#streamAssist">streamAssist(name, body=None, x__xgafv=None)</a></code></p>
<p class="firstline">Assists the user with a query in a streaming fashion.</p>
<h3>Method Details</h3>
<div class="method">
    <code class="details" id="close">close()</code>
  <pre>Close httplib2 connections.</pre>
</div>

<div class="method">
    <code class="details" id="get">get(name, x__xgafv=None)</code>
  <pre>Gets an Assistant.

Args:
  name: string, Required. Resource name of Assistant. Format: `projects/{project}/locations/{location}/collections/{collection}/engines/{engine}/assistants/{assistant}` (required)
  x__xgafv: string, V1 error format.
    Allowed values
      1 - v1 error format
      2 - v2 error format

Returns:
  An object of the form:

    { # Discovery Engine Assistant resource.
  &quot;customerPolicy&quot;: { # Customer-defined policy for the assistant. # Optional. Customer policy for the assistant.
    &quot;bannedPhrases&quot;: [ # Optional. List of banned phrases.
      { # Definition of a customer-defined banned phrase. A banned phrase is not allowed to appear in the user query or the LLM response, or else the answer will be refused.
        &quot;ignoreDiacritics&quot;: True or False, # Optional. If true, diacritical marks (e.g., accents, umlauts) are ignored when matching banned phrases. For example, &quot;cafe&quot; would match &quot;café&quot;.
        &quot;matchType&quot;: &quot;A String&quot;, # Optional. Match type for the banned phrase.
        &quot;phrase&quot;: &quot;A String&quot;, # Required. The raw string content to be banned.
      },
    ],
  },
  &quot;enabledTools&quot;: { # Optional. Note: not implemented yet. Use enabled_actions instead. The enabled tools on this assistant. The keys are connector name, for example &quot;projects/{projectId}/locations/{locationId}/collections/{collectionId}/dataconnector The values consist of admin enabled tools towards the connector instance. Admin can selectively enable multiple tools on any of the connector instances that they created in the project. For example {&quot;jira1ConnectorName&quot;: [(toolId1, &quot;createTicket&quot;), (toolId2, &quot;transferTicket&quot;)], &quot;gmail1ConnectorName&quot;: [(toolId3, &quot;sendEmail&quot;),..] }
    &quot;a_key&quot;: { # The enabled tools on a connector
      &quot;toolInfo&quot;: [ # The list of tools with corresponding tool information.
        { # Information to identify a tool.
          &quot;toolDisplayName&quot;: &quot;A String&quot;, # The display name of the tool.
          &quot;toolName&quot;: &quot;A String&quot;, # The name of the tool as defined by DataConnectorService.QueryAvailableActions. Note: it&#x27;s using `action` in the DataConnectorService apis, but they are the same as the `tool` here.
        },
      ],
    },
  },
  &quot;generationConfig&quot;: { # Configuration for the generation of the assistant response. # Optional. Configuration for the generation of the assistant response.
    &quot;defaultLanguage&quot;: &quot;A String&quot;, # The default language to use for the generation of the assistant response. Use an ISO 639-1 language code such as `en`. If not specified, the language will be automatically detected.
    &quot;systemInstruction&quot;: { # System instruction, also known as the prompt preamble for LLM calls. # System instruction, also known as the prompt preamble for LLM calls. See also https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/system-instructions
      &quot;additionalSystemInstruction&quot;: &quot;A String&quot;, # Optional. Additional system instruction that will be added to the default system instruction.
    },
  },
  &quot;name&quot;: &quot;A String&quot;, # Immutable. Resource name of the assistant. Format: `projects/{project}/locations/{location}/collections/{collection}/engines/{engine}/assistants/{assistant}` It must be a UTF-8 encoded string with a length limit of 1024 characters.
  &quot;webGroundingType&quot;: &quot;A String&quot;, # Optional. The type of web grounding to use.
}</pre>
</div>

<div class="method">
    <code class="details" id="patch">patch(name, body=None, updateMask=None, x__xgafv=None)</code>
  <pre>Updates an Assistant

Args:
  name: string, Immutable. Resource name of the assistant. Format: `projects/{project}/locations/{location}/collections/{collection}/engines/{engine}/assistants/{assistant}` It must be a UTF-8 encoded string with a length limit of 1024 characters. (required)
  body: object, The request body.
    The object takes the form of:

{ # Discovery Engine Assistant resource.
  &quot;customerPolicy&quot;: { # Customer-defined policy for the assistant. # Optional. Customer policy for the assistant.
    &quot;bannedPhrases&quot;: [ # Optional. List of banned phrases.
      { # Definition of a customer-defined banned phrase. A banned phrase is not allowed to appear in the user query or the LLM response, or else the answer will be refused.
        &quot;ignoreDiacritics&quot;: True or False, # Optional. If true, diacritical marks (e.g., accents, umlauts) are ignored when matching banned phrases. For example, &quot;cafe&quot; would match &quot;café&quot;.
        &quot;matchType&quot;: &quot;A String&quot;, # Optional. Match type for the banned phrase.
        &quot;phrase&quot;: &quot;A String&quot;, # Required. The raw string content to be banned.
      },
    ],
  },
  &quot;enabledTools&quot;: { # Optional. Note: not implemented yet. Use enabled_actions instead. The enabled tools on this assistant. The keys are connector name, for example &quot;projects/{projectId}/locations/{locationId}/collections/{collectionId}/dataconnector The values consist of admin enabled tools towards the connector instance. Admin can selectively enable multiple tools on any of the connector instances that they created in the project. For example {&quot;jira1ConnectorName&quot;: [(toolId1, &quot;createTicket&quot;), (toolId2, &quot;transferTicket&quot;)], &quot;gmail1ConnectorName&quot;: [(toolId3, &quot;sendEmail&quot;),..] }
    &quot;a_key&quot;: { # The enabled tools on a connector
      &quot;toolInfo&quot;: [ # The list of tools with corresponding tool information.
        { # Information to identify a tool.
          &quot;toolDisplayName&quot;: &quot;A String&quot;, # The display name of the tool.
          &quot;toolName&quot;: &quot;A String&quot;, # The name of the tool as defined by DataConnectorService.QueryAvailableActions. Note: it&#x27;s using `action` in the DataConnectorService apis, but they are the same as the `tool` here.
        },
      ],
    },
  },
  &quot;generationConfig&quot;: { # Configuration for the generation of the assistant response. # Optional. Configuration for the generation of the assistant response.
    &quot;defaultLanguage&quot;: &quot;A String&quot;, # The default language to use for the generation of the assistant response. Use an ISO 639-1 language code such as `en`. If not specified, the language will be automatically detected.
    &quot;systemInstruction&quot;: { # System instruction, also known as the prompt preamble for LLM calls. # System instruction, also known as the prompt preamble for LLM calls. See also https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/system-instructions
      &quot;additionalSystemInstruction&quot;: &quot;A String&quot;, # Optional. Additional system instruction that will be added to the default system instruction.
    },
  },
  &quot;name&quot;: &quot;A String&quot;, # Immutable. Resource name of the assistant. Format: `projects/{project}/locations/{location}/collections/{collection}/engines/{engine}/assistants/{assistant}` It must be a UTF-8 encoded string with a length limit of 1024 characters.
  &quot;webGroundingType&quot;: &quot;A String&quot;, # Optional. The type of web grounding to use.
}

  updateMask: string, The list of fields to update.
  x__xgafv: string, V1 error format.
    Allowed values
      1 - v1 error format
      2 - v2 error format

Returns:
  An object of the form:

    { # Discovery Engine Assistant resource.
  &quot;customerPolicy&quot;: { # Customer-defined policy for the assistant. # Optional. Customer policy for the assistant.
    &quot;bannedPhrases&quot;: [ # Optional. List of banned phrases.
      { # Definition of a customer-defined banned phrase. A banned phrase is not allowed to appear in the user query or the LLM response, or else the answer will be refused.
        &quot;ignoreDiacritics&quot;: True or False, # Optional. If true, diacritical marks (e.g., accents, umlauts) are ignored when matching banned phrases. For example, &quot;cafe&quot; would match &quot;café&quot;.
        &quot;matchType&quot;: &quot;A String&quot;, # Optional. Match type for the banned phrase.
        &quot;phrase&quot;: &quot;A String&quot;, # Required. The raw string content to be banned.
      },
    ],
  },
  &quot;enabledTools&quot;: { # Optional. Note: not implemented yet. Use enabled_actions instead. The enabled tools on this assistant. The keys are connector name, for example &quot;projects/{projectId}/locations/{locationId}/collections/{collectionId}/dataconnector The values consist of admin enabled tools towards the connector instance. Admin can selectively enable multiple tools on any of the connector instances that they created in the project. For example {&quot;jira1ConnectorName&quot;: [(toolId1, &quot;createTicket&quot;), (toolId2, &quot;transferTicket&quot;)], &quot;gmail1ConnectorName&quot;: [(toolId3, &quot;sendEmail&quot;),..] }
    &quot;a_key&quot;: { # The enabled tools on a connector
      &quot;toolInfo&quot;: [ # The list of tools with corresponding tool information.
        { # Information to identify a tool.
          &quot;toolDisplayName&quot;: &quot;A String&quot;, # The display name of the tool.
          &quot;toolName&quot;: &quot;A String&quot;, # The name of the tool as defined by DataConnectorService.QueryAvailableActions. Note: it&#x27;s using `action` in the DataConnectorService apis, but they are the same as the `tool` here.
        },
      ],
    },
  },
  &quot;generationConfig&quot;: { # Configuration for the generation of the assistant response. # Optional. Configuration for the generation of the assistant response.
    &quot;defaultLanguage&quot;: &quot;A String&quot;, # The default language to use for the generation of the assistant response. Use an ISO 639-1 language code such as `en`. If not specified, the language will be automatically detected.
    &quot;systemInstruction&quot;: { # System instruction, also known as the prompt preamble for LLM calls. # System instruction, also known as the prompt preamble for LLM calls. See also https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/system-instructions
      &quot;additionalSystemInstruction&quot;: &quot;A String&quot;, # Optional. Additional system instruction that will be added to the default system instruction.
    },
  },
  &quot;name&quot;: &quot;A String&quot;, # Immutable. Resource name of the assistant. Format: `projects/{project}/locations/{location}/collections/{collection}/engines/{engine}/assistants/{assistant}` It must be a UTF-8 encoded string with a length limit of 1024 characters.
  &quot;webGroundingType&quot;: &quot;A String&quot;, # Optional. The type of web grounding to use.
}</pre>
</div>

<div class="method">
    <code class="details" id="streamAssist">streamAssist(name, body=None, x__xgafv=None)</code>
  <pre>Assists the user with a query in a streaming fashion.

Args:
  name: string, Required. The resource name of the Assistant. Format: `projects/{project}/locations/{location}/collections/{collection}/engines/{engine}/assistants/{assistant}` (required)
  body: object, The request body.
    The object takes the form of:

{ # Request for the AssistantService.StreamAssist method.
  &quot;generationSpec&quot;: { # Assistant generation specification for the request. This allows to override the default generation configuration at the engine level. # Optional. Specification of the generation configuration for the request.
    &quot;modelId&quot;: &quot;A String&quot;, # Optional. The Vertex AI model_id used for the generative model. If not set, the default Assistant model will be used.
  },
  &quot;query&quot;: { # Defines a user inputed query. # Optional. Current user query. Empty query is only supported if `file_ids` are provided. In this case, the answer will be generated based on those context files.
    &quot;queryId&quot;: &quot;A String&quot;, # Output only. Unique Id for the query.
    &quot;text&quot;: &quot;A String&quot;, # Plain text.
  },
  &quot;session&quot;: &quot;A String&quot;, # Optional. The session to use for the request. If specified, the assistant has access to the session history, and the query and the answer are stored there. If `-` is specified as the session ID, or it is left empty, then a new session is created with an automatically generated ID. Format: `projects/{project}/locations/{location}/collections/{collection}/engines/{engine}/sessions/{session}`
  &quot;toolsSpec&quot;: { # Specification of tools that are used to serve the request. # Optional. Specification of tools that are used to serve the request.
    &quot;imageGenerationSpec&quot;: { # Specification of the image generation tool. # Optional. Specification of the image generation tool.
    },
    &quot;vertexAiSearchSpec&quot;: { # Specification of the Vertex AI Search tool. # Optional. Specification of the Vertex AI Search tool.
      &quot;dataStoreSpecs&quot;: [ # Optional. Specs defining DataStores to filter on in a search call and configurations for those data stores. This is only considered for Engines with multiple data stores.
        { # A struct to define data stores to filter on in a search call and configurations for those data stores. Otherwise, an `INVALID_ARGUMENT` error is returned.
          &quot;boostSpec&quot;: { # Boost specification to boost certain documents. # Optional. Boost specification to boost certain documents. For more information on boosting, see [Boosting](https://cloud.google.com/generative-ai-app-builder/docs/boost-search-results)
            &quot;conditionBoostSpecs&quot;: [ # Condition boost specifications. If a document matches multiple conditions in the specifications, boost scores from these specifications are all applied and combined in a non-linear way. Maximum number of specifications is 20.
              { # Boost applies to documents which match a condition.
                &quot;boost&quot;: 3.14, # Strength of the condition boost, which should be in [-1, 1]. Negative boost means demotion. Default is 0.0. Setting to 1.0 gives the document a big promotion. However, it does not necessarily mean that the boosted document will be the top result at all times, nor that other documents will be excluded. Results could still be shown even when none of them matches the condition. And results that are significantly more relevant to the search query can still trump your heavily favored but irrelevant documents. Setting to -1.0 gives the document a big demotion. However, results that are deeply relevant might still be shown. The document will have an upstream battle to get a fairly high ranking, but it is not blocked out completely. Setting to 0.0 means no boost applied. The boosting condition is ignored. Only one of the (condition, boost) combination or the boost_control_spec below are set. If both are set then the global boost is ignored and the more fine-grained boost_control_spec is applied.
                &quot;boostControlSpec&quot;: { # Specification for custom ranking based on customer specified attribute value. It provides more controls for customized ranking than the simple (condition, boost) combination above. # Complex specification for custom ranking based on customer defined attribute value.
                  &quot;attributeType&quot;: &quot;A String&quot;, # The attribute type to be used to determine the boost amount. The attribute value can be derived from the field value of the specified field_name. In the case of numerical it is straightforward i.e. attribute_value = numerical_field_value. In the case of freshness however, attribute_value = (time.now() - datetime_field_value).
                  &quot;controlPoints&quot;: [ # The control points used to define the curve. The monotonic function (defined through the interpolation_type above) passes through the control points listed here.
                    { # The control points used to define the curve. The curve defined through these control points can only be monotonically increasing or decreasing(constant values are acceptable).
                      &quot;attributeValue&quot;: &quot;A String&quot;, # Can be one of: 1. The numerical field value. 2. The duration spec for freshness: The value must be formatted as an XSD `dayTimeDuration` value (a restricted subset of an ISO 8601 duration value). The pattern for this is: `nDnM]`.
                      &quot;boostAmount&quot;: 3.14, # The value between -1 to 1 by which to boost the score if the attribute_value evaluates to the value specified above.
                    },
                  ],
                  &quot;fieldName&quot;: &quot;A String&quot;, # The name of the field whose value will be used to determine the boost amount.
                  &quot;interpolationType&quot;: &quot;A String&quot;, # The interpolation type to be applied to connect the control points listed below.
                },
                &quot;condition&quot;: &quot;A String&quot;, # An expression which specifies a boost condition. The syntax and supported fields are the same as a filter expression. See SearchRequest.filter for detail syntax and limitations. Examples: * To boost documents with document ID &quot;doc_1&quot; or &quot;doc_2&quot;, and color &quot;Red&quot; or &quot;Blue&quot;: `(document_id: ANY(&quot;doc_1&quot;, &quot;doc_2&quot;)) AND (color: ANY(&quot;Red&quot;, &quot;Blue&quot;))`
              },
            ],
          },
          &quot;customSearchOperators&quot;: &quot;A String&quot;, # Optional. Custom search operators which if specified will be used to filter results from workspace data stores. For more information on custom search operators, see [SearchOperators](https://support.google.com/cloudsearch/answer/6172299).
          &quot;dataStore&quot;: &quot;A String&quot;, # Required. Full resource name of DataStore, such as `projects/{project}/locations/{location}/collections/{collection_id}/dataStores/{data_store_id}`. The path must include the project number, project id is not supported for this field.
          &quot;filter&quot;: &quot;A String&quot;, # Optional. Filter specification to filter documents in the data store specified by data_store field. For more information on filtering, see [Filtering](https://cloud.google.com/generative-ai-app-builder/docs/filter-search-metadata)
        },
      ],
      &quot;filter&quot;: &quot;A String&quot;, # Optional. The filter syntax consists of an expression language for constructing a predicate from one or more fields of the documents being filtered. Filter expression is case-sensitive. If this field is unrecognizable, an `INVALID_ARGUMENT` is returned. Filtering in Vertex AI Search is done by mapping the LHS filter key to a key property defined in the Vertex AI Search backend -- this mapping is defined by the customer in their schema. For example a media customer might have a field &#x27;name&#x27; in their schema. In this case the filter would look like this: filter --&gt; name:&#x27;ANY(&quot;king kong&quot;)&#x27; For more information about filtering including syntax and filter operators, see [Filter](https://cloud.google.com/generative-ai-app-builder/docs/filter-search-metadata)
    },
    &quot;videoGenerationSpec&quot;: { # Specification of the video generation tool. # Optional. Specification of the video generation tool.
    },
    &quot;webGroundingSpec&quot;: { # Specification of the web grounding tool. # Optional. Specification of the web grounding tool. If field is present, enables grounding with web search. Works only if Assistant.web_grounding_type is WEB_GROUNDING_TYPE_GOOGLE_SEARCH or WEB_GROUNDING_TYPE_ENTERPRISE_WEB_SEARCH.
    },
  },
  &quot;userMetadata&quot;: { # User metadata of the request. # Optional. Information about the user initiating the query.
    &quot;preferredLanguageCode&quot;: &quot;A String&quot;, # Optional. Preferred language to be used for answering if language detection fails. Also used as the language of error messages created by actions, regardless of language detection results.
    &quot;timeZone&quot;: &quot;A String&quot;, # Optional. IANA time zone, e.g. Europe/Budapest.
  },
}

  x__xgafv: string, V1 error format.
    Allowed values
      1 - v1 error format
      2 - v2 error format

Returns:
  An object of the form:

    { # Response for the AssistantService.StreamAssist method.
  &quot;answer&quot;: { # AssistAnswer resource, main part of AssistResponse. # Assist answer resource object containing parts of the assistant&#x27;s final answer for the user&#x27;s query. Not present if the current response doesn&#x27;t add anything to previously sent AssistAnswer.replies. Observe AssistAnswer.state to see if more parts are to be expected. While the state is `IN_PROGRESS`, the AssistAnswer.replies field in each response will contain replies (reply fragments) to be appended to the ones received in previous responses. AssistAnswer.name won&#x27;t be filled. If the state is `SUCCEEDED`, `FAILED` or `SKIPPED`, the response is the last response and AssistAnswer.name will have a value.
    &quot;assistSkippedReasons&quot;: [ # Reasons for not answering the assist call.
      &quot;A String&quot;,
    ],
    &quot;name&quot;: &quot;A String&quot;, # Immutable. Identifier. Resource name of the `AssistAnswer`. Format: `projects/{project}/locations/{location}/collections/{collection}/engines/{engine}/sessions/{session}/assistAnswers/{assist_answer}` This field must be a UTF-8 encoded string with a length limit of 1024 characters.
    &quot;replies&quot;: [ # Replies of the assistant.
      { # One part of the multi-part response of the assist call.
        &quot;groundedContent&quot;: { # A piece of content and possibly its grounding information. Not all content needs grounding. Phrases like &quot;Of course, I will gladly search it for you.&quot; do not need grounding. # Possibly grounded response text or media from the assistant.
          &quot;content&quot;: { # Multi-modal content. # The content.
            &quot;codeExecutionResult&quot;: { # Result of executing ExecutableCode. # Result of executing an ExecutableCode.
              &quot;outcome&quot;: &quot;A String&quot;, # Required. Outcome of the code execution.
              &quot;output&quot;: &quot;A String&quot;, # Optional. Contains stdout when code execution is successful, stderr or other description otherwise.
            },
            &quot;executableCode&quot;: { # Code generated by the model that is meant to be executed by the model. # Code generated by the model that is meant to be executed.
              &quot;code&quot;: &quot;A String&quot;, # Required. The code content. Currently only supports Python.
            },
            &quot;file&quot;: { # A file, e.g., an audio summary. # A file, e.g., an audio summary.
              &quot;fileId&quot;: &quot;A String&quot;, # Required. The file ID.
              &quot;mimeType&quot;: &quot;A String&quot;, # Required. The media type (MIME type) of the file.
            },
            &quot;inlineData&quot;: { # Inline blob. # Inline binary data.
              &quot;data&quot;: &quot;A String&quot;, # Required. Raw bytes.
              &quot;mimeType&quot;: &quot;A String&quot;, # Required. The media type (MIME type) of the generated data.
            },
            &quot;role&quot;: &quot;A String&quot;, # The producer of the content. Can be &quot;model&quot; or &quot;user&quot;.
            &quot;text&quot;: &quot;A String&quot;, # Inline text.
            &quot;thought&quot;: True or False, # Optional. Indicates if the part is thought from the model.
          },
          &quot;textGroundingMetadata&quot;: { # Grounding details for text sources. # Metadata for grounding based on text sources.
            &quot;references&quot;: [ # References for the grounded text.
              { # Referenced content and related document metadata.
                &quot;content&quot;: &quot;A String&quot;, # Referenced text content.
                &quot;documentMetadata&quot;: { # Document metadata. # Document metadata.
                  &quot;document&quot;: &quot;A String&quot;, # Document resource name.
                  &quot;domain&quot;: &quot;A String&quot;, # Domain name from the document URI. Note that the `uri` field may contain a URL that redirects to the actual website, in which case this will contain the domain name of the target site.
                  &quot;pageIdentifier&quot;: &quot;A String&quot;, # Page identifier.
                  &quot;title&quot;: &quot;A String&quot;, # Title.
                  &quot;uri&quot;: &quot;A String&quot;, # URI for the document. It may contain a URL that redirects to the actual website.
                },
              },
            ],
            &quot;segments&quot;: [ # Grounding information for parts of the text.
              { # Grounding information for a segment of the text.
                &quot;endIndex&quot;: &quot;A String&quot;, # End of the segment, exclusive.
                &quot;groundingScore&quot;: 3.14, # Score for the segment.
                &quot;referenceIndices&quot;: [ # References for the segment.
                  42,
                ],
                &quot;startIndex&quot;: &quot;A String&quot;, # Zero-based index indicating the start of the segment, measured in bytes of a UTF-8 string (i.e. characters encoded on multiple bytes have a length of more than one).
                &quot;text&quot;: &quot;A String&quot;, # The text segment itself.
              },
            ],
          },
        },
      },
    ],
    &quot;state&quot;: &quot;A String&quot;, # State of the answer generation.
  },
  &quot;assistToken&quot;: &quot;A String&quot;, # A global unique ID that identifies the current pair of request and stream of responses. Used for feedback and support.
  &quot;sessionInfo&quot;: { # Information about the session. # Session information.
    &quot;session&quot;: &quot;A String&quot;, # Name of the newly generated or continued session. Format: `projects/{project}/locations/{location}/collections/{collection}/engines/{engine}/sessions/{session}`.
  },
}</pre>
</div>

</body></html>