<html><body>
<style>

body, h1, h2, h3, div, span, p, pre, a {
  margin: 0;
  padding: 0;
  border: 0;
  font-weight: inherit;
  font-style: inherit;
  font-size: 100%;
  font-family: inherit;
  vertical-align: baseline;
}

body {
  font-size: 13px;
  padding: 1em;
}

h1 {
  font-size: 26px;
  margin-bottom: 1em;
}

h2 {
  font-size: 24px;
  margin-bottom: 1em;
}

h3 {
  font-size: 20px;
  margin-bottom: 1em;
  margin-top: 1em;
}

pre, code {
  line-height: 1.5;
  font-family: Monaco, 'DejaVu Sans Mono', 'Bitstream Vera Sans Mono', 'Lucida Console', monospace;
}

pre {
  margin-top: 0.5em;
}

h1, h2, h3, p {
  font-family: Arial, sans serif;
}

h1, h2, h3 {
  border-bottom: solid #CCC 1px;
}

.toc_element {
  margin-top: 0.5em;
}

.firstline {
  margin-left: 2 em;
}

.method  {
  margin-top: 1em;
  border: solid 1px #CCC;
  padding: 1em;
  background: #EEE;
}

.details {
  font-weight: bold;
  font-size: 14px;
}

</style>

<h1><a href="ces_v1beta.html">Gemini Enterprise for Customer Experience API</a> . <a href="ces_v1beta.projects.html">projects</a> . <a href="ces_v1beta.projects.locations.html">locations</a> . <a href="ces_v1beta.projects.locations.apps.html">apps</a> . <a href="ces_v1beta.projects.locations.apps.evaluationRuns.html">evaluationRuns</a></h1>
<h2>Instance Methods</h2>
<p class="toc_element">
  <code><a href="#close">close()</a></code></p>
<p class="firstline">Close httplib2 connections.</p>
<p class="toc_element">
  <code><a href="#delete">delete(name, x__xgafv=None)</a></code></p>
<p class="firstline">Deletes an evaluation run.</p>
<p class="toc_element">
  <code><a href="#get">get(name, x__xgafv=None)</a></code></p>
<p class="firstline">Gets details of the specified evaluation run.</p>
<p class="toc_element">
  <code><a href="#list">list(parent, filter=None, orderBy=None, pageSize=None, pageToken=None, x__xgafv=None)</a></code></p>
<p class="firstline">Lists all evaluation runs in the given app.</p>
<p class="toc_element">
  <code><a href="#list_next">list_next()</a></code></p>
<p class="firstline">Retrieves the next page of results.</p>
<h3>Method Details</h3>
<div class="method">
    <code class="details" id="close">close()</code>
  <pre>Close httplib2 connections.</pre>
</div>

<div class="method">
    <code class="details" id="delete">delete(name, x__xgafv=None)</code>
  <pre>Deletes an evaluation run.

Args:
  name: string, Required. The resource name of the evaluation run to delete. (required)
  x__xgafv: string, V1 error format.
    Allowed values
      1 - v1 error format
      2 - v2 error format

Returns:
  An object of the form:

    { # This resource represents a long-running operation that is the result of a network API call.
  &quot;done&quot;: True or False, # If the value is `false`, it means the operation is still in progress. If `true`, the operation is completed, and either `error` or `response` is available.
  &quot;error&quot;: { # The `Status` type defines a logical error model that is suitable for different programming environments, including REST APIs and RPC APIs. It is used by [gRPC](https://github.com/grpc). Each `Status` message contains three pieces of data: error code, error message, and error details. You can find out more about this error model and how to work with it in the [API Design Guide](https://cloud.google.com/apis/design/errors). # The error result of the operation in case of failure or cancellation.
    &quot;code&quot;: 42, # The status code, which should be an enum value of google.rpc.Code.
    &quot;details&quot;: [ # A list of messages that carry the error details. There is a common set of message types for APIs to use.
      {
        &quot;a_key&quot;: &quot;&quot;, # Properties of the object. Contains field @type with type URL.
      },
    ],
    &quot;message&quot;: &quot;A String&quot;, # A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client.
  },
  &quot;metadata&quot;: { # Service-specific metadata associated with the operation. It typically contains progress information and common metadata such as create time. Some services might not provide such metadata. Any method that returns a long-running operation should document the metadata type, if any.
    &quot;a_key&quot;: &quot;&quot;, # Properties of the object. Contains field @type with type URL.
  },
  &quot;name&quot;: &quot;A String&quot;, # The server-assigned name, which is only unique within the same service that originally returns it. If you use the default HTTP mapping, the `name` should be a resource name ending with `operations/{unique_id}`.
  &quot;response&quot;: { # The normal, successful response of the operation. If the original method returns no data on success, such as `Delete`, the response is `google.protobuf.Empty`. If the original method is standard `Get`/`Create`/`Update`, the response should be the resource. For other methods, the response should have the type `XxxResponse`, where `Xxx` is the original method name. For example, if the original method name is `TakeSnapshot()`, the inferred response type is `TakeSnapshotResponse`.
    &quot;a_key&quot;: &quot;&quot;, # Properties of the object. Contains field @type with type URL.
  },
}</pre>
</div>

<div class="method">
    <code class="details" id="get">get(name, x__xgafv=None)</code>
  <pre>Gets details of the specified evaluation run.

Args:
  name: string, Required. The resource name of the evaluation run to retrieve. (required)
  x__xgafv: string, V1 error format.
    Allowed values
      1 - v1 error format
      2 - v2 error format

Returns:
  An object of the form:

    { # An evaluation run represents an all the evaluation results from an evaluation execution.
  &quot;appVersion&quot;: &quot;A String&quot;, # Output only. The app version to evaluate. Format: `projects/{project}/locations/{location}/apps/{app}/versions/{version}`
  &quot;appVersionDisplayName&quot;: &quot;A String&quot;, # Output only. The display name of the `app_version` that the evaluation ran against.
  &quot;changelog&quot;: &quot;A String&quot;, # Output only. The changelog of the app version that the evaluation ran against. This is populated if user runs evaluation on latest/draft.
  &quot;changelogCreateTime&quot;: &quot;A String&quot;, # Output only. The create time of the changelog of the app version that the evaluation ran against. This is populated if user runs evaluation on latest/draft.
  &quot;config&quot;: { # EvaluationConfig configures settings for running the evaluation. # Output only. The configuration used in the run.
    &quot;evaluationChannel&quot;: &quot;A String&quot;, # Optional. The channel to evaluate.
    &quot;inputAudioConfig&quot;: { # InputAudioConfig configures how the CES agent should interpret the incoming audio data. # Optional. Configuration for processing the input audio.
      &quot;audioEncoding&quot;: &quot;A String&quot;, # Required. The encoding of the input audio data.
      &quot;noiseSuppressionLevel&quot;: &quot;A String&quot;, # Optional. Whether to enable noise suppression on the input audio. Available values are &quot;low&quot;, &quot;moderate&quot;, &quot;high&quot;, &quot;very_high&quot;.
      &quot;sampleRateHertz&quot;: 42, # Required. The sample rate (in Hertz) of the input audio data.
    },
    &quot;outputAudioConfig&quot;: { # OutputAudioConfig configures how the CES agent should synthesize outgoing audio responses. # Optional. Configuration for generating the output audio.
      &quot;audioEncoding&quot;: &quot;A String&quot;, # Required. The encoding of the output audio data.
      &quot;sampleRateHertz&quot;: 42, # Required. The sample rate (in Hertz) of the output audio data.
    },
    &quot;toolCallBehaviour&quot;: &quot;A String&quot;, # Optional. Specifies whether the evaluation should use real tool calls or fake tools.
  },
  &quot;createTime&quot;: &quot;A String&quot;, # Output only. Timestamp when the evaluation run was created.
  &quot;displayName&quot;: &quot;A String&quot;, # Optional. User-defined display name of the evaluation run. default: &quot; run - &quot;.
  &quot;error&quot;: { # The `Status` type defines a logical error model that is suitable for different programming environments, including REST APIs and RPC APIs. It is used by [gRPC](https://github.com/grpc). Each `Status` message contains three pieces of data: error code, error message, and error details. You can find out more about this error model and how to work with it in the [API Design Guide](https://cloud.google.com/apis/design/errors). # Output only. Deprecated: Use error_info instead. Errors encountered during execution.
    &quot;code&quot;: 42, # The status code, which should be an enum value of google.rpc.Code.
    &quot;details&quot;: [ # A list of messages that carry the error details. There is a common set of message types for APIs to use.
      {
        &quot;a_key&quot;: &quot;&quot;, # Properties of the object. Contains field @type with type URL.
      },
    ],
    &quot;message&quot;: &quot;A String&quot;, # A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client.
  },
  &quot;errorInfo&quot;: { # Information about an error encountered during an evaluation execution. # Output only. Error information for the evaluation run.
    &quot;errorMessage&quot;: &quot;A String&quot;, # Output only. The error message.
    &quot;errorType&quot;: &quot;A String&quot;, # Output only. The type of error.
    &quot;sessionId&quot;: &quot;A String&quot;, # Output only. The session ID for the conversation that caused the error.
  },
  &quot;evaluationDataset&quot;: &quot;A String&quot;, # Output only. The evaluation dataset that this run is associated with. This field is mutually exclusive with `evaluations`. Format: `projects/{project}/locations/{location}/apps/{app}/evaluationDatasets/{evaluationDataset}`
  &quot;evaluationResults&quot;: [ # Output only. The evaluation results that are part of this run. Format: `projects/{project}/locations/{location}/apps/{app}/evaluations/{evaluation}/results/{result}`
    &quot;A String&quot;,
  ],
  &quot;evaluationRunSummaries&quot;: { # Output only. Map of evaluation name to EvaluationRunSummary.
    &quot;a_key&quot;: { # Contains the summary of passed and failed result counts for a specific evaluation in an evaluation run.
      &quot;errorCount&quot;: 42, # Output only. Number of error results for the associated Evaluation in this run.
      &quot;failedCount&quot;: 42, # Output only. Number of failed results for the associated Evaluation in this run.
      &quot;passedCount&quot;: 42, # Output only. Number of passed results for the associated Evaluation in this run.
    },
  },
  &quot;evaluationType&quot;: &quot;A String&quot;, # Output only. The type of the evaluations in this run.
  &quot;evaluations&quot;: [ # Output only. The evaluations that are part of this run. The list may contain evaluations of either type. This field is mutually exclusive with `evaluation_dataset`. Format: `projects/{project}/locations/{location}/apps/{app}/evaluations/{evaluation}`
    &quot;A String&quot;,
  ],
  &quot;goldenRunMethod&quot;: &quot;A String&quot;, # Output only. The method used to run the evaluation.
  &quot;initiatedBy&quot;: &quot;A String&quot;, # Output only. The user who initiated the evaluation run.
  &quot;latencyReport&quot;: { # Latency report for the evaluation run. # Output only. Latency report for the evaluation run.
    &quot;callbackLatencies&quot;: [ # Output only. Unordered list. Latency metrics for each callback.
      { # Latency metrics for a single callback.
        &quot;latencyMetrics&quot;: { # Latency metrics for a component. # Output only. The latency metrics for the callback.
          &quot;callCount&quot;: 42, # Output only. The number of times the resource was called.
          &quot;p50Latency&quot;: &quot;A String&quot;, # Output only. The 50th percentile latency.
          &quot;p90Latency&quot;: &quot;A String&quot;, # Output only. The 90th percentile latency.
          &quot;p99Latency&quot;: &quot;A String&quot;, # Output only. The 99th percentile latency.
        },
        &quot;stage&quot;: &quot;A String&quot;, # Output only. The stage of the callback.
      },
    ],
    &quot;guardrailLatencies&quot;: [ # Output only. Unordered list. Latency metrics for each guardrail.
      { # Latency metrics for a single guardrail.
        &quot;guardrail&quot;: &quot;A String&quot;, # Output only. The name of the guardrail. Format: `projects/{project}/locations/{location}/apps/{app}/guardrails/{guardrail}`.
        &quot;guardrailDisplayName&quot;: &quot;A String&quot;, # Output only. The display name of the guardrail.
        &quot;latencyMetrics&quot;: { # Latency metrics for a component. # Output only. The latency metrics for the guardrail.
          &quot;callCount&quot;: 42, # Output only. The number of times the resource was called.
          &quot;p50Latency&quot;: &quot;A String&quot;, # Output only. The 50th percentile latency.
          &quot;p90Latency&quot;: &quot;A String&quot;, # Output only. The 90th percentile latency.
          &quot;p99Latency&quot;: &quot;A String&quot;, # Output only. The 99th percentile latency.
        },
      },
    ],
    &quot;llmCallLatencies&quot;: [ # Output only. Unordered list. Latency metrics for each LLM call.
      { # Latency metrics for a single LLM call.
        &quot;latencyMetrics&quot;: { # Latency metrics for a component. # Output only. The latency metrics for the LLM call.
          &quot;callCount&quot;: 42, # Output only. The number of times the resource was called.
          &quot;p50Latency&quot;: &quot;A String&quot;, # Output only. The 50th percentile latency.
          &quot;p90Latency&quot;: &quot;A String&quot;, # Output only. The 90th percentile latency.
          &quot;p99Latency&quot;: &quot;A String&quot;, # Output only. The 99th percentile latency.
        },
        &quot;model&quot;: &quot;A String&quot;, # Output only. The name of the model.
      },
    ],
    &quot;sessionCount&quot;: 42, # Output only. The total number of sessions considered in the latency report.
    &quot;toolLatencies&quot;: [ # Output only. Unordered list. Latency metrics for each tool.
      { # Latency metrics for a single tool.
        &quot;latencyMetrics&quot;: { # Latency metrics for a component. # Output only. The latency metrics for the tool.
          &quot;callCount&quot;: 42, # Output only. The number of times the resource was called.
          &quot;p50Latency&quot;: &quot;A String&quot;, # Output only. The 50th percentile latency.
          &quot;p90Latency&quot;: &quot;A String&quot;, # Output only. The 90th percentile latency.
          &quot;p99Latency&quot;: &quot;A String&quot;, # Output only. The 99th percentile latency.
        },
        &quot;tool&quot;: &quot;A String&quot;, # Output only. Format: `projects/{project}/locations/{location}/apps/{app}/tools/{tool}`.
        &quot;toolDisplayName&quot;: &quot;A String&quot;, # Output only. The display name of the tool.
        &quot;toolsetTool&quot;: { # A tool that is created from a toolset. # Output only. The toolset tool identifier.
          &quot;toolId&quot;: &quot;A String&quot;, # Optional. The tool ID to filter the tools to retrieve the schema for.
          &quot;toolset&quot;: &quot;A String&quot;, # Required. The resource name of the Toolset from which this tool is derived. Format: `projects/{project}/locations/{location}/apps/{app}/toolsets/{toolset}`
        },
      },
    ],
  },
  &quot;name&quot;: &quot;A String&quot;, # Identifier. The unique identifier of the evaluation run. Format: `projects/{project}/locations/{location}/apps/{app}/evaluationRuns/{evaluationRun}`
  &quot;optimizationConfig&quot;: { # Configuration for running the optimization step after the evaluation run. # Optional. Configuration for running the optimization step after the evaluation run. If not set, the optimization step will not be run.
    &quot;assistantSession&quot;: &quot;A String&quot;, # Output only. The assistant session to use for the optimization based on this evaluation run. Format: `projects/{project}/locations/{location}/apps/{app}/assistantSessions/{assistantSession}`
    &quot;errorMessage&quot;: &quot;A String&quot;, # Output only. The error message if the optimization run failed.
    &quot;generateLossReport&quot;: True or False, # Optional. Whether to generate a loss report.
    &quot;lossReport&quot;: { # Output only. The generated loss report.
      &quot;a_key&quot;: &quot;&quot;, # Properties of the object.
    },
    &quot;reportSummary&quot;: &quot;A String&quot;, # Output only. The summary of the loss report.
    &quot;shouldSuggestFix&quot;: True or False, # Output only. Whether to suggest a fix for the losses.
    &quot;status&quot;: &quot;A String&quot;, # Output only. The status of the optimization run.
  },
  &quot;personaRunConfigs&quot;: [ # Output only. The configuration to use for the run per persona.
    { # Configuration for running an evaluation for a specific persona.
      &quot;persona&quot;: &quot;A String&quot;, # Optional. The persona to use for the evaluation. Format: `projects/{project}/locations/{location}/apps/{app}/evaluationPersonas/{evaluationPersona}`
      &quot;taskCount&quot;: 42, # Optional. The number of tasks to run for the persona.
    },
  ],
  &quot;progress&quot;: { # The progress of the evaluation run. # Output only. The progress of the evaluation run.
    &quot;completedCount&quot;: 42, # Output only. Number of evaluation results that finished successfully. (EvaluationResult.execution_state is COMPLETED).
    &quot;errorCount&quot;: 42, # Output only. Number of evaluation results that failed to execute. (EvaluationResult.execution_state is ERROR).
    &quot;failedCount&quot;: 42, # Output only. Number of completed evaluation results with an outcome of FAIL. (EvaluationResult.execution_state is COMPLETED and EvaluationResult.evaluation_status is FAIL).
    &quot;passedCount&quot;: 42, # Output only. Number of completed evaluation results with an outcome of PASS. (EvaluationResult.execution_state is COMPLETED and EvaluationResult.evaluation_status is PASS).
    &quot;totalCount&quot;: 42, # Output only. Total number of evaluation results in this run.
  },
  &quot;runCount&quot;: 42, # Output only. The number of times the evaluations inside the run were run.
  &quot;scheduledEvaluationRun&quot;: &quot;A String&quot;, # Output only. The scheduled evaluation run resource name that created this evaluation run. This field is only set if the evaluation run was created by a scheduled evaluation run. Format: `projects/{project}/locations/{location}/apps/{app}/scheduledEvaluationRuns/{scheduled_evaluation_run}`
  &quot;state&quot;: &quot;A String&quot;, # Output only. The state of the evaluation run.
}</pre>
</div>

<div class="method">
    <code class="details" id="list">list(parent, filter=None, orderBy=None, pageSize=None, pageToken=None, x__xgafv=None)</code>
  <pre>Lists all evaluation runs in the given app.

Args:
  parent: string, Required. The resource name of the app to list evaluation runs from. (required)
  filter: string, Optional. Filter to be applied when listing the evaluation runs. See https://google.aip.dev/160 for more details.
  orderBy: string, Optional. Field to sort by. Only &quot;name&quot; and &quot;create_time&quot;, and &quot;update_time&quot; are supported. Time fields are ordered in descending order, and the name field is ordered in ascending order. If not included, &quot;update_time&quot; will be the default. See https://google.aip.dev/132#ordering for more details.
  pageSize: integer, Optional. Requested page size. Server may return fewer items than requested. If unspecified, server will pick an appropriate default.
  pageToken: string, Optional. The next_page_token value returned from a previous list EvaluationService.ListEvaluationRuns call.
  x__xgafv: string, V1 error format.
    Allowed values
      1 - v1 error format
      2 - v2 error format

Returns:
  An object of the form:

    { # Response message for EvaluationService.ListEvaluationRuns.
  &quot;evaluationRuns&quot;: [ # The list of evaluation runs.
    { # An evaluation run represents an all the evaluation results from an evaluation execution.
      &quot;appVersion&quot;: &quot;A String&quot;, # Output only. The app version to evaluate. Format: `projects/{project}/locations/{location}/apps/{app}/versions/{version}`
      &quot;appVersionDisplayName&quot;: &quot;A String&quot;, # Output only. The display name of the `app_version` that the evaluation ran against.
      &quot;changelog&quot;: &quot;A String&quot;, # Output only. The changelog of the app version that the evaluation ran against. This is populated if user runs evaluation on latest/draft.
      &quot;changelogCreateTime&quot;: &quot;A String&quot;, # Output only. The create time of the changelog of the app version that the evaluation ran against. This is populated if user runs evaluation on latest/draft.
      &quot;config&quot;: { # EvaluationConfig configures settings for running the evaluation. # Output only. The configuration used in the run.
        &quot;evaluationChannel&quot;: &quot;A String&quot;, # Optional. The channel to evaluate.
        &quot;inputAudioConfig&quot;: { # InputAudioConfig configures how the CES agent should interpret the incoming audio data. # Optional. Configuration for processing the input audio.
          &quot;audioEncoding&quot;: &quot;A String&quot;, # Required. The encoding of the input audio data.
          &quot;noiseSuppressionLevel&quot;: &quot;A String&quot;, # Optional. Whether to enable noise suppression on the input audio. Available values are &quot;low&quot;, &quot;moderate&quot;, &quot;high&quot;, &quot;very_high&quot;.
          &quot;sampleRateHertz&quot;: 42, # Required. The sample rate (in Hertz) of the input audio data.
        },
        &quot;outputAudioConfig&quot;: { # OutputAudioConfig configures how the CES agent should synthesize outgoing audio responses. # Optional. Configuration for generating the output audio.
          &quot;audioEncoding&quot;: &quot;A String&quot;, # Required. The encoding of the output audio data.
          &quot;sampleRateHertz&quot;: 42, # Required. The sample rate (in Hertz) of the output audio data.
        },
        &quot;toolCallBehaviour&quot;: &quot;A String&quot;, # Optional. Specifies whether the evaluation should use real tool calls or fake tools.
      },
      &quot;createTime&quot;: &quot;A String&quot;, # Output only. Timestamp when the evaluation run was created.
      &quot;displayName&quot;: &quot;A String&quot;, # Optional. User-defined display name of the evaluation run. default: &quot; run - &quot;.
      &quot;error&quot;: { # The `Status` type defines a logical error model that is suitable for different programming environments, including REST APIs and RPC APIs. It is used by [gRPC](https://github.com/grpc). Each `Status` message contains three pieces of data: error code, error message, and error details. You can find out more about this error model and how to work with it in the [API Design Guide](https://cloud.google.com/apis/design/errors). # Output only. Deprecated: Use error_info instead. Errors encountered during execution.
        &quot;code&quot;: 42, # The status code, which should be an enum value of google.rpc.Code.
        &quot;details&quot;: [ # A list of messages that carry the error details. There is a common set of message types for APIs to use.
          {
            &quot;a_key&quot;: &quot;&quot;, # Properties of the object. Contains field @type with type URL.
          },
        ],
        &quot;message&quot;: &quot;A String&quot;, # A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client.
      },
      &quot;errorInfo&quot;: { # Information about an error encountered during an evaluation execution. # Output only. Error information for the evaluation run.
        &quot;errorMessage&quot;: &quot;A String&quot;, # Output only. The error message.
        &quot;errorType&quot;: &quot;A String&quot;, # Output only. The type of error.
        &quot;sessionId&quot;: &quot;A String&quot;, # Output only. The session ID for the conversation that caused the error.
      },
      &quot;evaluationDataset&quot;: &quot;A String&quot;, # Output only. The evaluation dataset that this run is associated with. This field is mutually exclusive with `evaluations`. Format: `projects/{project}/locations/{location}/apps/{app}/evaluationDatasets/{evaluationDataset}`
      &quot;evaluationResults&quot;: [ # Output only. The evaluation results that are part of this run. Format: `projects/{project}/locations/{location}/apps/{app}/evaluations/{evaluation}/results/{result}`
        &quot;A String&quot;,
      ],
      &quot;evaluationRunSummaries&quot;: { # Output only. Map of evaluation name to EvaluationRunSummary.
        &quot;a_key&quot;: { # Contains the summary of passed and failed result counts for a specific evaluation in an evaluation run.
          &quot;errorCount&quot;: 42, # Output only. Number of error results for the associated Evaluation in this run.
          &quot;failedCount&quot;: 42, # Output only. Number of failed results for the associated Evaluation in this run.
          &quot;passedCount&quot;: 42, # Output only. Number of passed results for the associated Evaluation in this run.
        },
      },
      &quot;evaluationType&quot;: &quot;A String&quot;, # Output only. The type of the evaluations in this run.
      &quot;evaluations&quot;: [ # Output only. The evaluations that are part of this run. The list may contain evaluations of either type. This field is mutually exclusive with `evaluation_dataset`. Format: `projects/{project}/locations/{location}/apps/{app}/evaluations/{evaluation}`
        &quot;A String&quot;,
      ],
      &quot;goldenRunMethod&quot;: &quot;A String&quot;, # Output only. The method used to run the evaluation.
      &quot;initiatedBy&quot;: &quot;A String&quot;, # Output only. The user who initiated the evaluation run.
      &quot;latencyReport&quot;: { # Latency report for the evaluation run. # Output only. Latency report for the evaluation run.
        &quot;callbackLatencies&quot;: [ # Output only. Unordered list. Latency metrics for each callback.
          { # Latency metrics for a single callback.
            &quot;latencyMetrics&quot;: { # Latency metrics for a component. # Output only. The latency metrics for the callback.
              &quot;callCount&quot;: 42, # Output only. The number of times the resource was called.
              &quot;p50Latency&quot;: &quot;A String&quot;, # Output only. The 50th percentile latency.
              &quot;p90Latency&quot;: &quot;A String&quot;, # Output only. The 90th percentile latency.
              &quot;p99Latency&quot;: &quot;A String&quot;, # Output only. The 99th percentile latency.
            },
            &quot;stage&quot;: &quot;A String&quot;, # Output only. The stage of the callback.
          },
        ],
        &quot;guardrailLatencies&quot;: [ # Output only. Unordered list. Latency metrics for each guardrail.
          { # Latency metrics for a single guardrail.
            &quot;guardrail&quot;: &quot;A String&quot;, # Output only. The name of the guardrail. Format: `projects/{project}/locations/{location}/apps/{app}/guardrails/{guardrail}`.
            &quot;guardrailDisplayName&quot;: &quot;A String&quot;, # Output only. The display name of the guardrail.
            &quot;latencyMetrics&quot;: { # Latency metrics for a component. # Output only. The latency metrics for the guardrail.
              &quot;callCount&quot;: 42, # Output only. The number of times the resource was called.
              &quot;p50Latency&quot;: &quot;A String&quot;, # Output only. The 50th percentile latency.
              &quot;p90Latency&quot;: &quot;A String&quot;, # Output only. The 90th percentile latency.
              &quot;p99Latency&quot;: &quot;A String&quot;, # Output only. The 99th percentile latency.
            },
          },
        ],
        &quot;llmCallLatencies&quot;: [ # Output only. Unordered list. Latency metrics for each LLM call.
          { # Latency metrics for a single LLM call.
            &quot;latencyMetrics&quot;: { # Latency metrics for a component. # Output only. The latency metrics for the LLM call.
              &quot;callCount&quot;: 42, # Output only. The number of times the resource was called.
              &quot;p50Latency&quot;: &quot;A String&quot;, # Output only. The 50th percentile latency.
              &quot;p90Latency&quot;: &quot;A String&quot;, # Output only. The 90th percentile latency.
              &quot;p99Latency&quot;: &quot;A String&quot;, # Output only. The 99th percentile latency.
            },
            &quot;model&quot;: &quot;A String&quot;, # Output only. The name of the model.
          },
        ],
        &quot;sessionCount&quot;: 42, # Output only. The total number of sessions considered in the latency report.
        &quot;toolLatencies&quot;: [ # Output only. Unordered list. Latency metrics for each tool.
          { # Latency metrics for a single tool.
            &quot;latencyMetrics&quot;: { # Latency metrics for a component. # Output only. The latency metrics for the tool.
              &quot;callCount&quot;: 42, # Output only. The number of times the resource was called.
              &quot;p50Latency&quot;: &quot;A String&quot;, # Output only. The 50th percentile latency.
              &quot;p90Latency&quot;: &quot;A String&quot;, # Output only. The 90th percentile latency.
              &quot;p99Latency&quot;: &quot;A String&quot;, # Output only. The 99th percentile latency.
            },
            &quot;tool&quot;: &quot;A String&quot;, # Output only. Format: `projects/{project}/locations/{location}/apps/{app}/tools/{tool}`.
            &quot;toolDisplayName&quot;: &quot;A String&quot;, # Output only. The display name of the tool.
            &quot;toolsetTool&quot;: { # A tool that is created from a toolset. # Output only. The toolset tool identifier.
              &quot;toolId&quot;: &quot;A String&quot;, # Optional. The tool ID to filter the tools to retrieve the schema for.
              &quot;toolset&quot;: &quot;A String&quot;, # Required. The resource name of the Toolset from which this tool is derived. Format: `projects/{project}/locations/{location}/apps/{app}/toolsets/{toolset}`
            },
          },
        ],
      },
      &quot;name&quot;: &quot;A String&quot;, # Identifier. The unique identifier of the evaluation run. Format: `projects/{project}/locations/{location}/apps/{app}/evaluationRuns/{evaluationRun}`
      &quot;optimizationConfig&quot;: { # Configuration for running the optimization step after the evaluation run. # Optional. Configuration for running the optimization step after the evaluation run. If not set, the optimization step will not be run.
        &quot;assistantSession&quot;: &quot;A String&quot;, # Output only. The assistant session to use for the optimization based on this evaluation run. Format: `projects/{project}/locations/{location}/apps/{app}/assistantSessions/{assistantSession}`
        &quot;errorMessage&quot;: &quot;A String&quot;, # Output only. The error message if the optimization run failed.
        &quot;generateLossReport&quot;: True or False, # Optional. Whether to generate a loss report.
        &quot;lossReport&quot;: { # Output only. The generated loss report.
          &quot;a_key&quot;: &quot;&quot;, # Properties of the object.
        },
        &quot;reportSummary&quot;: &quot;A String&quot;, # Output only. The summary of the loss report.
        &quot;shouldSuggestFix&quot;: True or False, # Output only. Whether to suggest a fix for the losses.
        &quot;status&quot;: &quot;A String&quot;, # Output only. The status of the optimization run.
      },
      &quot;personaRunConfigs&quot;: [ # Output only. The configuration to use for the run per persona.
        { # Configuration for running an evaluation for a specific persona.
          &quot;persona&quot;: &quot;A String&quot;, # Optional. The persona to use for the evaluation. Format: `projects/{project}/locations/{location}/apps/{app}/evaluationPersonas/{evaluationPersona}`
          &quot;taskCount&quot;: 42, # Optional. The number of tasks to run for the persona.
        },
      ],
      &quot;progress&quot;: { # The progress of the evaluation run. # Output only. The progress of the evaluation run.
        &quot;completedCount&quot;: 42, # Output only. Number of evaluation results that finished successfully. (EvaluationResult.execution_state is COMPLETED).
        &quot;errorCount&quot;: 42, # Output only. Number of evaluation results that failed to execute. (EvaluationResult.execution_state is ERROR).
        &quot;failedCount&quot;: 42, # Output only. Number of completed evaluation results with an outcome of FAIL. (EvaluationResult.execution_state is COMPLETED and EvaluationResult.evaluation_status is FAIL).
        &quot;passedCount&quot;: 42, # Output only. Number of completed evaluation results with an outcome of PASS. (EvaluationResult.execution_state is COMPLETED and EvaluationResult.evaluation_status is PASS).
        &quot;totalCount&quot;: 42, # Output only. Total number of evaluation results in this run.
      },
      &quot;runCount&quot;: 42, # Output only. The number of times the evaluations inside the run were run.
      &quot;scheduledEvaluationRun&quot;: &quot;A String&quot;, # Output only. The scheduled evaluation run resource name that created this evaluation run. This field is only set if the evaluation run was created by a scheduled evaluation run. Format: `projects/{project}/locations/{location}/apps/{app}/scheduledEvaluationRuns/{scheduled_evaluation_run}`
      &quot;state&quot;: &quot;A String&quot;, # Output only. The state of the evaluation run.
    },
  ],
  &quot;nextPageToken&quot;: &quot;A String&quot;, # A token that can be sent as ListEvaluationRunsRequest.page_token to retrieve the next page. Absence of this field indicates there are no subsequent pages.
}</pre>
</div>

<div class="method">
    <code class="details" id="list_next">list_next()</code>
  <pre>Retrieves the next page of results.

        Args:
          previous_request: The request for the previous page. (required)
          previous_response: The response from the request for the previous page. (required)

        Returns:
          A request object that you can call &#x27;execute()&#x27; on to request the next
          page. Returns None if there are no more items in the collection.
        </pre>
</div>

</body></html>